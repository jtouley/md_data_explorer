[0;32mRunning all tests...[0m
uv run pytest tests -v
============================= test session starts ==============================
platform darwin -- Python 3.13.11, pytest-9.0.2, pluggy-1.6.0 -- /Users/jasontouleyrou/Projects/md_data_explorer/.venv/bin/python
cachedir: .pytest_cache
rootdir: /Users/jasontouleyrou/Projects/md_data_explorer
configfile: pyproject.toml
plugins: anyio-4.12.0, xdist-3.8.0, langsmith-0.5.1, cov-7.0.0
collecting ... collected 1214 items

tests/analysis/test_compute.py::TestComputeDescriptiveAnalysis::test_compute_descriptive_analysis_returns_serializable_dict PASSED [  0%]
tests/analysis/test_compute.py::TestComputeDescriptiveAnalysis::test_compute_descriptive_analysis_uses_polars_attributes PASSED [  0%]
tests/analysis/test_compute.py::TestComputeDescriptiveAnalysis::test_compute_descriptive_analysis_returns_to_dicts_format PASSED [  0%]
tests/analysis/test_compute.py::TestComputeDescriptiveAnalysis::test_compute_descriptive_analysis_handles_empty_dataframe PASSED [  0%]
tests/analysis/test_compute.py::TestComputeDescriptiveAnalysis::test_compute_descriptive_analysis_handles_null_values PASSED [  0%]
tests/analysis/test_compute.py::TestComputeDescriptiveAnalysis::test_compute_descriptive_analysis_includes_breakdown_when_filters_applied PASSED [  0%]
tests/analysis/test_compute.py::TestComputeDescriptiveAnalysis::test_compute_descriptive_analysis_no_breakdown_when_no_filters PASSED [  0%]
tests/analysis/test_compute.py::TestComputeDescriptiveAnalysis::test_compute_descriptive_analysis_breakdown_tracks_filtered_vs_unfiltered_counts PASSED [  0%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_compute_comparison_analysis_returns_serializable_dict PASSED [  0%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_compute_comparison_analysis_t_test_for_two_groups PASSED [  0%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_compute_comparison_analysis_anova_for_multiple_groups PASSED [  0%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_compute_comparison_analysis_chi_square_for_categorical PASSED [  0%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_compute_comparison_analysis_handles_insufficient_data PASSED [  1%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_compute_comparison_analysis_handles_single_group PASSED [  1%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_comparison_analysis_with_string_numeric_outcome PASSED [  1%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_comparison_analysis_with_european_comma_format PASSED [  1%]
tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_comparison_analysis_works_identically_single_file_and_multi_table PASSED [  1%]
tests/analysis/test_compute.py::TestComputePredictorAnalysis::test_compute_predictor_analysis_returns_serializable_dict PASSED [  1%]
tests/analysis/test_compute.py::TestComputePredictorAnalysis::test_compute_predictor_analysis_handles_insufficient_data PASSED [  1%]
tests/analysis/test_compute.py::TestComputePredictorAnalysis::test_compute_predictor_analysis_handles_non_binary_outcome PASSED [  1%]
tests/analysis/test_compute.py::TestComputeSurvivalAnalysis::test_compute_survival_analysis_returns_serializable_dict PASSED [  1%]
tests/analysis/test_compute.py::TestComputeSurvivalAnalysis::test_compute_survival_analysis_handles_insufficient_data PASSED [  1%]
tests/analysis/test_compute.py::TestComputeSurvivalAnalysis::test_compute_survival_analysis_handles_non_binary_event PASSED [  1%]
tests/analysis/test_compute.py::TestComputeRelationshipAnalysis::test_compute_relationship_analysis_returns_serializable_dict PASSED [  1%]
tests/analysis/test_compute.py::TestComputeRelationshipAnalysis::test_compute_relationship_analysis_handles_insufficient_variables PASSED [  2%]
tests/analysis/test_compute.py::TestComputeRelationshipAnalysis::test_compute_relationship_analysis_handles_insufficient_observations PASSED [  2%]
tests/analysis/test_compute.py::TestComputeRelationshipAnalysis::test_compute_relationship_analysis_identifies_strong_correlations PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_descriptive PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_comparison PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_predictor PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_survival PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_relationship PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_count PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_count_with_grouping PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_count_analysis_applies_filters PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_count_analysis_with_filters_and_grouping PASSED [  2%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_count_analysis_without_filters_counts_all_rows PASSED [  3%]
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_handles_unknown_intent PASSED [  3%]
tests/analysis/test_compute_count_most_query.py::TestMostQueryDetection::test_most_query_returns_only_top_result PASSED [  3%]
tests/analysis/test_compute_count_most_query.py::TestMostQueryDetection::test_non_most_query_returns_all_results PASSED [  3%]
tests/analysis/test_compute_count_most_query.py::TestMostQueryDetection::test_most_detection_is_generic_works_for_any_query PASSED [  3%]
tests/analysis/test_compute_count_most_query.py::TestMostQueryDetection::test_most_query_headline_shows_only_top_result PASSED [  3%]
tests/analysis/test_stats.py::TestStats::test_run_logistic_regression PASSED [  3%]
tests/analysis/test_stats.py::TestStats::test_run_logistic_regression_single_predictor PASSED [  3%]
tests/analysis/test_stats.py::TestStats::test_run_logistic_regression_with_nulls PASSED [  3%]
tests/analysis/test_stats.py::TestStats::test_run_logistic_regression_all_nulls PASSED [  3%]
tests/analysis/test_stats.py::TestStats::test_run_logistic_regression_empty_dataframe PASSED [  3%]
tests/analysis/test_stats.py::TestStats::test_run_logistic_regression_results_format PASSED [  3%]
tests/analysis/test_stats_vectorization.py::TestVectorizedOperations::test_odds_ratio_calculation_uses_vectorized_operations PASSED [  4%]
tests/analysis/test_stats_vectorization.py::TestVectorizedOperations::test_vectorized_exp_produces_same_results_as_apply PASSED [  4%]
tests/analysis/test_stats_vectorization.py::TestVectorizedOperations::test_vectorized_exp_on_dataframe_produces_same_results PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_kaplan_meier_single_cohort PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_kaplan_meier_stratified PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_kaplan_meier_with_nulls PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_kaplan_meier_all_nulls PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression_categorical PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression_with_nulls PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression_all_nulls PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_logrank_test_two_groups PASSED [  4%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_logrank_test_multiple_groups PASSED [  5%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_logrank_test_single_group PASSED [  5%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_calculate_median_survival_single_cohort PASSED [  5%]
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_calculate_median_survival_stratified PASSED [  5%]
tests/core/test_chart_spec.py::TestChartSpecGeneration::test_result_artifact_includes_chart_spec PASSED [  5%]
tests/core/test_chart_spec.py::TestChartSpecGeneration::test_chart_spec_has_required_fields PASSED [  5%]
tests/core/test_chart_spec.py::TestChartSpecGeneration::test_chart_spec_type_is_valid PASSED [  5%]
tests/core/test_chart_spec.py::TestChartSpecGeneration::test_chart_spec_deterministic_from_plan PASSED [  5%]
tests/core/test_chart_spec.py::TestChartSpecGeneration::test_chart_spec_differs_for_different_plans PASSED [  5%]
tests/core/test_chart_spec.py::TestChartSpecGeneration::test_chart_spec_none_for_non_visualizable_plans PASSED [  5%]
tests/core/test_clarifying_questions.py::test_clarifying_questions_asks_about_intent_type PASSED [  5%]
tests/core/test_clarifying_questions.py::test_clarifying_questions_uses_semantic_layer_metadata PASSED [  5%]
tests/core/test_clarifying_questions.py::test_clarifying_questions_handles_collisions PASSED [  6%]
tests/core/test_clarifying_questions.py::test_clarifying_questions_surfaces_quality_warnings PASSED [  6%]
tests/core/test_clarifying_questions.py::test_clarifying_questions_asks_about_variables PASSED [  6%]
tests/core/test_clarifying_questions.py::test_clarifying_questions_refines_intent PASSED [  6%]
tests/core/test_clarifying_questions.py::test_clarifying_questions_aborted_gracefully PASSED [  6%]
tests/core/test_clarifying_questions.py::test_clarifying_questions_respects_feature_flag PASSED [  6%]
tests/core/test_dataset.py::test_map_granularity_to_grain_valid PASSED   [  6%]
tests/core/test_dataset.py::test_map_granularity_to_grain_invalid_raises PASSED [  6%]
tests/core/test_dataset_instance_isolation.py::TestDatasetInstanceIsolation::test_semantic_is_instance_attribute PASSED [  6%]
tests/core/test_dataset_instance_isolation.py::TestDatasetInstanceIsolation::test_semantic_property_raises_before_load PASSED [  6%]
tests/core/test_dataset_instance_isolation.py::TestDatasetInstanceIsolation::test_semantic_property_returns_after_set PASSED [  6%]
tests/core/test_dataset_instance_isolation.py::TestDatasetInstanceIsolation::test_semantic_setter_works PASSED [  6%]
tests/core/test_dataset_instance_isolation.py::TestDatasetInstanceIsolation::test_multiple_instances_independent PASSED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_initialization_creates_dataset_instance[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_validation_returns_boolean[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_load_populates_data_when_available[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_get_cohort_returns_unified_schema[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_get_cohort_auto_loads_if_not_loaded[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_idempotency_same_filters_produce_same_result[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_config_driven_mapper_provides_defaults[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_config_driven_time_zero_value[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_config_driven_outcome_label[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestDatasetInterface::test_patient_level_granularity_supported[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestSemanticLayerIntegration::test_config_loaded_correctly[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestSemanticLayerIntegration::test_semantic_layer_initialized_after_load[NOTSET] SKIPPED [  7%]
tests/core/test_dataset_interface.py::TestSchemaCompliance::test_required_columns_present[NOTSET] SKIPPED [  8%]
tests/core/test_dataset_interface.py::TestSchemaCompliance::test_patient_id_column_correct_type[NOTSET] SKIPPED [  8%]
tests/core/test_dataset_interface.py::TestSchemaCompliance::test_time_zero_column_is_datetime[NOTSET] SKIPPED [  8%]
tests/core/test_dataset_interface.py::TestSchemaCompliance::test_outcome_column_is_numeric[NOTSET] SKIPPED [  8%]
tests/core/test_dataset_interface.py::TestSchemaCompliance::test_cohort_has_data[NOTSET] SKIPPED [  8%]
tests/core/test_error_translation.py::TestTranslateErrorWithLLM::test_translate_error_returns_friendly_message_on_success PASSED [  8%]
tests/core/test_error_translation.py::TestTranslateErrorWithLLM::test_translate_error_returns_none_on_llm_failure PASSED [  8%]
tests/core/test_error_translation.py::TestTranslateErrorWithLLM::test_translate_error_returns_none_on_malformed_json PASSED [  8%]
tests/core/test_error_translation.py::TestTranslateErrorWithLLM::test_translate_error_returns_none_on_missing_friendly_message_field PASSED [  8%]
tests/core/test_error_translation.py::TestTranslateErrorWithLLM::test_translate_error_uses_correct_timeout PASSED [  8%]
tests/core/test_error_translation.py::TestTranslateErrorWithLLM::test_translate_error_does_not_expose_sensitive_data PASSED [  8%]
tests/core/test_error_translation.py::TestTranslateErrorWithLLM::test_translate_error_handles_empty_error_message PASSED [  8%]
tests/core/test_eval_harness.py::TestGoldenQuestionsYAML::test_load_golden_questions_from_yaml PASSED [  9%]
tests/core/test_eval_harness.py::TestGoldenQuestionsYAML::test_golden_questions_yaml_supports_filters PASSED [  9%]
tests/core/test_eval_harness.py::TestEvalHarness::test_eval_harness_runs_golden_question PASSED [  9%]
tests/core/test_eval_harness.py::TestEvalHarness::test_eval_harness_detects_intent_mismatch PASSED [  9%]
tests/core/test_eval_harness.py::TestEvalHarness::test_eval_harness_batch_evaluation PASSED [  9%]
tests/core/test_eval_harness.py::TestEvalHarness::test_eval_harness_summary_statistics PASSED [  9%]
tests/core/test_eval_harness.py::TestEvalHarnessIntegration::test_eval_harness_with_real_parsing PASSED [  9%]
tests/core/test_execution_gating.py::TestTransparentConfidenceDisplay::test_execution_always_proceeds_regardless_of_confidence PASSED [  9%]
tests/core/test_execution_gating.py::TestTransparentConfidenceDisplay::test_confidence_levels_categorized_correctly PASSED [  9%]
tests/core/test_execution_gating.py::TestTransparentConfidenceDisplay::test_low_confidence_expands_interpretation_by_default PASSED [  9%]
tests/core/test_execution_gating.py::TestTransparentConfidenceDisplay::test_high_confidence_collapses_interpretation_by_default PASSED [  9%]
tests/core/test_execution_gating.py::TestTransparentConfidenceDisplay::test_queryplan_run_key_used_for_idempotency PASSED [  9%]
tests/core/test_execution_gating.py::TestTransparentConfidenceDisplay::test_confidence_display_falls_back_to_context_when_no_queryplan PASSED [ 10%]
tests/core/test_execution_gating.py::TestTransparentConfidenceDisplay::test_confidence_display_prefers_queryplan_when_available PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_function_exists PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_success_simple PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_real_world_case PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_complex_patterns PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_independent_validation PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_confidence_reduction PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_graceful_degradation PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_timeout_handling PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_json_parse_failure PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_operator_validation PASSED [ 10%]
tests/core/test_filter_extraction.py::TestFilterExtractionLLM::test_extract_filters_with_llm_value_type_validation PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_generate_golden_questions_from_logs_function_exists PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_analyze_golden_question_coverage_function_exists PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_maintain_golden_questions_automatically_function_exists PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_generate_golden_questions_success PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_generate_golden_questions_graceful_degradation PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_analyze_golden_question_coverage PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_validate_golden_question_valid PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_validate_golden_question_missing_question_field PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_validate_golden_question_missing_intent_field PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_validate_golden_question_invalid_intent PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_maintain_golden_questions_automatically_dry_run PASSED [ 11%]
tests/core/test_golden_question_generation.py::TestGoldenQuestionGeneration::test_maintain_golden_questions_automatically_with_updates PASSED [ 12%]
tests/core/test_llm_fallback.py::test_ollama_client_connection_success PASSED [ 12%]
tests/core/test_llm_fallback.py::test_ollama_client_connection_failure_handles_gracefully PASSED [ 12%]
tests/core/test_llm_fallback.py::test_ollama_client_model_available PASSED [ 12%]
tests/core/test_llm_fallback.py::test_ollama_client_model_not_available_handles_gracefully PASSED [ 12%]
tests/core/test_llm_fallback.py::test_rag_context_builder_includes_columns PASSED [ 12%]
tests/core/test_llm_fallback.py::test_rag_context_builder_includes_aliases PASSED [ 12%]
tests/core/test_llm_fallback.py::test_rag_context_builder_includes_examples PASSED [ 12%]
tests/core/test_llm_fallback.py::test_structured_json_extraction_valid_schema PASSED [ 12%]
tests/core/test_llm_fallback.py::test_structured_json_extraction_invalid_json_retries PASSED [ 12%]
tests/core/test_llm_fallback.py::test_structured_json_extraction_timeout_handling PASSED [ 12%]
tests/core/test_llm_fallback.py::test_llm_parse_returns_query_intent_with_confidence PASSED [ 12%]
tests/core/test_llm_fallback.py::test_llm_parse_fallback_to_stub_on_error PASSED [ 13%]
tests/core/test_llm_fallback_integration.py::test_ollama_manager_status PASSED [ 13%]
tests/core/test_llm_fallback_integration.py::test_ollama_client_real_connection PASSED [ 13%]
tests/core/test_llm_fallback_integration.py::test_ollama_client_real_model_available PASSED [ 13%]
tests/core/test_llm_fallback_integration.py::test_ollama_client_real_generate FAILED [ 13%]
tests/core/test_llm_fallback_integration.py::test_llm_parse_with_real_ollama PASSED [ 13%]
tests/core/test_llm_feature.py::TestLLMFeature::test_llmfeature_has_all_expected_values PASSED [ 13%]
tests/core/test_llm_feature.py::TestLLMFeature::test_llmfeature_values_are_strings PASSED [ 13%]
tests/core/test_llm_feature.py::TestCallLLM::test_call_llm_success_returns_result PASSED [ 13%]
tests/core/test_llm_feature.py::TestCallLLM::test_call_llm_ollama_unavailable_returns_error PASSED [ 13%]
tests/core/test_llm_feature.py::TestCallLLM::test_call_llm_timeout_sets_timed_out_flag PASSED [ 13%]
tests/core/test_llm_feature.py::TestCallLLM::test_call_llm_malformed_json_returns_raw_text_only PASSED [ 13%]
tests/core/test_llm_feature.py::TestCallLLM::test_call_llm_respects_timeout_parameter PASSED [ 14%]
tests/core/test_llm_feature.py::TestCallLLM::test_call_llm_tracks_latency PASSED [ 14%]
tests/core/test_llm_feature.py::TestCallLLM::test_call_llm_uses_json_mode PASSED [ 14%]
tests/core/test_llm_feature.py::TestLLMCallResult::test_llmcallresult_success_state PASSED [ 14%]
tests/core/test_llm_feature.py::TestLLMCallResult::test_llmcallresult_timeout_state PASSED [ 14%]
tests/core/test_llm_feature.py::TestLLMCallResult::test_llmcallresult_error_state PASSED [ 14%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_valid_json_returns_dict PASSED [ 14%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_malformed_json_returns_none PASSED [ 14%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_empty_string_returns_none PASSED [ 14%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_none_input_returns_none PASSED [ 14%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_non_json_text_returns_none PASSED [ 14%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_json_array_returns_list PASSED [ 14%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_nested_json_preserves_structure PASSED [ 14%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_json_with_whitespace_succeeds PASSED [ 15%]
tests/core/test_llm_json.py::TestParseJsonResponse::test_parse_json_with_unicode_succeeds PASSED [ 15%]
tests/core/test_llm_json.py::TestValidateShape::test_validate_valid_queryplan_schema_passes PASSED [ 15%]
tests/core/test_llm_json.py::TestValidateShape::test_validate_missing_required_field_fails PASSED [ 15%]
tests/core/test_llm_json.py::TestValidateShape::test_validate_wrong_field_type_fails PASSED [ 15%]
tests/core/test_llm_json.py::TestValidateShape::test_validate_followups_schema_passes PASSED [ 15%]
tests/core/test_llm_json.py::TestValidateShape::test_validate_unknown_schema_fails PASSED [ 15%]
tests/core/test_llm_json.py::TestValidateShape::test_validate_none_payload_fails PASSED [ 15%]
tests/core/test_llm_json.py::TestValidateShape::test_validate_interpretation_schema_passes PASSED [ 15%]
tests/core/test_llm_json.py::TestValidateShape::test_validate_filter_array_schema_passes PASSED [ 15%]
tests/core/test_llm_json.py::TestValidationResult::test_validation_result_valid_has_no_errors PASSED [ 15%]
tests/core/test_llm_json.py::TestValidationResult::test_validation_result_invalid_has_errors PASSED [ 15%]
tests/core/test_llm_mock_performance.py::TestLLMMockPerformance::test_mock_llm_calls_patches_is_available PASSED [ 16%]
tests/core/test_llm_mock_performance.py::TestLLMMockPerformance::test_mock_llm_calls_prevents_http_requests PASSED [ 16%]
tests/core/test_llm_mock_performance.py::TestLLMMockPerformance::test_sentence_transformer_cached_across_tests PASSED [ 16%]
tests/core/test_llm_mock_performance.py::TestLLMMockPerformance::test_nl_query_engine_with_cached_model_fast PASSED [ 16%]
tests/core/test_llm_observability.py::TestSanitizeQuery::test_sanitize_query_returns_hash_and_tags PASSED [ 16%]
tests/core/test_llm_observability.py::TestSanitizeQuery::test_sanitize_query_hash_is_deterministic PASSED [ 16%]
tests/core/test_llm_observability.py::TestSanitizeQuery::test_sanitize_query_hash_is_sha256 PASSED [ 16%]
tests/core/test_llm_observability.py::TestSanitizeQuery::test_sanitize_query_never_includes_raw_text PASSED [ 16%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_detects_negation PASSED [ 16%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_detects_missingness PASSED [ 16%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_detects_numeric_range PASSED [ 16%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_detects_comparison PASSED [ 16%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_detects_grouping PASSED [ 17%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_detects_value_exclusion PASSED [ 17%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_detects_multi_table_join PASSED [ 17%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_returns_empty_for_simple_query PASSED [ 17%]
tests/core/test_llm_observability.py::TestExtractPatternTags::test_extract_pattern_tags_returns_multiple_tags PASSED [ 17%]
tests/core/test_llm_observability.py::TestLLMEvent::test_llmevent_has_all_required_fields PASSED [ 17%]
tests/core/test_llm_observability.py::TestLLMEvent::test_llmevent_allows_optional_fields_none PASSED [ 17%]
tests/core/test_llm_observability.py::TestLogLLMEvent::test_log_llm_event_creates_valid_event PASSED [ 17%]
tests/core/test_llm_observability.py::TestLogLLMEvent::test_log_llm_event_sanitizes_query PASSED [ 17%]
tests/core/test_llm_observability.py::TestLogLLMEvent::test_log_llm_event_with_error PASSED [ 17%]
tests/core/test_mapper.py::TestColumnMapper::test_mapper_initialization_with_config FAILED [ 17%]
tests/core/test_mapper.py::TestColumnMapper::test_get_default_predictors_returns_list FAILED [ 17%]
tests/core/test_mapper.py::TestColumnMapper::test_get_categorical_variables_returns_list FAILED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_get_default_outcome_returns_non_empty_string FAILED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_get_default_filters_returns_dict FAILED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_apply_outcome_transformations PASSED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_map_to_unified_cohort PASSED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_apply_filters PASSED   [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_apply_filters_with_different_types PASSED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_apply_filters_range PASSED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_apply_filters_in PASSED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_apply_filters_exists PASSED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_apply_aggregations PASSED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_apply_aggregations_all_methods PASSED [ 18%]
tests/core/test_mapper.py::TestColumnMapper::test_get_time_zero_value PASSED [ 19%]
tests/core/test_mapper.py::TestColumnMapper::test_get_default_outcome_label PASSED [ 19%]
tests/core/test_mapper.py::TestColumnMapper::test_idempotency PASSED     [ 19%]
tests/core/test_mapper.py::TestValueMappingDataQuality::test_unmapped_values_raise_data_quality_error PASSED [ 19%]
tests/core/test_mapper.py::TestValueMappingDataQuality::test_all_mapped_values_no_error PASSED [ 19%]
tests/core/test_mapper.py::TestValueMappingDataQuality::test_null_values_allowed_no_error PASSED [ 19%]
tests/core/test_mapper.py::TestConfigLoading::test_load_dataset_config_returns_valid_dict SKIPPED [ 19%]
tests/core/test_mapper.py::TestConfigLoading::test_load_nonexistent_config_raises_keyerror PASSED [ 19%]
tests/core/test_mapper.py::TestConfigLoading::test_get_global_config_returns_dict PASSED [ 19%]
tests/core/test_mock_llm_fixture.py::test_mock_llm_calls_fixture_mocks_parse_feature PASSED [ 19%]
tests/core/test_mock_llm_fixture.py::test_mock_llm_calls_fixture_mocks_filter_extraction_feature PASSED [ 19%]
tests/core/test_mock_llm_fixture.py::test_mock_llm_calls_fixture_mocks_followups_feature PASSED [ 19%]
tests/core/test_mock_llm_fixture.py::test_mock_llm_calls_fixture_mocks_result_interpretation_feature PASSED [ 20%]
tests/core/test_mock_llm_fixture.py::test_mock_llm_calls_fixture_mocks_error_translation_feature PASSED [ 20%]
tests/core/test_mock_llm_fixture.py::test_mock_llm_calls_fixture_returns_fast PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassification::test_bridge_detection_on_many_to_many_fixture PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassification::test_byte_estimates_within_sane_range PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassification::test_grain_key_detection_is_deterministic PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassification::test_grain_level_detection PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassification::test_time_column_detection PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassification::test_classification_rules PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassification::test_null_rate_calculation PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassificationEdgeCases::test_empty_dataframe PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassificationEdgeCases::test_single_row_dataframe PASSED [ 20%]
tests/core/test_multi_table_handler.py::TestTableClassificationEdgeCases::test_all_nulls_grain_key PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestPerformanceOptimizations::test_grain_key_fallback_prefers_patient_over_event PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestPerformanceOptimizations::test_id_pattern_does_not_match_false_positives PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestPerformanceOptimizations::test_classification_uses_sampled_helpers_only PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestPerformanceOptimizations::test_classification_1m_rows_completes_within_3_seconds PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestAnchorSelection::test_never_anchors_on_event_fact_bridge PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestAnchorSelection::test_same_input_graph_yields_same_anchor PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestAnchorSelection::test_prefers_lower_null_rate_and_smaller_bytes_on_ties PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestAnchorSelection::test_hard_exclusions_no_unique_grain PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestAnchorSelection::test_hard_exclusions_high_null_rate PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestDimensionMart::test_mart_rowcount_equals_anchor_unique_grain_count PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestDimensionMart::test_no_joins_where_rhs_key_is_non_unique PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestFactAggregation::test_policy_violations_raise_errors_not_warnings PASSED [ 21%]
tests/core/test_multi_table_handler.py::TestFactAggregation::test_default_policy_is_safe_no_mean_on_codes PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestFactAggregation::test_opt_in_mean_works_on_non_code_columns PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestFactAggregation::test_aggregated_features_use_lazy_frames PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestFactAggregation::test_feature_tables_have_correct_schema PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestFactAggregation::test_feature_tables_exclude_dimension_and_bridge_tables PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestBuildUnifiedCohort::test_build_unified_cohort_does_not_use_legacy_duckdb_join PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestBuildUnifiedCohort::test_feature_joins_preserve_row_count PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestBuildUnifiedCohort::test_lazy_join_validate_1_1_fails_on_duplicates PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestBuildUnifiedCohort::test_build_unified_cohort_deterministic_columns PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestBuildUnifiedCohort::test_build_unified_cohort_rejects_invalid_join_type PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestBuildUnifiedCohort::test_build_unified_cohort_accepts_case_insensitive_join_type PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestMaterializeMart::test_materialize_mart_writes_parquet PASSED [ 22%]
tests/core/test_multi_table_handler.py::TestMaterializeMart::test_materialize_mart_caching_works PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestMaterializeMart::test_materialize_mart_rowcount_matches_build_unified_cohort PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestMaterializeMart::test_materialize_mart_patient_level_single_file PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestMaterializeMart::test_dataset_fingerprint_changes_when_data_changes PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestMaterializeMart::test_ibis_connection_is_cached PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestMaterializeMart::test_bucket_column_dropped_from_planned_table PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestMaterializeMart::test_schema_version_used_in_run_id PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestPlanMart::test_plan_mart_returns_lazy_ibis_expression PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestPlanMart::test_plan_mart_compiles_to_sql_without_executing PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestPlanMart::test_plan_mart_materialized_parquet_readable PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestPlanMart::test_plan_mart_uses_duckdb_backend PASSED [ 23%]
tests/core/test_multi_table_handler.py::TestPlanMart::test_plan_mart_handles_partitioned_directories PASSED [ 23%]
tests/core/test_nl_query_config.py::test_config_constants_are_defined PASSED [ 24%]
tests/core/test_nl_query_config.py::test_auto_execute_threshold_matches_semantic_threshold PASSED [ 24%]
tests/core/test_nl_query_config.py::test_feature_flags_default_to_true PASSED [ 24%]
tests/core/test_nl_query_config.py::test_feature_flags_respect_env_vars PASSED [ 24%]
tests/core/test_nl_query_engine_average_pattern.py::TestAveragePatternDetection::test_average_bmi_pattern_detected PASSED [ 24%]
tests/core/test_nl_query_engine_average_pattern.py::TestAveragePatternDetection::test_average_ldl_pattern_detected PASSED [ 24%]
tests/core/test_nl_query_engine_average_pattern.py::TestAveragePatternDetection::test_mean_pattern_works PASSED [ 24%]
tests/core/test_nl_query_engine_average_pattern.py::TestAveragePatternDetection::test_avg_pattern_works PASSED [ 24%]
tests/core/test_nl_query_engine_average_pattern.py::TestAveragePatternDetection::test_average_pattern_without_variable_match_still_returns_describe PASSED [ 24%]
tests/core/test_nl_query_engine_average_pattern.py::TestAveragePatternDetection::test_average_pattern_handles_various_phrasings PASSED [ 24%]
tests/core/test_nl_query_engine_binary_prioritization.py::TestBinaryColumnPrioritization::test_binary_column_prioritized_over_multi_value_for_on_query PASSED [ 24%]
tests/core/test_nl_query_engine_binary_prioritization.py::TestBinaryColumnPrioritization::test_prioritization_works_for_any_medication_type PASSED [ 24%]
tests/core/test_nl_query_engine_binary_prioritization.py::TestBinaryColumnPrioritization::test_prioritization_detects_binary_by_pattern_not_hardcoding PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_query_intent_tracks_successful_tier PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_query_intent_tracks_all_parsing_attempts PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_query_intent_includes_failure_reason PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_query_intent_validates_intent_type PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_query_intent_accepts_valid_intent_types PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_existing_queries_still_parse_correctly PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_pattern_match_which_x_had_lowest_y PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_pattern_match_which_x_had_highest_y PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_parse_query_populates_parsing_tier PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_parse_query_tracks_parsing_attempts PASSED [ 25%]
tests/core/test_nl_query_engine_diagnostics.py::test_parse_query_sets_failure_reason_on_failure PASSED [ 25%]
tests/core/test_nl_query_engine_e2e_dexa_query.py::test_e2e_dexa_query_which_regimen_lowest_viral_load PASSED [ 26%]
tests/core/test_nl_query_engine_e2e_dexa_query.py::test_e2e_dexa_query_to_analysis_context PASSED [ 26%]
tests/core/test_nl_query_engine_e2e_dexa_query.py::test_e2e_dexa_query_logging_throughout_process PASSED [ 26%]
tests/core/test_nl_query_engine_e2e_dexa_query.py::test_e2e_dexa_query_variable_matching_accuracy PASSED [ 26%]
tests/core/test_nl_query_engine_e2e_dexa_query.py::test_e2e_dexa_query_execution_readiness PASSED [ 26%]
tests/core/test_nl_query_engine_error_messages.py::test_error_message_shows_parsing_attempts PASSED [ 26%]
tests/core/test_nl_query_engine_error_messages.py::test_error_message_includes_suggestions PASSED [ 26%]
tests/core/test_nl_query_engine_error_messages.py::test_suggestions_use_semantic_layer_metadata PASSED [ 26%]
tests/core/test_nl_query_engine_filter_deduplication.py::TestFilterDeduplication::test_deduplication_removes_identical_filters PASSED [ 26%]
tests/core/test_nl_query_engine_filter_deduplication.py::TestFilterDeduplication::test_deduplication_handles_list_values PASSED [ 26%]
tests/core/test_nl_query_engine_filter_deduplication.py::TestFilterDeduplication::test_deduplication_is_generic_works_for_any_column PASSED [ 26%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionStopsAtContinuationWords::test_filter_extraction_stops_at_and PASSED [ 26%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionStopsAtContinuationWords::test_filter_extraction_stops_at_which PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionStopsAtContinuationWords::test_filter_extraction_stops_at_or PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionStopsAtContinuationWords::test_filter_extraction_correctly_extracts_single_filter PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestCodedColumnDetection::test_is_coded_column_uses_metadata_when_available PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestCodedColumnDetection::test_is_coded_column_detects_code_pattern_in_alias PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestCodedColumnDetection::test_is_coded_column_detects_multiple_codes PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestCodedColumnDetection::test_is_coded_column_detects_coded_indicators PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestCodedColumnDetection::test_is_coded_column_looks_up_alias_when_not_provided PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionTypeSafety::test_filter_extraction_extracts_numeric_codes_not_strings_for_coded_columns PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionTypeSafety::test_filter_extraction_uses_in_operator_for_multiple_codes PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionTypeSafety::test_filter_extraction_binary_yes_no_extracts_single_code PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterApplicationTypeSafety::test_apply_filters_handles_type_mismatch_gracefully PASSED [ 27%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterApplicationTypeSafety::test_apply_filters_applies_numeric_filter_correctly PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterApplicationTypeSafety::test_apply_filters_applies_in_operator_with_numeric_codes PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionStrategy1ToStrategy2Handoff::test_strategy1_passes_coded_column_to_strategy2 FAILED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionStrategy1ToStrategy2Handoff::test_strategy1_to_strategy2_handoff_prevents_missing_filters PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionStrategy1ToStrategy2Handoff::test_strategy1_handles_full_alias_string_as_column_name PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_exclude_variant_creates_exclusion_filter PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_remove_pattern_creates_exclusion_filter PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_exclude_na_value_maps_to_code_zero PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_exclusion_filter_excludes_code_zero PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_exclusion_with_most_query PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_exclusion_filter_works_for_any_medication_type FAILED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_exclusion_filter_works_for_any_coded_column FAILED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_dont_want_pattern_with_context_creates_exclusion_filter PASSED [ 28%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_dont_want_zero_with_context_creates_exclusion_filter PASSED [ 29%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_do_not_want_na_creates_exclusion_filter PASSED [ 29%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_dont_want_with_grouping_variable_uses_context PASSED [ 29%]
tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_dont_want_strips_the_prefix_from_value PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_broken_down_by_per_pattern PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_broken_down_by_simple_pattern PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_per_pattern PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_by_pattern PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_which_pattern_still_works PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_which_pattern_with_domain_specific_terms PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_which_pattern_with_and PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_returns_none_when_no_match PASSED [ 29%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_prioritizes_broken_down_over_which PASSED [ 30%]
tests/core/test_nl_query_engine_grouping.py::TestGroupingExtractionFromCompoundQueries::test_extract_grouping_uses_partial_match_when_fuzzy_fails PASSED [ 30%]
tests/core/test_nl_query_engine_most_query.py::TestMostQueryPatternDetection::test_which_most_pattern_detected_as_count PASSED [ 30%]
tests/core/test_nl_query_engine_most_query.py::TestMostQueryPatternDetection::test_most_pattern_works_for_any_domain PASSED [ 30%]
tests/core/test_nl_query_engine_most_query.py::TestMostQueryPatternDetection::test_most_query_extracts_grouping_variable PASSED [ 30%]
tests/core/test_nl_query_engine_pattern_fallback.py::test_parse_query_preserves_pattern_match_below_threshold PASSED [ 30%]
tests/core/test_nl_query_engine_pattern_fallback.py::test_parse_query_uses_semantic_if_better_than_pattern PASSED [ 30%]
tests/core/test_nl_query_engine_pattern_fallback.py::test_parse_query_pattern_below_threshold_vs_semantic_describe PASSED [ 30%]
tests/core/test_nl_query_engine_pattern_fallback.py::test_parse_query_logs_partial_pattern_match PASSED [ 30%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldCorrelationQueries::test_correlation_query_parsing[bmi_statin_regimen_cd4_relationship] PASSED [ 30%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldCountQueries::test_count_query_parsing[count_patients_on_statins] PASSED [ 30%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldCountQueries::test_count_query_parsing[most_prescribed_statin] PASSED [ 30%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldCountQueries::test_count_query_parsing[most_common_hiv_regiment] PASSED [ 31%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldCountQueries::test_count_query_parsing[most_common_current_regimen] PASSED [ 31%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldCountQueries::test_count_query_with_filter_parsing PASSED [ 31%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldCountQueries::test_complex_count_breakdown_parsing PASSED [ 31%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldDescribeQueries::test_average_query_parsing[average BMI of patients-BMI] PASSED [ 31%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldDescribeQueries::test_average_query_parsing[average ldl of all patients-LDL mg/dL] PASSED [ 31%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldQueryTracking::test_all_count_queries_from_fixture PASSED [ 31%]
tests/core/test_nl_query_engine_real_world_queries.py::TestRealWorldQueryTracking::test_all_describe_queries_from_fixture PASSED [ 31%]
tests/core/test_nl_query_engine_self_improvement.py::TestPromptOverlayPath::test_overlay_path_defaults_to_tmp_directory PASSED [ 31%]
tests/core/test_nl_query_engine_self_improvement.py::TestPromptOverlayPath::test_overlay_path_respects_env_var_override PASSED [ 31%]
tests/core/test_nl_query_engine_self_improvement.py::TestPromptOverlayCaching::test_overlay_cache_initializes_to_empty PASSED [ 31%]
tests/core/test_nl_query_engine_self_improvement.py::TestPromptOverlayCaching::test_load_overlay_returns_empty_when_file_missing PASSED [ 31%]
tests/core/test_nl_query_engine_self_improvement.py::TestPromptOverlayCaching::test_load_overlay_reads_file_content PASSED [ 32%]
tests/core/test_nl_query_engine_self_improvement.py::TestPromptOverlayCaching::test_load_overlay_uses_cache_when_file_unchanged PASSED [ 32%]
tests/core/test_nl_query_engine_self_improvement.py::TestPromptOverlayCaching::test_load_overlay_reloads_when_file_modified PASSED [ 32%]
tests/core/test_nl_query_engine_self_improvement.py::TestStableHash::test_stable_hash_returns_deterministic_output PASSED [ 32%]
tests/core/test_nl_query_engine_self_improvement.py::TestStableHash::test_stable_hash_differs_for_different_inputs PASSED [ 32%]
tests/core/test_nl_query_engine_self_improvement.py::TestStableHash::test_stable_hash_is_not_pythons_builtin_hash PASSED [ 32%]
tests/core/test_nl_query_engine_variable_extraction.py::test_pattern_match_extracts_variables_when_fuzzy_match_fails PASSED [ 32%]
tests/core/test_nl_query_engine_variable_extraction.py::test_parse_query_extracts_variables_for_compare_groups PASSED [ 32%]
tests/core/test_nl_query_engine_variable_extraction.py::test_parse_query_extracts_variables_when_pattern_match_partial PASSED [ 32%]
tests/core/test_nl_query_engine_variable_extraction.py::test_parse_query_extracts_variables_for_find_predictors PASSED [ 32%]
tests/core/test_nl_query_engine_variable_extraction.py::test_parse_query_extracts_variables_for_correlations PASSED [ 32%]
tests/core/test_nl_query_engine_variable_extraction.py::test_variable_extraction_logs_when_variables_found PASSED [ 32%]
tests/core/test_nl_query_engine_variable_extraction.py::test_pattern_match_returns_compare_groups_even_without_variable_match PASSED [ 33%]
tests/core/test_nl_query_llm_constrained.py::TestLLMQueryPlanSchema::test_llm_prompt_specifies_queryplan_schema PASSED [ 33%]
tests/core/test_nl_query_llm_constrained.py::TestLLMQueryPlanSchema::test_llm_response_parses_to_queryplan_compatible_dict PASSED [ 33%]
tests/core/test_nl_query_llm_constrained.py::TestLLMQueryPlanSchema::test_llm_rejects_invalid_intent_type PASSED [ 33%]
tests/core/test_nl_query_llm_constrained.py::TestLLMQueryPlanSchema::test_llm_rejects_malformed_json PASSED [ 33%]
tests/core/test_nl_query_llm_constrained.py::TestLLMQueryPlanSchema::test_llm_rejects_missing_required_fields PASSED [ 33%]
tests/core/test_nl_query_llm_constrained.py::TestLLMQueryPlanSchema::test_llm_rejects_nested_query_object_structure PASSED [ 33%]
tests/core/test_nl_query_llm_constrained.py::TestLLMConstrainedOutput::test_llm_fallback_returns_valid_queryplan_compatible_dict PASSED [ 33%]
tests/core/test_nl_query_llm_constrained.py::TestLLMConstrainedOutput::test_confidence_clamped_to_valid_range PASSED [ 33%]
tests/core/test_nl_query_refinement.py::test_parse_query_with_refinement_context_adds_filter PASSED [ 33%]
tests/core/test_nl_query_refinement.py::test_parse_query_refinement_without_context_has_low_confidence PASSED [ 33%]
tests/core/test_nl_query_refinement.py::test_parse_query_refinement_merges_with_existing_filters FAILED [ 33%]
tests/core/test_nl_query_refinement.py::test_parse_query_refinement_updates_same_column_filter FAILED [ 34%]
tests/core/test_nl_query_refinement.py::test_parse_query_non_refinement_with_history_works_normally PASSED [ 34%]
tests/core/test_nl_query_refinement.py::test_parse_query_backward_compatible_without_history PASSED [ 34%]
tests/core/test_nl_query_refinement.py::test_llm_recognizes_refinement_patterns[remove the n/a-previous] PASSED [ 34%]
tests/core/test_nl_query_refinement.py::test_llm_recognizes_refinement_patterns[exclude missing values-previous] PASSED [ 34%]
tests/core/test_nl_query_refinement.py::test_llm_recognizes_refinement_patterns[get rid of zeros-previous] PASSED [ 34%]
tests/core/test_nl_query_refinement.py::test_llm_recognizes_refinement_patterns[without unknowns-previous] PASSED [ 34%]
tests/core/test_nl_query_refinement.py::test_llm_recognizes_refinement_patterns[only active patients-previous] PASSED [ 34%]
tests/core/test_nl_query_refinement.py::test_llm_recognizes_refinement_patterns[also exclude pediatric-previous] PASSED [ 34%]
tests/core/test_nl_query_refinement.py::test_llm_refinement_with_coded_categorical_column FAILED [ 34%]
tests/core/test_nl_query_refinement.py::test_llm_provides_explanation_for_refinement FAILED [ 34%]
tests/core/test_nl_query_refinement.py::test_parse_query_refinement_handles_llm_failure_with_fallback FAILED [ 34%]
tests/core/test_nl_query_type_aware.py::TestTypeAwareIntentSelection::test_categorical_grouping_triggers_count_intent PASSED [ 35%]
tests/core/test_nl_query_type_aware.py::TestTypeAwareIntentSelection::test_numeric_metric_triggers_describe_intent PASSED [ 35%]
tests/core/test_nl_query_type_aware.py::TestTypeAwareIntentSelection::test_numeric_grouping_categorical_metric_triggers_compare PASSED [ 35%]
tests/core/test_nl_query_type_aware.py::TestGroupingVariableValidation::test_numeric_grouping_variable_handled_appropriately PASSED [ 35%]
tests/core/test_nl_query_type_aware.py::TestGroupingVariableValidation::test_categorical_grouping_variable_accepted PASSED [ 35%]
tests/core/test_nl_query_type_aware.py::TestTypeAwareCodedColumnHandling::test_coded_categorical_triggers_count_with_filter PASSED [ 35%]
tests/core/test_normalize_query.py::TestQueryNormalization::test_normalize_query_empty_string_returns_empty PASSED [ 35%]
tests/core/test_normalize_query.py::TestQueryNormalization::test_normalize_query_whitespace_only_returns_empty PASSED [ 35%]
tests/core/test_normalize_query.py::TestQueryNormalization::test_normalize_query_none_returns_empty PASSED [ 35%]
tests/core/test_normalize_query.py::TestQueryNormalization::test_normalize_query_collapses_whitespace PASSED [ 35%]
tests/core/test_normalize_query.py::TestQueryNormalization::test_normalize_query_lowercases_text PASSED [ 35%]
tests/core/test_normalize_query.py::TestQueryNormalization::test_normalize_query_strips_leading_trailing_whitespace PASSED [ 35%]
tests/core/test_ollama_manager_integration.py::test_ollama_manager_singleton PASSED [ 35%]
tests/core/test_ollama_manager_integration.py::test_ollama_manager_status SKIPPED [ 36%]
tests/core/test_ollama_manager_integration.py::test_ollama_manager_service_detection SKIPPED [ 36%]
tests/core/test_ollama_manager_integration.py::test_ollama_manager_model_detection PASSED [ 36%]
tests/core/test_ollama_manager_integration.py::test_ollama_manager_get_client PASSED [ 36%]
tests/core/test_ollama_manager_integration.py::test_ollama_manager_setup_instructions PASSED [ 36%]
tests/core/test_ollama_manager_integration.py::test_ollama_manager_end_to_end PASSED [ 36%]
tests/core/test_profiling.py::TestDataProfiler::test_profiler_initialization_pandas PASSED [ 36%]
tests/core/test_profiling.py::TestDataProfiler::test_profiler_initialization_polars PASSED [ 36%]
tests/core/test_profiling.py::TestDataProfiler::test_generate_profile PASSED [ 36%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_overview PASSED [ 36%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_missing_data PASSED [ 36%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_missing_data_no_missing PASSED [ 36%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_numeric_features PASSED [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_numeric_features_empty PASSED [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_categorical_features PASSED [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_categorical_features_empty PASSED [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_data_quality PASSED [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_calculate_quality_score PASSED [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_to_dict PASSED      [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_to_html PASSED      [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_with_duplicates PASSED [ 37%]
tests/core/test_profiling.py::TestDataProfiler::test_profile_with_constant_columns PASSED [ 37%]
tests/core/test_prompt_optimizer.py::test_learning_config_load_with_valid_config_returns_config PASSED [ 37%]
tests/core/test_prompt_optimizer.py::test_learning_config_load_with_missing_file_returns_empty_config PASSED [ 37%]
tests/core/test_prompt_optimizer.py::test_optimizer_analyze_failures_with_invalid_intent_detects_pattern FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_analyze_failures_with_refinement_failures_detects_pattern FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_analyze_failures_with_all_passing_returns_empty_list FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_generate_fix_from_template_replaces_placeholders FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_generate_prompt_additions_with_patterns_returns_text FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_generate_prompt_additions_with_no_patterns_returns_empty FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_get_keyword_hints_with_matching_keyword_returns_intent FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_get_keyword_hints_with_no_match_returns_none FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_is_refinement_query_with_refinement_phrase_returns_true FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_is_refinement_query_with_no_phrase_returns_false FAILED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_log_iteration_creates_log_file PASSED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_log_iteration_with_logging_disabled_creates_no_file PASSED [ 38%]
tests/core/test_prompt_optimizer.py::test_optimizer_evaluate_condition_with_valid_condition_returns_true FAILED [ 39%]
tests/core/test_prompt_optimizer.py::test_optimizer_evaluate_condition_with_invalid_condition_returns_false FAILED [ 39%]
tests/core/test_prompt_optimizer.py::test_optimizer_full_workflow_analyzes_and_generates_fixes PASSED [ 39%]
tests/core/test_prompt_optimizer.py::test_optimizer_analyze_failures_with_none_intent_filters_none_values FAILED [ 39%]
tests/core/test_queryplan_contract.py::TestQueryPlanContractEnforcement::test_execute_query_plan_logs_execution_start PASSED [ 39%]
tests/core/test_queryplan_contract.py::TestQueryPlanContractEnforcement::test_execute_query_plan_validates_plan_type PASSED [ 39%]
tests/core/test_queryplan_contract.py::TestQueryPlanContractEnforcement::test_execute_query_plan_validates_plan_intent PASSED [ 39%]
tests/core/test_queryplan_contract.py::TestQueryPlanContractEnforcement::test_execute_query_plan_returns_standardized_result PASSED [ 39%]
tests/core/test_queryplan_contract.py::TestQueryPlanContractEnforcement::test_execute_query_plan_generates_deterministic_run_key PASSED [ 39%]
tests/core/test_queryplan_contract.py::TestQueryPlanContractEnforcement::test_execute_query_plan_different_run_key_for_different_plans PASSED [ 39%]
tests/core/test_queryplan_contract.py::TestQueryPlanContractEnforcement::test_execute_query_plan_uses_retry_logic PASSED [ 39%]
tests/core/test_queryplan_conversion.py::TestQueryPlanConversion::test_intent_to_plan_creates_queryplan_without_run_key PASSED [ 39%]
tests/core/test_queryplan_conversion.py::TestQueryPlanConversion::test_intent_to_plan_does_not_set_run_key PASSED [ 40%]
tests/core/test_queryplan_conversion.py::TestQueryPlanConversion::test_intent_to_plan_preserves_filters_without_run_key PASSED [ 40%]
tests/core/test_queryplan_conversion.py::TestQueryPlanConversion::test_intent_to_plan_preserves_all_intent_fields PASSED [ 40%]
tests/core/test_queryplan_conversion.py::TestAnalysisContextQueryPlan::test_analysiscontext_has_query_plan_field PASSED [ 40%]
tests/core/test_queryplan_conversion.py::TestAnalysisContextQueryPlan::test_queryplan_can_be_assigned_to_analysiscontext PASSED [ 40%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_with_follow_ups_creates_successfully PASSED [ 40%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_without_follow_ups_defaults_to_empty PASSED [ 40%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_from_dict_with_follow_ups_preserves_fields PASSED [ 40%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_from_dict_without_follow_ups_uses_defaults PASSED [ 40%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_from_dict_with_empty_follow_ups_preserves_empty_list PASSED [ 40%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_follow_ups_accepts_single_question PASSED [ 40%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_follow_ups_accepts_multiple_questions PASSED [ 40%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_follow_up_explanation_accepts_long_text PASSED [ 41%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_follow_ups_preserves_order PASSED [ 41%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_with_follow_ups_serializes_to_dict PASSED [ 41%]
tests/core/test_queryplan_followups.py::TestQueryPlanFollowUpsSchema::test_queryplan_from_dict_roundtrip_preserves_follow_ups PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_with_interpretation_creates_successfully PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_without_interpretation_defaults_to_empty PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_from_dict_with_interpretation_preserves_fields PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_from_dict_without_interpretation_uses_defaults PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_from_dict_with_empty_interpretation_preserves_empty PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_interpretation_accepts_long_text PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_with_interpretation_serializes_to_dict PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_from_dict_roundtrip_preserves_interpretation PASSED [ 41%]
tests/core/test_queryplan_interpretation.py::TestQueryPlanInterpretationSchema::test_queryplan_with_both_follow_ups_and_interpretation PASSED [ 42%]
tests/core/test_queryplan_only_path.py::TestQueryPlanOnlyPath::test_semantic_layer_execute_requires_queryplan PASSED [ 42%]
tests/core/test_queryplan_only_path.py::TestQueryPlanOnlyPath::test_execute_query_plan_accepts_only_queryplan_type PASSED [ 42%]
tests/core/test_queryplan_only_path.py::TestQueryPlanOnlyPath::test_no_direct_compute_analysis_by_type_calls_in_ui PASSED [ 42%]
tests/core/test_queryplan_only_path.py::TestQueryPlanOnlyPath::test_no_direct_get_or_compute_result_calls_in_ui PASSED [ 42%]
tests/core/test_queryplan_only_path.py::TestQueryPlanOnlyPath::test_all_execution_paths_use_semantic_layer_execute_query_plan PASSED [ 42%]
tests/core/test_queryplan_only_path.py::TestQueryPlanOnlyPath::test_chat_handler_should_not_execute_query PASSED [ 42%]
tests/core/test_queryplan_only_path.py::TestQueryPlanOnlyPath::test_format_execution_result_should_not_reanalyze_result_dataframe PASSED [ 42%]
tests/core/test_queryplan_only_path.py::TestQueryPlanOnlyPath::test_format_execution_result_formats_count_result_correctly PASSED [ 42%]
tests/core/test_queryplan_validation.py::TestQueryPlanFromDict::test_from_dict_creates_valid_queryplan PASSED [ 42%]
tests/core/test_queryplan_validation.py::TestQueryPlanFromDict::test_from_dict_rejects_invalid_intent PASSED [ 42%]
tests/core/test_queryplan_validation.py::TestQueryPlanFromDict::test_from_dict_rejects_missing_intent PASSED [ 42%]
tests/core/test_queryplan_validation.py::TestQueryPlanFromDict::test_from_dict_applies_defaults_for_optional_fields PASSED [ 42%]
tests/core/test_queryplan_validation.py::TestQueryPlanFromDict::test_from_dict_validates_confidence_range PASSED [ 43%]
tests/core/test_queryplan_validation.py::TestQueryPlanValidateIntent::test_queryplan_accepts_valid_intents PASSED [ 43%]
tests/core/test_queryplan_validation.py::TestQueryPlanValidateIntent::test_queryplan_rejects_invalid_intents PASSED [ 43%]
tests/core/test_queryplan_validation.py::TestQueryPlanFilterSpecValidation::test_queryplan_accepts_valid_filterspec PASSED [ 43%]
tests/core/test_queryplan_validation.py::TestQueryPlanFilterSpecValidation::test_filterspec_validates_operator PASSED [ 43%]
tests/core/test_queryplan_validation.py::TestQueryPlanFilterSpecValidation::test_filterspec_rejects_invalid_operator PASSED [ 43%]
tests/core/test_queryplan_validation.py::TestQueryPlanScopeValidation::test_queryplan_accepts_valid_scopes PASSED [ 43%]
tests/core/test_queryplan_validation.py::TestQueryPlanScopeValidation::test_queryplan_defaults_scope_to_all PASSED [ 43%]
tests/core/test_registry.py::TestDatasetRegistry::test_discover_datasets_returns_non_empty_dict PASSED [ 43%]
tests/core/test_registry.py::TestDatasetRegistry::test_list_datasets_returns_non_empty_list PASSED [ 43%]
tests/core/test_registry.py::TestDatasetRegistry::test_get_dataset_info_returns_metadata_dict PASSED [ 43%]
tests/core/test_registry.py::TestDatasetRegistry::test_get_dataset_factory_creates_instance FAILED [ 43%]
tests/core/test_registry.py::TestDatasetRegistry::test_get_all_dataset_info_returns_dict_with_metadata PASSED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_reset_clears_registry_state PASSED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_get_nonexistent_dataset_raises_keyerror PASSED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_load_config_sets_config_loaded_flag PASSED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_load_config_nonexistent_file_sets_empty_config PASSED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_register_from_dataframe_creates_config PASSED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_get_auto_inferred_dataframe_retrieves_stored_data PASSED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_get_auto_inferred_dataframe_nonexistent_returns_none PASSED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_get_dataset_with_override_params_applies_overrides FAILED [ 44%]
tests/core/test_registry.py::TestDatasetRegistry::test_registry_filters_unsupported_params_without_error FAILED [ 44%]
tests/core/test_relationship_detector.py::TestPrimaryKeyDetection::test_detect_primary_key_with_id_column_returns_id PASSED [ 44%]
tests/core/test_relationship_detector.py::TestPrimaryKeyDetection::test_detect_primary_key_with_patient_id_column_returns_patient_id PASSED [ 44%]
tests/core/test_relationship_detector.py::TestPrimaryKeyDetection::test_detect_primary_key_with_duplicates_returns_none PASSED [ 45%]
tests/core/test_relationship_detector.py::TestPrimaryKeyDetection::test_detect_primary_key_with_nulls_returns_none PASSED [ 45%]
tests/core/test_relationship_detector.py::TestForeignKeyCandidateDetection::test_is_foreign_key_candidate_exact_match_returns_true PASSED [ 45%]
tests/core/test_relationship_detector.py::TestForeignKeyCandidateDetection::test_is_foreign_key_candidate_with_fk_prefix_returns_true PASSED [ 45%]
tests/core/test_relationship_detector.py::TestForeignKeyCandidateDetection::test_is_foreign_key_candidate_case_insensitive_returns_true PASSED [ 45%]
tests/core/test_relationship_detector.py::TestForeignKeyCandidateDetection::test_is_foreign_key_candidate_different_names_returns_false PASSED [ 45%]
tests/core/test_relationship_detector.py::TestReferentialIntegrityVerification::test_verify_referential_integrity_full_match_returns_one PASSED [ 45%]
tests/core/test_relationship_detector.py::TestReferentialIntegrityVerification::test_verify_referential_integrity_partial_match_returns_ratio PASSED [ 45%]
tests/core/test_relationship_detector.py::TestReferentialIntegrityVerification::test_verify_referential_integrity_no_match_returns_zero PASSED [ 45%]
tests/core/test_relationship_detector.py::TestReferentialIntegrityVerification::test_verify_referential_integrity_handles_nulls PASSED [ 45%]
tests/core/test_relationship_detector.py::TestReferentialIntegrityVerification::test_verify_referential_integrity_handles_type_mismatch PASSED [ 45%]
tests/core/test_relationship_detector.py::TestRelationshipDetection::test_detect_relationships_finds_one_to_many PASSED [ 45%]
tests/core/test_relationship_detector.py::TestRelationshipDetection::test_detect_relationships_excludes_low_confidence PASSED [ 46%]
tests/core/test_relationship_detector.py::TestRelationshipDetection::test_detect_relationships_returns_sorted_by_confidence PASSED [ 46%]
tests/core/test_result_interpretation.py::TestInterpretResultWithLLM::test_interpret_result_returns_interpretation_on_success PASSED [ 46%]
tests/core/test_result_interpretation.py::TestInterpretResultWithLLM::test_interpret_result_returns_none_on_llm_failure PASSED [ 46%]
tests/core/test_result_interpretation.py::TestInterpretResultWithLLM::test_interpret_result_returns_none_on_malformed_json PASSED [ 46%]
tests/core/test_result_interpretation.py::TestInterpretResultWithLLM::test_interpret_result_returns_none_on_missing_interpretation_field PASSED [ 46%]
tests/core/test_result_interpretation.py::TestInterpretResultWithLLM::test_interpret_result_uses_correct_timeout PASSED [ 46%]
tests/core/test_result_interpretation.py::TestInterpretResultWithLLM::test_interpret_result_sanitizes_large_result_data PASSED [ 46%]
tests/core/test_schema.py::TestUnifiedCohort::test_required_columns PASSED [ 46%]
tests/core/test_schema.py::TestUnifiedCohort::test_column_names PASSED   [ 46%]
tests/core/test_schema.py::TestUnifiedCohort::test_required_columns_list PASSED [ 46%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_valid_cohort_returns_true PASSED [ 46%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_missing_columns_returns_error PASSED [ 47%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_upload_time_only_requires_patient_id PASSED [ 47%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_upload_time_missing_patient_id_returns_error PASSED [ 47%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_null_patient_id_returns_error PASSED [ 47%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_non_numeric_outcome_returns_error PASSED [ 47%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_invalid_binary_outcome_returns_error PASSED [ 47%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_strict_mode_raises_exception PASSED [ 47%]
tests/core/test_schema_validation.py::TestValidateUnifiedCohortSchema::test_schema_validation_extra_columns_still_valid PASSED [ 47%]
tests/core/test_scope_canonicalization.py::TestScopeCanonnicalization::test_scope_canonicalization_handles_nested_dicts PASSED [ 47%]
tests/core/test_scope_canonicalization.py::TestScopeCanonnicalization::test_scope_canonicalization_handles_nested_lists PASSED [ 47%]
tests/core/test_scope_canonicalization.py::TestScopeCanonnicalization::test_scope_canonicalization_drops_none_recursively PASSED [ 47%]
tests/core/test_scope_canonicalization.py::TestScopeCanonnicalization::test_scope_canonicalization_sorts_keys_recursively PASSED [ 47%]
tests/core/test_scope_canonicalization.py::TestScopeCanonnicalization::test_scope_canonicalization_handles_empty_dict PASSED [ 48%]
tests/core/test_scope_canonicalization.py::TestScopeCanonnicalization::test_scope_canonicalization_handles_none PASSED [ 48%]
tests/core/test_security.py::TestValidateTableIdentifier::test_identifier_validation_valid_names_pass PASSED [ 48%]
tests/core/test_security.py::TestValidateTableIdentifier::test_identifier_validation_sql_injection_raises_valueerror PASSED [ 48%]
tests/core/test_security.py::TestValidateTableIdentifier::test_identifier_validation_special_chars_raises_valueerror PASSED [ 48%]
tests/core/test_security.py::TestValidateTableIdentifier::test_identifier_validation_starts_with_number_raises_valueerror PASSED [ 48%]
tests/core/test_security.py::TestValidateTableIdentifier::test_identifier_validation_empty_string_raises_valueerror PASSED [ 48%]
tests/core/test_security.py::TestSafeExtractZipMember::test_zip_extraction_valid_member_extracts_correctly PASSED [ 48%]
tests/core/test_security.py::TestSafeExtractZipMember::test_zip_extraction_path_traversal_raises_securityerror PASSED [ 48%]
tests/core/test_security.py::TestSafeExtractZipMember::test_zip_extraction_absolute_path_raises_securityerror PASSED [ 48%]
tests/core/test_security.py::TestSafeStoreUpload::test_upload_storage_uses_uuid_not_original_filename PASSED [ 48%]
tests/core/test_security.py::TestSafeStoreUpload::test_upload_storage_path_traversal_in_filename_ignored PASSED [ 48%]
tests/core/test_self_improve_nl_parsing.py::TestAtomicOverlayWrite::test_write_overlay_creates_parent_directory PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestAtomicOverlayWrite::test_write_overlay_uses_atomic_replace PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestAtomicOverlayWrite::test_write_overlay_leaves_no_temp_files PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestAtomicOverlayWrite::test_write_overlay_handles_unicode_content PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestOverlaySizeCapping::test_size_capping_keeps_top_five_patterns_by_priority PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestOverlaySizeCapping::test_size_capping_truncates_overlay_at_8kb PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestOverlaySizeCapping::test_size_capping_preserves_content_under_limit PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestGoldenQuestionsRefresh::test_refresh_golden_questions_adds_new_questions_from_logs PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestGoldenQuestionsRefresh::test_refresh_golden_questions_deduplicates_existing_queries PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestGoldenQuestionsRefresh::test_refresh_golden_questions_respects_max_limit PASSED [ 49%]
tests/core/test_self_improve_nl_parsing.py::TestGoldenQuestionsRefresh::test_refresh_golden_questions_handles_empty_log_gracefully PASSED [ 49%]
tests/core/test_semantic_alias_persistence.py::test_add_user_alias_persists_to_metadata PASSED [ 49%]
tests/core/test_semantic_alias_persistence.py::test_load_user_aliases_on_initialization PASSED [ 50%]
tests/core/test_semantic_alias_persistence.py::test_user_aliases_override_system_aliases PASSED [ 50%]
tests/core/test_semantic_alias_persistence.py::test_alias_scope_per_dataset PASSED [ 50%]
tests/core/test_semantic_alias_persistence.py::test_orphaned_alias_handling PASSED [ 50%]
tests/core/test_semantic_alias_persistence.py::test_alias_collision_detection PASSED [ 50%]
tests/core/test_semantic_alias_persistence.py::test_alias_persistence_format PASSED [ 50%]
tests/core/test_semantic_alias_persistence.py::test_alias_normalization_consistency PASSED [ 50%]
tests/core/test_semantic_deterministic_compilation.py::TestDeterministicCompilation::test_same_queryplan_produces_same_sql_multiple_times PASSED [ 50%]
tests/core/test_semantic_deterministic_compilation.py::TestDeterministicCompilation::test_different_queryplans_produce_different_sql PASSED [ 50%]
tests/core/test_semantic_deterministic_compilation.py::TestDeterministicCompilation::test_queryplan_with_filters_compiles_deterministically PASSED [ 50%]
tests/core/test_semantic_deterministic_compilation.py::TestDeterministicCompilation::test_queryplan_with_grouping_compiles_deterministically PASSED [ 50%]
tests/core/test_semantic_deterministic_compilation.py::TestDeterministicCompilation::test_run_key_determinism_for_same_plan PASSED [ 50%]
tests/core/test_semantic_deterministic_compilation.py::TestDeterministicCompilation::test_run_key_different_for_different_filters PASSED [ 50%]
tests/core/test_semantic_deterministic_compilation.py::TestDeterministicCompilation::test_execution_is_testable_no_freeform_code PASSED [ 51%]
tests/core/test_semantic_granularity.py::test_granularity_default_value_is_patient_level PASSED [ 51%]
tests/core/test_semantic_granularity.py::test_build_cohort_query_all_granularity_values_accepted[patient_level] PASSED [ 51%]
tests/core/test_semantic_granularity.py::test_build_cohort_query_all_granularity_values_accepted[admission_level] PASSED [ 51%]
tests/core/test_semantic_granularity.py::test_build_cohort_query_all_granularity_values_accepted[event_level] PASSED [ 51%]
tests/core/test_semantic_granularity.py::test_get_cohort_with_show_sql_uses_logger_info PASSED [ 51%]
tests/core/test_semantic_granularity.py::test_get_cohort_without_granularity_uses_default PASSED [ 51%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_workspace_root_detection_via_pyproject_toml PASSED [ 51%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_workspace_root_detection_via_git PASSED [ 51%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_workspace_root_fallback_to_cwd PASSED [ 51%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_relative_path_resolution PASSED [ 51%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_absolute_path_handling PASSED [ 51%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_missing_file_error_includes_resolved_path PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_directory_source_raises_not_implemented PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_database_table_source PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_workspace_root_from_config PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerPathResolution::test_logging_contains_path_resolution_info PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerGranularity::test_get_cohort_accepts_patient_level_granularity PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerGranularity::test_get_cohort_accepts_all_granularity_values PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerGranularity::test_get_cohort_backward_compatible_no_granularity PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerGranularity::test_build_cohort_query_accepts_granularity_parameter PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerGranularity::test_build_cohort_query_accepts_all_granularity_values PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerGranularity::test_show_sql_logs_sql_instead_of_printing PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerGranularity::test_granularity_passed_to_build_cohort_query PASSED [ 52%]
tests/core/test_semantic_layer.py::TestSemanticLayerSafeIdentifiers::test_safe_identifier_with_hyphens PASSED [ 53%]
tests/core/test_semantic_layer.py::TestSemanticLayerSafeIdentifiers::test_safe_identifier_with_dots PASSED [ 53%]
tests/core/test_semantic_layer.py::TestSemanticLayerSafeIdentifiers::test_safe_identifier_with_spaces PASSED [ 53%]
tests/core/test_semantic_layer.py::TestSemanticLayerSafeIdentifiers::test_safe_identifier_with_emojis PASSED [ 53%]
tests/core/test_semantic_layer.py::TestSemanticLayerSafeIdentifiers::test_safe_identifier_starts_with_number PASSED [ 53%]
tests/core/test_semantic_layer.py::TestSemanticLayerSafeIdentifiers::test_safe_identifier_empty_string PASSED [ 53%]
tests/core/test_semantic_layer.py::TestSemanticLayerSafeIdentifiers::test_safe_identifier_produces_unique_results PASSED [ 53%]
tests/core/test_semantic_layer.py::TestSemanticLayerSafeIdentifiers::test_safe_identifier_used_in_table_registration PASSED [ 53%]
tests/core/test_semantic_observability.py::TestSemanticLayerObservability::test_execute_query_plan_includes_warnings_field PASSED [ 53%]
tests/core/test_semantic_observability.py::TestSemanticLayerObservability::test_execute_query_plan_includes_steps_field PASSED [ 53%]
tests/core/test_semantic_observability.py::TestSemanticLayerObservability::test_low_confidence_adds_warning_with_explanation PASSED [ 53%]
tests/core/test_semantic_observability.py::TestSemanticLayerObservability::test_incomplete_plan_adds_warning_with_explanation PASSED [ 53%]
tests/core/test_semantic_observability.py::TestSemanticLayerObservability::test_validation_failure_adds_warning_with_explanation PASSED [ 54%]
tests/core/test_semantic_observability.py::TestSemanticLayerObservability::test_successful_execution_has_empty_warnings PASSED [ 54%]
tests/core/test_semantic_observability.py::TestSemanticLayerRetryLogic::test_retry_succeeds_after_backend_error PASSED [ 54%]
tests/core/test_semantic_observability.py::TestSemanticLayerRetryLogic::test_retry_succeeds_after_connection_error PASSED [ 54%]
tests/core/test_semantic_observability.py::TestSemanticLayerRetryLogic::test_retry_succeeds_after_transient_error PASSED [ 54%]
tests/core/test_semantic_observability.py::TestSemanticLayerRetryLogic::test_retry_raises_after_max_attempts PASSED [ 54%]
tests/core/test_semantic_observability.py::TestSemanticLayerRetryLogic::test_retry_non_transient_error_no_retry PASSED [ 54%]
tests/core/test_semantic_observability.py::TestSemanticLayerRetryLogic::test_retry_exponential_backoff_timing PASSED [ 54%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_validates_columns_exist PASSED [ 54%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_validates_operators PASSED [ 54%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_validates_type_compatibility PASSED [ 54%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_count_scope_validation PASSED [ 54%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_count_entity_key_validation PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_confidence_gating PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_completeness_gating PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_type_aware_categorical PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_type_aware_numeric PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_count_intent_execution PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_breakdown_validation PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_high_cardinality_detection PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_filter_deduplication PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_run_key_determinism PASSED [ 55%]
tests/core/test_semantic_queryplan_execution.py::test_execute_query_plan_refuses_invalid_plans PASSED [ 55%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_deterministic_for_same_plan_and_query PASSED [ 55%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_different_for_different_queries PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_same_for_whitespace_variations PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_includes_all_plan_fields PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_includes_filters_sorted PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_includes_dataset_version PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_handles_none_query_text PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_different_for_different_intents PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminism::test_run_key_different_for_different_scope PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminismAllExecutionPaths::test_all_execution_paths_produce_same_run_key PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminismAllExecutionPaths::test_query_plan_run_key_always_from_semantic_layer PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminismAllExecutionPaths::test_execute_query_plan_always_generates_run_key PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminismAllExecutionPaths::test_execute_query_plan_run_key_matches_direct_generation PASSED [ 56%]
tests/core/test_semantic_run_key_determinism.py::TestRunKeyDeterminismAllExecutionPaths::test_run_key_deterministic_across_multiple_executions PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_validate_table_identifier_accepts_valid_identifier PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_validate_table_identifier_rejects_sql_injection_attempts PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_validate_table_identifier_rejects_special_characters PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_validate_table_identifier_rejects_empty_string PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_validate_table_identifier_rejects_too_long_identifier PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_validate_table_identifier_accepts_max_length_identifier PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_validate_table_identifier_rejects_starting_with_digit PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_safe_identifier_sanitizes_user_input PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_safe_identifier_handles_collision_prevention PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_safe_identifier_starts_with_letter_or_underscore PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_safe_identifier_enforces_max_length PASSED [ 57%]
tests/core/test_semantic_security.py::TestSQLInjectionMitigation::test_safe_identifier_preserves_readability PASSED [ 57%]
tests/datasets/test_unified_semantic_layer.py::TestUnifiedSemanticLayerRegistration::test_single_table_upload_registers_individual_table PASSED [ 58%]
tests/datasets/test_unified_semantic_layer.py::TestUnifiedSemanticLayerRegistration::test_multi_table_upload_registers_all_tables PASSED [ 58%]
tests/datasets/test_unified_semantic_layer.py::TestUnifiedSemanticLayerRegistration::test_semantic_layer_registration_is_idempotent PASSED [ 58%]
tests/datasets/test_unified_semantic_layer.py::TestGranularityValidation::test_get_cohort_validates_requested_granularity_exists PASSED [ 58%]
tests/datasets/test_unified_semantic_layer.py::TestGranularityValidation::test_get_cohort_supports_all_inferred_granularities PASSED [ 58%]
tests/datasets/test_unified_semantic_layer.py::TestNoConditionalLogic::test_both_upload_types_use_same_registration_code_path PASSED [ 58%]
tests/datasets/test_uploaded_dataset.py::TestBuildConfigFromVariableMapping::test_build_config_from_variable_mapping_with_all_fields_returns_complete_config PASSED [ 58%]
tests/datasets/test_uploaded_dataset.py::TestBuildConfigFromVariableMapping::test_build_config_from_variable_mapping_without_outcome_handles_gracefully PASSED [ 58%]
tests/datasets/test_uploaded_dataset.py::TestBuildConfigFromVariableMapping::test_build_config_from_variable_mapping_detects_categorical_variables PASSED [ 58%]
tests/datasets/test_uploaded_dataset.py::TestBuildConfigFromVariableMapping::test_build_config_from_variable_mapping_infers_outcome_type_from_data PASSED [ 58%]
tests/datasets/test_uploaded_dataset.py::TestBuildConfigFromVariableMapping::test_build_config_from_variable_mapping_time_zero_matches_multi_table_format PASSED [ 58%]
tests/datasets/test_uploaded_dataset.py::TestMaybeInitSemantic::test_maybe_init_semantic_with_variable_mapping_initializes_semantic_layer PASSED [ 58%]
tests/datasets/test_uploaded_dataset.py::TestMaybeInitSemantic::test_maybe_init_semantic_with_inferred_schema_still_works_multi_table PASSED [ 59%]
tests/datasets/test_uploaded_dataset.py::TestMaybeInitSemantic::test_maybe_init_semantic_with_variable_mapping_registers_table_after_migration PASSED [ 59%]
tests/datasets/test_uploaded_dataset.py::TestMaybeInitSemantic::test_maybe_init_semantic_without_schema_or_mapping_raises_valueerror PASSED [ 59%]
tests/datasets/test_uploaded_dataset.py::TestMaybeInitSemantic::test_maybe_init_semantic_sets_init_params_with_absolute_csv_path PASSED [ 59%]
tests/datasets/test_uploaded_dataset_integration.py::TestUploadedDatasetSemanticLayerIntegration::test_single_table_upload_semantic_layer_enables_nl_queries PASSED [ 59%]
tests/datasets/test_uploaded_dataset_integration.py::TestUploadedDatasetSemanticLayerIntegration::test_multi_table_upload_semantic_layer_still_works_regression PASSED [ 59%]
tests/datasets/test_uploaded_dataset_integration.py::TestUploadedDatasetSemanticLayerIntegration::test_semantic_layer_config_structure_matches_expected_format PASSED [ 59%]
tests/datasets/test_uploaded_dataset_integration.py::TestUploadedDatasetSemanticLayerIntegration::test_single_table_semantic_layer_init_params_has_absolute_path PASSED [ 59%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestGetUploadDataLazy::test_get_upload_data_lazy_true_returns_lazy_frame PASSED [ 59%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestGetUploadDataLazy::test_get_upload_data_lazy_false_returns_pandas_dataframe PASSED [ 59%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestGetUploadDataLazy::test_get_upload_data_default_lazy_true PASSED [ 59%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestUploadedDatasetLoadLazy::test_load_stores_lazy_frame PASSED [ 59%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestUploadedDatasetLoadLazy::test_load_with_legacy_pandas_backend PASSED [ 60%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestGetCohortLazyEvaluation::test_get_cohort_with_lazy_frame_returns_pandas PASSED [ 60%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestGetCohortLazyEvaluation::test_get_cohort_applies_filters_before_materialization PASSED [ 60%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestGetCohortLazyEvaluation::test_get_cohort_filters_applied_before_materialization PASSED [ 60%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestGetCohortLazyEvaluation::test_get_cohort_lazy_plan_contains_filter_node PASSED [ 60%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestLazyFrameMigrationCompleteness::test_get_cohort_collects_exactly_once PASSED [ 60%]
tests/datasets/test_uploaded_dataset_lazy_frames.py::TestLazyFrameMigrationCompleteness::test_unified_cohort_created_from_lazy_tables PASSED [ 60%]
tests/e2e/test_ask_questions_full_flow.py::TestE2EFullQueryFlow::test_e2e_nl_query_parses_to_queryplan_with_grouping PASSED [ 60%]
tests/e2e/test_ask_questions_full_flow.py::TestE2EFullQueryFlow::test_e2e_queryplan_run_key_is_none_from_nl_query_engine PASSED [ 60%]
tests/e2e/test_ask_questions_full_flow.py::TestE2EFilterExtraction::test_e2e_filter_extraction_stops_at_continuation_words PASSED [ 60%]
tests/e2e/test_ask_questions_full_flow.py::TestE2EConversationHistory::test_e2e_conversation_history_is_lightweight PASSED [ 60%]
tests/eval/test_golden_questions.py::test_golden_questions_evaluation FAILED [ 60%]
tests/eval/test_golden_questions.py::test_load_golden_questions_yaml PASSED [ 61%]
tests/fixtures/test_cache.py::TestContentBasedHashing::test_hash_dataframe_generates_consistent_hash PASSED [ 61%]
tests/fixtures/test_cache.py::TestContentBasedHashing::test_hash_dataframe_detects_different_data PASSED [ 61%]
tests/fixtures/test_cache.py::TestContentBasedHashing::test_hash_file_generates_consistent_hash PASSED [ 61%]
tests/fixtures/test_cache.py::TestContentBasedHashing::test_hash_file_detects_different_content PASSED [ 61%]
tests/fixtures/test_cache.py::TestDataFrameCaching::test_cache_dataframe_stores_parquet_file PASSED [ 61%]
tests/fixtures/test_cache.py::TestDataFrameCaching::test_get_cached_dataframe_retrieves_parquet_file PASSED [ 61%]
tests/fixtures/test_cache.py::TestDataFrameCaching::test_get_cached_dataframe_returns_none_when_not_cached PASSED [ 61%]
tests/fixtures/test_cache.py::TestExcelFileCaching::test_cache_excel_file_stores_file PASSED [ 61%]
tests/fixtures/test_cache.py::TestExcelFileCaching::test_get_cached_excel_file_retrieves_file PASSED [ 61%]
tests/fixtures/test_cache.py::TestExcelFileCaching::test_get_cached_excel_file_returns_none_when_not_cached PASSED [ 61%]
tests/fixtures/test_cached_fixtures.py::TestCachedExcelFixtures::test_excel_file_caching_creates_cache_entry[test_data0-simple_numeric] PASSED [ 61%]
tests/fixtures/test_cached_fixtures.py::TestCachedExcelFixtures::test_excel_file_caching_creates_cache_entry[test_data1-mixed_types] PASSED [ 62%]
tests/fixtures/test_cached_fixtures.py::TestCachedExcelFixtures::test_excel_file_caching_creates_cache_entry[test_data2-string_with_duplicates] PASSED [ 62%]
tests/fixtures/test_cached_fixtures.py::TestCachedExcelFixtures::test_excel_file_caching_creates_cache_entry[test_data3-large_dataset] PASSED [ 62%]
tests/fixtures/test_cached_fixtures.py::TestCachedExcelFixtures::test_cached_excel_file_retrieves_from_cache[source_data0-simple_numeric] PASSED [ 62%]
tests/fixtures/test_cached_fixtures.py::TestCachedExcelFixtures::test_cached_excel_file_retrieves_from_cache[source_data1-mixed_types] PASSED [ 62%]
tests/fixtures/test_cached_fixtures.py::TestCachedExcelFixtures::test_cached_excel_file_retrieves_from_cache[source_data2-string_with_duplicates] PASSED [ 62%]
tests/integration/test_adr002_end_to_end.py::TestADR002EndToEnd::test_complete_upload_to_query_flow PASSED [ 62%]
tests/integration/test_adr002_end_to_end.py::TestADR002EndToEnd::test_parquet_predicate_pushdown_optimization PASSED [ 62%]
tests/integration/test_adr002_end_to_end.py::TestADR002EndToEnd::test_core_invariant_identical_data_produces_same_version PASSED [ 62%]
tests/integration/test_run_app_script.py::TestRunAppScriptCleanup::test_unit_script_exists_is_executable PASSED [ 62%]
tests/integration/test_run_app_script.py::TestRunAppScriptCleanup::test_unit_cleanup_function_defined PASSED [ 62%]
tests/integration/test_run_app_script.py::TestRunAppScriptCleanup::test_unit_trap_registered_handles_signals PASSED [ 62%]
tests/integration/test_run_app_script.py::TestRunAppScriptCleanup::test_unit_cleanup_checks_ollama_pid PASSED [ 63%]
tests/integration/test_run_app_script.py::TestRunAppScriptCleanup::test_unit_cleanup_supports_stop_ollama_flag PASSED [ 63%]
tests/integration/test_run_app_script.py::TestRunAppScriptCleanup::test_unit_cleanup_kills_ollama_process PASSED [ 63%]
tests/integration/test_run_app_script.py::TestRunAppScriptCleanup::test_integration_script_syntax_valid PASSED [ 63%]
tests/integration/test_run_app_script.py::TestRunAppScriptCleanup::test_unit_ollama_pid_initialized_globally PASSED [ 63%]
tests/integration/test_run_key_determinism_ui_flow.py::TestRunKeyDeterminismUIFlow::test_ui_cache_key_stable_across_sessions PASSED [ 63%]
tests/integration/test_run_key_determinism_ui_flow.py::TestRunKeyDeterminismUIFlow::test_cache_key_different_for_different_queries PASSED [ 63%]
tests/integration/test_run_key_determinism_ui_flow.py::TestRunKeyDeterminismUIFlow::test_cache_key_whitespace_normalization PASSED [ 63%]
tests/integration/test_run_key_determinism_ui_flow.py::TestRunKeyDeterminismUIFlow::test_cache_key_uses_stable_sha256_not_python_hash PASSED [ 63%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_with_csv_files PASSED [ 63%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_with_csv_gz_files PASSED [ 63%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_with_subdirectories PASSED [ 63%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_ignores_macosx PASSED [ 64%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_no_csv_files PASSED [ 64%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_invalid_file PASSED [ 64%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_with_mixed_types PASSED [ 64%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_large_dataset PASSED [ 64%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_creates_unified_cohort PASSED [ 64%]
tests/loader/test_zip_extraction.py::TestZipExtraction::test_extract_zip_saves_metadata PASSED [ 64%]
tests/loader/test_zip_extraction.py::TestMultiTableHandler::test_detect_relationships_with_type_mismatch PASSED [ 64%]
tests/loader/test_zip_extraction.py::TestMultiTableHandler::test_build_unified_cohort_with_type_mismatch PASSED [ 64%]
tests/performance/test_cli.py::TestCLI::test_cli_generate_markdown_report_from_file PASSED [ 64%]
tests/performance/test_cli.py::TestCLI::test_cli_create_baseline_from_performance_data PASSED [ 64%]
tests/performance/test_integration.py::TestPerformanceIntegration::test_integration_track_report_baseline_regression_workflow PASSED [ 64%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_is_tracking_enabled_with_flag PASSED [ 64%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_is_tracking_enabled_without_flag PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_should_exclude_test_excludes_performance_tests PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_should_exclude_test_includes_other_tests PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_get_worker_id_returns_worker_id PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_get_worker_id_returns_master_when_no_worker PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_is_worker_process_returns_true_for_worker PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_is_worker_process_returns_false_for_master PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_get_performance_data_file_returns_correct_path PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginHelpers::test_plugin_get_worker_file_returns_correct_path PASSED [ 65%]
tests/performance/test_plugin.py::TestPluginIntegration::test_plugin_tracks_test_duration_when_enabled PASSED [ 65%]
tests/performance/test_regression.py::TestRegression::test_regression_calculate_percentage_increase PASSED [ 65%]
tests/performance/test_regression.py::TestRegression::test_regression_calculate_percentage_increase_with_zero_baseline PASSED [ 65%]
tests/performance/test_regression.py::TestRegression::test_regression_check_regressions_detects_individual_test_regression PASSED [ 66%]
tests/performance/test_regression.py::TestRegression::test_regression_check_regressions_passes_when_no_regression PASSED [ 66%]
tests/performance/test_regression.py::TestRegression::test_regression_check_regressions_handles_missing_baseline_gracefully PASSED [ 66%]
tests/performance/test_regression.py::TestRegression::test_regression_check_regressions_detects_suite_level_regression PASSED [ 66%]
tests/performance/test_reporter.py::TestReporter::test_reporter_generate_markdown_report_with_data PASSED [ 66%]
tests/performance/test_reporter.py::TestReporter::test_reporter_generate_markdown_report_with_empty_data PASSED [ 66%]
tests/performance/test_reporter.py::TestReporter::test_reporter_generate_json_report_with_data PASSED [ 66%]
tests/performance/test_reporter.py::TestReporter::test_reporter_generate_markdown_report_includes_slowest_tests PASSED [ 66%]
tests/performance/test_storage.py::TestStorageReadWrite::test_storage_save_and_load_performance_data_roundtrip PASSED [ 66%]
tests/performance/test_storage.py::TestStorageReadWrite::test_storage_load_missing_file_returns_empty_structure PASSED [ 66%]
tests/performance/test_storage.py::TestStorageReadWrite::test_storage_summary_includes_min_max_duration PASSED [ 66%]
tests/performance/test_storage.py::TestStorageReadWrite::test_storage_load_corrupted_json_returns_empty_structure PASSED [ 66%]
tests/performance/test_storage.py::TestStorageReadWrite::test_storage_save_and_load_baseline_roundtrip PASSED [ 67%]
tests/performance/test_storage.py::TestStorageReadWrite::test_storage_load_missing_baseline_returns_empty_structure PASSED [ 67%]
tests/performance/test_storage.py::TestStorageReadWrite::test_storage_load_validates_schema_on_load PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStoreSaveLoad::test_datastore_save_table_persists_data PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStoreSaveLoad::test_datastore_load_table_returns_lazy_frame PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStoreSaveLoad::test_datastore_save_multiple_tables PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStorePersistence::test_datastore_table_survives_restart PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStoreListDatasets::test_datastore_list_datasets_returns_all_uploads PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStoreListDatasets::test_datastore_list_tables_returns_table_names PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStoreParquetExport::test_export_to_parquet_creates_file PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStoreParquetExport::test_parquet_compression_smaller_than_csv PASSED [ 67%]
tests/storage/test_datastore.py::TestDataStoreParquetExport::test_load_from_parquet_returns_lazy_frame PASSED [ 67%]
tests/storage/test_query_logger.py::TestQueryLoggerBasics::test_query_logger_creates_log_directory PASSED [ 68%]
tests/storage/test_query_logger.py::TestQueryLoggerBasics::test_log_query_writes_jsonl_entry PASSED [ 68%]
tests/storage/test_query_logger.py::TestQueryLoggerBasics::test_log_execution_writes_jsonl_entry PASSED [ 68%]
tests/storage/test_query_logger.py::TestQueryLoggerBasics::test_log_result_writes_jsonl_entry PASSED [ 68%]
tests/storage/test_query_logger.py::TestQueryLoggerStreaming::test_multiple_queries_append_to_same_file PASSED [ 68%]
tests/storage/test_query_logger.py::TestQueryLoggerStreaming::test_different_uploads_use_separate_files PASSED [ 68%]
tests/storage/test_query_logger.py::TestQueryLoggerRetrieval::test_get_query_history_returns_all_entries PASSED [ 68%]
tests/storage/test_query_logger.py::TestQueryLoggerRetrieval::test_get_query_history_returns_empty_for_nonexistent_upload PASSED [ 68%]
tests/storage/test_query_logger.py::TestQueryLoggerRetrieval::test_get_latest_queries_returns_recent_entries PASSED [ 68%]
tests/storage/test_query_logger_enhanced.py::TestEnhancedQueryContextLogging::test_log_query_with_full_context PASSED [ 68%]
tests/storage/test_query_logger_enhanced.py::TestEnhancedQueryContextLogging::test_log_execution_with_warnings PASSED [ 68%]
tests/storage/test_query_logger_enhanced.py::TestEnhancedQueryContextLogging::test_log_result_with_row_count PASSED [ 68%]
tests/storage/test_query_logger_enhanced.py::TestFailureLogging::test_log_failure_with_details PASSED [ 69%]
tests/storage/test_query_logger_enhanced.py::TestFailureLogging::test_log_failure_using_dedicated_method PASSED [ 69%]
tests/storage/test_query_logger_enhanced.py::TestBackwardCompatibility::test_log_query_without_context_still_works PASSED [ 69%]
tests/storage/test_query_logger_enhanced.py::TestBackwardCompatibility::test_log_execution_without_warnings_still_works PASSED [ 69%]
tests/storage/test_versioning.py::TestComputeDatasetVersion::test_compute_dataset_version_identical_tables_same_version PASSED [ 69%]
tests/storage/test_versioning.py::TestComputeDatasetVersion::test_compute_dataset_version_different_tables_different_version PASSED [ 69%]
tests/storage/test_versioning.py::TestComputeDatasetVersion::test_compute_dataset_version_canonicalization_row_order_independent PASSED [ 69%]
tests/storage/test_versioning.py::TestComputeDatasetVersion::test_compute_dataset_version_canonicalization_column_order_independent PASSED [ 69%]
tests/storage/test_versioning.py::TestComputeDatasetVersion::test_compute_dataset_version_multi_table PASSED [ 69%]
tests/storage/test_versioning.py::TestComputeDatasetVersion::test_compute_dataset_version_handles_null_values PASSED [ 69%]
tests/storage/test_versioning.py::TestComputeDatasetVersion::test_compute_dataset_version_different_schemas_different_version PASSED [ 69%]
tests/storage/test_versioning.py::TestSaveTableListStoresVersion::test_save_table_list_stores_dataset_version PASSED [ 69%]
tests/storage/test_versioning.py::TestSaveTableListStoresVersion::test_save_table_list_stores_table_fingerprints PASSED [ 70%]
tests/test_performance_regression.py::TestPerformanceRegression::test_individual_test_performance SKIPPED [ 70%]
tests/test_performance_regression.py::TestPerformanceRegression::test_suite_performance SKIPPED [ 70%]
tests/test_performance_regression.py::TestPerformanceRegression::test_slow_test_count PASSED [ 70%]
tests/ui/components/test_dataset_loader.py::test_dataset_loader_encapsulates_loading_logic PASSED [ 70%]
tests/ui/components/test_dataset_loader.py::test_dataset_loader_returns_dataset_and_cohort PASSED [ 70%]
tests/ui/components/test_dataset_loader.py::test_dataset_loader_handles_no_datasets PASSED [ 70%]
tests/ui/components/test_dataset_loader.py::test_dataset_loader_shows_semantic_scope PASSED [ 70%]
tests/ui/components/test_question_engine_clarifying.py::test_ask_free_form_question_uses_clarifying_questions_for_low_confidence PASSED [ 70%]
tests/ui/components/test_question_engine_clarifying.py::test_ask_free_form_question_skips_clarifying_questions_for_high_confidence PASSED [ 70%]
tests/ui/components/test_question_engine_confidence_propagation.py::test_ask_free_form_question_propagates_confidence_to_context PASSED [ 70%]
tests/ui/components/test_question_engine_confidence_propagation.py::test_ask_free_form_question_propagates_low_confidence PASSED [ 70%]
tests/ui/components/test_question_engine_confidence_propagation.py::test_analysis_context_has_confidence_field PASSED [ 71%]
tests/ui/components/test_question_engine_error_formatting.py::test_format_diagnostic_error_shows_suggestions PASSED [ 71%]
tests/ui/components/test_question_engine_error_formatting.py::test_format_diagnostic_error_shows_parsing_attempts PASSED [ 71%]
tests/ui/components/test_question_engine_error_formatting.py::test_format_diagnostic_error_shows_failure_reason PASSED [ 71%]
tests/ui/components/test_question_engine_integration.py::test_end_to_end_nl_query_flow PASSED [ 71%]
tests/ui/components/test_question_engine_progressive_feedback.py::test_progressive_feedback_returns_intent_with_diagnostics PASSED [ 71%]
tests/ui/components/test_question_engine_progressive_feedback.py::test_progressive_feedback_tracks_all_attempts PASSED [ 71%]
tests/ui/components/test_question_engine_progressive_feedback.py::test_progressive_feedback_handles_timeout PASSED [ 71%]
tests/ui/components/test_question_engine_progressive_feedback.py::test_progressive_feedback_respects_feature_flag PASSED [ 71%]
tests/ui/pages/test_ask_questions_semantic_layer_check.py::test_natural_language_queries_require_semantic_layer PASSED [ 71%]
tests/ui/pages/test_ask_questions_semantic_layer_check.py::test_natural_language_queries_with_semantic_layer_work PASSED [ 71%]
tests/ui/pages/test_page_gating.py::TestPageGating::test_legacy_pages_have_gating_marker PASSED [ 71%]
tests/ui/pages/test_page_gating.py::TestPageGating::test_core_pages_have_no_gating_marker PASSED [ 71%]
tests/ui/pages/test_page_gating.py::TestPageGating::test_gated_pages_show_info_message PASSED [ 72%]
tests/ui/pages/test_page_gating.py::TestPageGating::test_v1_mvp_mode_reduces_page_count PASSED [ 72%]
tests/ui/pages/test_page_ordering.py::TestPageOrdering::test_core_pages_ordered_upload_summary_ask PASSED [ 72%]
tests/ui/pages/test_page_ordering.py::TestPageOrdering::test_gated_pages_come_after_core_pages PASSED [ 72%]
tests/ui/pages/test_page_ordering.py::TestPageOrdering::test_page_numbering_creates_correct_sidebar_order PASSED [ 72%]
tests/ui/pages/test_upload_progress.py::TestUploadProgress::test_upload_page_has_progress_bar PASSED [ 72%]
tests/ui/pages/test_upload_progress.py::TestUploadProgress::test_upload_page_has_progress_callback PASSED [ 72%]
tests/ui/pages/test_upload_progress.py::TestUploadProgress::test_upload_page_has_detailed_logging PASSED [ 72%]
tests/ui/pages/test_upload_progress.py::TestUploadProgress::test_upload_page_uses_spinners PASSED [ 72%]
tests/ui/test_app.py::test_app_initial_load PASSED                       [ 72%]
tests/ui/test_app.py::test_dataset_selection_flow PASSED                 [ 72%]
tests/ui/test_app.py::test_statistical_analysis_execution PASSED         [ 72%]
tests/ui/test_composite_identifier.py::TestCompositeIdentifierDetection::test_find_composite_identifier_with_two_columns PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestCompositeIdentifierDetection::test_find_composite_identifier_no_candidates PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestCompositeIdentifierDetection::test_find_composite_identifier_excludes_high_missing PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestCompositeIdentifierDetection::test_find_composite_identifier_prefers_smaller_combinations PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestSyntheticPatientIdCreation::test_create_synthetic_patient_id_from_two_columns PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestSyntheticPatientIdCreation::test_create_synthetic_patient_id_deterministic PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestSyntheticPatientIdCreation::test_create_synthetic_patient_id_handles_nulls PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestEnsurePatientId::test_ensure_patient_id_existing_column PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestEnsurePatientId::test_ensure_patient_id_single_column_identifier PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestEnsurePatientId::test_ensure_patient_id_composite_identifier PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestEnsurePatientId::test_ensure_patient_id_no_identifier_found PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestEnsurePatientId::test_ensure_patient_id_with_pandas_input PASSED [ 73%]
tests/ui/test_composite_identifier.py::TestCompositeIdentifierIntegration::test_suggest_schema_mapping_with_composite_id PASSED [ 74%]
tests/ui/test_composite_identifier.py::TestCompositeIdentifierIntegration::test_composite_identifier_preserves_original_columns PASSED [ 74%]
tests/ui/test_composite_identifier.py::TestCompositeIdentifierIntegration::test_composite_identifier_handles_mixed_types PASSED [ 74%]
tests/ui/test_composite_identifier.py::TestEnsurePatientIdLogging::test_ensure_patient_id_logs_appropriately PASSED [ 74%]
tests/ui/test_data_validator.py::TestDataQualityValidatorComplete::test_validate_complete_empty_dataframe PASSED [ 74%]
tests/ui/test_data_validator.py::TestDataQualityValidatorComplete::test_validate_complete_no_columns PASSED [ 74%]
tests/ui/test_data_validator.py::TestDataQualityValidatorComplete::test_validate_complete_valid_data_always_passes PASSED [ 74%]
tests/ui/test_data_validator.py::TestDataQualityValidatorComplete::test_validate_complete_high_missing_is_warning_not_error PASSED [ 74%]
tests/ui/test_data_validator.py::TestDataQualityValidatorComplete::test_validate_complete_duplicates_are_warnings PASSED [ 74%]
tests/ui/test_data_validator.py::TestDataQualityValidatorComplete::test_validate_complete_stores_quality_metadata PASSED [ 74%]
tests/ui/test_data_validator.py::TestDataQualityValidatorComplete::test_validate_complete_preview_mode_no_id_column PASSED [ 74%]
tests/ui/test_data_validator.py::TestDataQualityValidatorComplete::test_validate_complete_summary_statistics PASSED [ 74%]
tests/ui/test_data_validator.py::TestVariableTypeDetector::test_detect_identifier_by_uniqueness PASSED [ 75%]
tests/ui/test_data_validator.py::TestVariableTypeDetector::test_detect_binary_outcome PASSED [ 75%]
tests/ui/test_data_validator.py::TestVariableTypeDetector::test_detect_continuous PASSED [ 75%]
tests/ui/test_data_validator.py::TestVariableTypeDetector::test_suggest_schema_mapping_data_driven PASSED [ 75%]
tests/ui/test_data_validator.py::TestEnsurePolars::test_ensure_polars_with_polars_dataframe PASSED [ 75%]
tests/ui/test_data_validator.py::TestEnsurePolars::test_ensure_polars_with_normal_pandas PASSED [ 75%]
tests/ui/test_data_validator.py::TestEnsurePolars::test_ensure_polars_handles_mixed_types PASSED [ 75%]
tests/ui/test_excel_reading.py::TestPolarsExcelReading::test_read_excel_with_openpyxl_engine PASSED [ 75%]
tests/ui/test_excel_reading.py::TestPolarsExcelReading::test_read_excel_mixed_types_handled PASSED [ 75%]
tests/ui/test_excel_reading.py::TestPolarsExcelReading::test_read_excel_bytes_io PASSED [ 75%]
tests/ui/test_excel_reading.py::TestEnsurePolarsErrorHandling::test_ensure_polars_with_polars_dataframe PASSED [ 75%]
tests/ui/test_excel_reading.py::TestEnsurePolarsErrorHandling::test_ensure_polars_with_normal_pandas PASSED [ 75%]
tests/ui/test_excel_reading.py::TestEnsurePolarsErrorHandling::test_ensure_polars_with_mixed_types_fallback PASSED [ 76%]
tests/ui/test_excel_reading.py::TestEnsurePolarsErrorHandling::test_ensure_polars_with_nan_strings PASSED [ 76%]
tests/ui/test_excel_reading.py::TestEnsurePolarsErrorHandling::test_ensure_polars_with_empty_strings PASSED [ 76%]
tests/ui/test_excel_reading.py::TestEnsurePolarsErrorHandling::test_ensure_polars_raises_other_errors PASSED [ 76%]
tests/ui/test_excel_reading.py::TestExcelReadingIntegration::test_excel_to_pandas_conversion_for_preview PASSED [ 76%]
tests/ui/test_excel_reading.py::TestExcelReadingIntegration::test_excel_with_mixed_types_roundtrip PASSED [ 76%]
tests/ui/test_excel_reading.py::TestExcelHeaderDetection::test_detect_header_row_standard_format PASSED [ 76%]
tests/ui/test_excel_reading.py::TestExcelHeaderDetection::test_detect_header_row_with_empty_first_row PASSED [ 76%]
tests/ui/test_excel_reading.py::TestExcelHeaderDetection::test_detect_header_row_with_metadata_rows PASSED [ 76%]
tests/ui/test_integration.py::TestUIDatasetIntegration::test_dataset_registry_discovers_datasets PASSED [ 76%]
tests/ui/test_integration.py::TestUIDatasetIntegration::test_dataset_info_retrieval_returns_metadata PASSED [ 76%]
tests/ui/test_integration.py::TestUIDatasetIntegration::test_dataset_factory_creates_instance_via_registry SKIPPED [ 76%]
tests/ui/test_integration.py::TestUIDatasetIntegration::test_cohort_retrieval_with_default_filters[NOTSET] SKIPPED [ 77%]
tests/ui/test_integration.py::TestUIDatasetIntegration::test_ui_workflow_end_to_end_with_all_datasets FAILED [ 77%]
tests/ui/test_integration.py::TestUIDatasetIntegration::test_patient_level_granularity_supported[NOTSET] SKIPPED [ 77%]
tests/ui/test_integration.py::TestUIDatasetIntegration::test_non_patient_level_granularity_rejected_for_single_table[NOTSET] SKIPPED [ 77%]
tests/ui/test_integration.py::TestUIErrorHandling::test_invalid_dataset_name_raises_keyerror PASSED [ 77%]
tests/ui/test_integration.py::TestUIFilterHandling::test_boolean_filter_type_safety[NOTSET] SKIPPED [ 77%]
tests/ui/test_normalization.py::TestNormalizeUploadToTableList::test_normalize_csv_to_table_list PASSED [ 77%]
tests/ui/test_normalization.py::TestNormalizeUploadToTableList::test_normalize_excel_to_table_list SKIPPED [ 77%]
tests/ui/test_normalization.py::TestNormalizeUploadToTableList::test_normalize_zip_to_table_list PASSED [ 77%]
tests/ui/test_normalization.py::TestNormalizeUploadToTableList::test_normalize_preserves_original_filename_stem PASSED [ 77%]
tests/ui/test_normalization.py::TestNormalizeUploadToTableList::test_normalize_handles_gzip_compressed_csv_in_zip PASSED [ 77%]
tests/ui/test_normalization.py::TestExtractZipTables::test_extract_valid_zip_returns_tables PASSED [ 77%]
tests/ui/test_normalization.py::TestExtractZipTables::test_extract_zip_rejects_path_traversal PASSED [ 78%]
tests/ui/test_normalization.py::TestExtractZipTables::test_extract_zip_rejects_no_csv_files PASSED [ 78%]
tests/ui/test_normalization.py::TestExtractZipTables::test_extract_zip_handles_duplicate_table_names PASSED [ 78%]
tests/ui/test_normalization.py::TestExtractZipTables::test_extract_zip_skips_macosx_files PASSED [ 78%]
tests/ui/test_normalization.py::TestExtractZipTables::test_extract_zip_handles_corrupted_file PASSED [ 78%]
tests/ui/test_normalization.py::TestLoadSingleFile::test_load_csv_returns_polars_dataframe PASSED [ 78%]
tests/ui/test_normalization.py::TestLoadSingleFile::test_load_excel_returns_polars_dataframe SKIPPED [ 78%]
tests/ui/test_normalization.py::TestLoadSingleFile::test_load_unsupported_file_raises_error PASSED [ 78%]
tests/ui/test_normalization.py::TestLoadSingleFile::test_load_preserves_column_types PASSED [ 78%]
tests/ui/test_ollama_init.py::TestOllamaAutoDownload::test_ensure_models_downloaded_auto_downloads_when_missing PASSED [ 78%]
tests/ui/test_ollama_init.py::TestOllamaAutoDownload::test_ensure_models_downloaded_returns_ready_when_models_exist PASSED [ 78%]
tests/ui/test_ollama_init.py::TestOllamaAutoDownload::test_ensure_models_downloaded_tries_fallback_on_default_failure PASSED [ 78%]
tests/ui/test_ollama_init.py::TestOllamaInitializationStatus::test_initialize_ollama_shows_download_in_progress_message PASSED [ 78%]
tests/ui/test_ollama_init.py::TestOllamaInitializationStatus::test_initialize_ollama_returns_ready_when_models_available PASSED [ 79%]
tests/ui/test_ollama_ui_feedback.py::TestOllamaUIFeedback::test_app_shows_warning_banner_when_ollama_not_ready PASSED [ 79%]
tests/ui/test_ollama_ui_feedback.py::TestOllamaUIFeedback::test_app_initialization_with_auto_download_success PASSED [ 79%]
tests/ui/test_ollama_ui_feedback.py::TestOllamaUIFeedback::test_app_provides_helpful_message_on_download_failure PASSED [ 79%]
tests/ui/test_ollama_ui_feedback.py::TestOllamaStatusDisplay::test_get_ollama_status_display_ready PASSED [ 79%]
tests/ui/test_ollama_ui_feedback.py::TestOllamaStatusDisplay::test_get_ollama_status_display_not_ready PASSED [ 79%]
tests/ui/test_patient_id_regeneration.py::TestValidateSyntheticIdMetadata::test_none_metadata_returns_empty_dict PASSED [ 79%]
tests/ui/test_patient_id_regeneration.py::TestValidateSyntheticIdMetadata::test_valid_metadata_returns_unchanged PASSED [ 79%]
tests/ui/test_patient_id_regeneration.py::TestValidateSyntheticIdMetadata::test_invalid_type_raises_error PASSED [ 79%]
tests/ui/test_patient_id_regeneration.py::TestValidateSyntheticIdMetadata::test_invalid_patient_id_type_raises_error PASSED [ 79%]
tests/ui/test_patient_id_regeneration.py::TestValidateSyntheticIdMetadata::test_invalid_patient_id_source_raises_error PASSED [ 79%]
tests/ui/test_patient_id_regeneration.py::TestValidateSyntheticIdMetadata::test_valid_sources_accepted PASSED [ 79%]
tests/ui/test_patient_id_regeneration.py::TestValidateSyntheticIdMetadata::test_invalid_patient_id_columns_type_raises_error PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestCanRegeneratePatientId::test_no_metadata_returns_cannot_regenerate PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestCanRegeneratePatientId::test_composite_with_all_columns_present_returns_can_regenerate PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestCanRegeneratePatientId::test_composite_with_missing_column_returns_cannot_regenerate_with_error PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestCanRegeneratePatientId::test_composite_with_empty_columns_returns_cannot_regenerate PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestCanRegeneratePatientId::test_single_column_with_column_present_returns_can_regenerate PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestCanRegeneratePatientId::test_single_column_with_missing_column_returns_cannot_regenerate PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestCanRegeneratePatientId::test_existing_source_returns_cannot_regenerate PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestRegeneratePatientId::test_composite_regeneration_creates_patient_id PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestRegeneratePatientId::test_single_column_regeneration_creates_patient_id PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestRegeneratePatientId::test_regeneration_with_nulls_is_deterministic PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestRegeneratePatientId::test_invalid_source_type_raises_error PASSED [ 80%]
tests/ui/test_patient_id_regeneration.py::TestPatientIdRegenerationIntegration::test_full_flow_composite_regeneration PASSED [ 81%]
tests/ui/test_patient_id_regeneration.py::TestPatientIdRegenerationIntegration::test_full_flow_fails_fast_on_missing_column PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_basic_variable_mapping_to_inferred_schema PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_infers_binary_outcome_from_data PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_infers_continuous_outcome_from_data PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_maps_time_zero PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_maps_predictors PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_detects_categorical_variables PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_rejects_high_uniqueness_ratio_as_categorical PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_infers_granularities_from_columns PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_patient_level_always_supported PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_handles_missing_optional_fields PASSED [ 81%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_sets_default_outcome PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_preserves_polars_dtype_info PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_missing_patient_id_column_raises_valueerror PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_missing_time_zero_column_raises_valueerror PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestConvertSchema::test_convert_schema_missing_outcome_column_raises_valueerror PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestCategoricalDetection::test_categorical_detection_low_cardinality_string PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestCategoricalDetection::test_categorical_detection_high_cardinality_string PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestCategoricalDetection::test_categorical_detection_numeric_never_categorical PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestGranularityInference::test_infer_granularities_patient_only PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestGranularityInference::test_infer_granularities_with_admission_id PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestGranularityInference::test_infer_granularities_with_event_timestamp PASSED [ 82%]
tests/ui/test_schema_conversion.py::TestGranularityInference::test_infer_granularities_with_all_columns PASSED [ 82%]
tests/ui/test_session_recovery.py::TestRestoreDatasets::test_restore_datasets_detects_existing_uploads PASSED [ 83%]
tests/ui/test_session_recovery.py::TestRestoreDatasets::test_restore_datasets_handles_missing_metadata PASSED [ 83%]
tests/ui/test_session_recovery.py::TestRestoreDatasets::test_restore_datasets_returns_empty_list_when_no_db PASSED [ 83%]
tests/ui/test_session_recovery.py::TestRestoreDatasets::test_restore_datasets_sorts_by_created_at_descending PASSED [ 83%]
tests/ui/test_session_recovery.py::TestSessionRecoveryIntegration::test_session_recovery_loads_dataset_on_startup PASSED [ 83%]
tests/ui/test_trust_ui.py::test_trust_ui_shows_query_plan_raw_fields PASSED [ 83%]
tests/ui/test_trust_ui.py::test_trust_ui_shows_alias_resolved_plan PASSED [ 83%]
tests/ui/test_trust_ui.py::test_trust_ui_shows_effective_execution PASSED [ 83%]
tests/ui/test_trust_ui.py::test_trust_ui_shows_run_key_and_audit_trail PASSED [ 83%]
tests/ui/test_trust_ui.py::test_trust_ui_patient_level_export_capped PASSED [ 83%]
tests/ui/test_trust_ui.py::test_trust_ui_patient_level_export_full_requires_confirmation PASSED [ 83%]
tests/ui/test_trust_ui.py::test_trust_ui_cohort_size_calculation PASSED  [ 83%]
tests/ui/test_trust_ui.py::test_trust_ui_tautology_detection PASSED      [ 84%]
tests/ui/test_trust_ui.py::test_trust_ui_integration_with_descriptive_analysis PASSED [ 84%]
tests/ui/test_trust_ui.py::test_trust_ui_integration_with_comparison_analysis PASSED [ 84%]
tests/ui/test_trust_ui.py::test_trust_ui_integration_with_count_analysis PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileTypeValidation::test_valid_csv PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileTypeValidation::test_valid_excel_xlsx PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileTypeValidation::test_valid_excel_xls PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileTypeValidation::test_valid_spss PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileTypeValidation::test_case_insensitive PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileTypeValidation::test_invalid_extension PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileTypeValidation::test_no_extension PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileTypeValidation::test_dangerous_extensions PASSED [ 84%]
tests/ui/test_upload_security.py::TestFileSizeValidation::test_valid_size PASSED [ 85%]
tests/ui/test_upload_security.py::TestFileSizeValidation::test_max_size PASSED [ 85%]
tests/ui/test_upload_security.py::TestFileSizeValidation::test_too_large PASSED [ 85%]
tests/ui/test_upload_security.py::TestFileSizeValidation::test_too_small PASSED [ 85%]
tests/ui/test_upload_security.py::TestFileSizeValidation::test_empty_file PASSED [ 85%]
tests/ui/test_upload_security.py::TestFilenameSecure::test_sanitize_normal PASSED [ 85%]
tests/ui/test_upload_security.py::TestFilenameSecure::test_sanitize_path_traversal PASSED [ 85%]
tests/ui/test_upload_security.py::TestFilenameSecure::test_sanitize_absolute_path PASSED [ 85%]
tests/ui/test_upload_security.py::TestFilenameSecure::test_sanitize_windows_path PASSED [ 85%]
tests/ui/test_upload_security.py::TestFilenameSecure::test_sanitize_special_chars PASSED [ 85%]
tests/ui/test_upload_security.py::TestFilenameSecure::test_sanitize_spaces PASSED [ 85%]
tests/ui/test_upload_security.py::TestFilenameSecure::test_sanitize_unicode PASSED [ 85%]
tests/ui/test_upload_security.py::TestCompleteValidation::test_valid_upload PASSED [ 85%]
tests/ui/test_upload_security.py::TestCompleteValidation::test_invalid_type PASSED [ 86%]
tests/ui/test_upload_security.py::TestCompleteValidation::test_too_large_file PASSED [ 86%]
tests/ui/test_upload_security.py::TestCompleteValidation::test_multiple_issues PASSED [ 86%]
tests/ui/test_upload_security.py::TestSecurityConstants::test_allowed_extensions_defined PASSED [ 86%]
tests/ui/test_upload_security.py::TestSecurityConstants::test_size_limits_defined PASSED [ 86%]
tests/ui/test_upload_security.py::TestSecurityConstants::test_size_limits_reasonable PASSED [ 86%]
tests/ui/test_upload_security.py::TestSecurityConstants::test_allowed_extensions_secure PASSED [ 86%]
tests/ui/test_uploaded_dataset_patient_id.py::TestUploadedDatasetPatientId::test_get_cohort_with_missing_patient_id_regenerates PASSED [ 86%]
tests/ui/test_uploaded_dataset_patient_id.py::TestUploadedDatasetPatientId::test_get_cohort_with_missing_patient_id_raises_error_if_cannot_regenerate PASSED [ 86%]
tests/ui/test_uploaded_dataset_patient_id.py::TestUploadedDatasetPatientId::test_get_cohort_with_existing_patient_id_uses_it PASSED [ 86%]
tests/ui/test_uploaded_dataset_patient_id.py::TestUploadedDatasetPatientId::test_get_cohort_with_wrong_patient_id_column_name_raises_error PASSED [ 86%]
tests/ui/test_uploaded_dataset_patient_id.py::TestUploadedDatasetPatientId::test_get_cohort_with_renamed_patient_id_column_uses_patient_id PASSED [ 86%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_validate_file_type_csv PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_validate_file_type_xlsx PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_validate_file_type_invalid PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_validate_file_type_no_extension PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_validate_file_size_valid PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_validate_file_size_too_small PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_validate_file_size_too_large PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_sanitize_filename PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_sanitize_filename_path_traversal PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUploadSecurityValidator::test_sanitize_filename_special_chars PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_storage_initialization PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_save_upload PASSED [ 87%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_get_upload_data PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_get_upload_data_large_id_values PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_get_upload_data_synthetic_id_metadata PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_list_uploads PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_get_upload_metadata PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_delete_upload PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_overwrite_preserves_version_history PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_overwrite_without_flag_rejected PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_duplicate_dataset_name_rejected PASSED [ 88%]
tests/ui/test_user_datasets.py::TestUserDatasetStorage::test_different_dataset_names_allowed PASSED [ 88%]
tests/ui/test_user_datasets.py::TestSaveTableList::test_save_table_list_single_table_creates_tables_directory PASSED [ 88%]
tests/ui/test_user_datasets.py::TestSaveTableList::test_save_table_list_saves_metadata_with_tables_list PASSED [ 88%]
tests/ui/test_user_datasets.py::TestSaveTableList::test_save_table_list_converts_variable_mapping_to_inferred_schema PASSED [ 89%]
tests/ui/test_user_datasets.py::TestSaveTableList::test_save_table_list_multi_table_builds_unified_cohort PASSED [ 89%]
tests/ui/test_user_datasets.py::TestFileLocking::test_file_lock_exclusive_access PASSED [ 89%]
tests/ui/test_user_datasets.py::TestFileLocking::test_file_lock_platform_support PASSED [ 89%]
tests/ui/test_user_datasets.py::TestCrossDatasetDeduplication::test_same_content_different_name_warns_with_link PASSED [ 89%]
tests/ui/test_user_datasets.py::TestCrossDatasetDeduplication::test_same_content_same_name_overwrite_allowed PASSED [ 89%]
tests/ui/test_user_datasets.py::TestCrossDatasetDeduplication::test_different_content_different_name_allowed PASSED [ 89%]
tests/ui/test_user_datasets.py::TestVersionHistoryMetadata::test_metadata_includes_version_history PASSED [ 89%]
tests/ui/test_user_datasets.py::TestVersionHistoryMetadata::test_version_entry_has_canonical_tables_structure PASSED [ 89%]
tests/ui/test_user_datasets.py::TestVersionHistoryMetadata::test_stable_internal_table_identifier_preserved PASSED [ 89%]
tests/ui/test_user_datasets.py::TestSchemaDriftDetection::test_detect_schema_drift_policy_defined PASSED [ 89%]
tests/ui/test_user_datasets.py::TestSchemaDriftDetection::test_detect_schema_drift_same_schema PASSED [ 89%]
tests/ui/test_user_datasets.py::TestSchemaDriftDetection::test_detect_schema_drift_new_column PASSED [ 90%]
tests/ui/test_user_datasets.py::TestSchemaDriftDetection::test_detect_schema_drift_removed_column PASSED [ 90%]
tests/ui/test_user_datasets.py::TestSchemaDriftDetection::test_detect_schema_drift_type_change PASSED [ 90%]
tests/ui/test_user_datasets.py::TestMetadataInvariants::test_assert_invariants_valid_metadata PASSED [ 90%]
tests/ui/test_user_datasets.py::TestMetadataInvariants::test_assert_invariants_missing_version_history PASSED [ 90%]
tests/ui/test_user_datasets.py::TestMetadataInvariants::test_assert_invariants_no_active_version PASSED [ 90%]
tests/ui/test_user_datasets.py::TestRollbackMechanism::test_rollback_to_previous_version PASSED [ 90%]
tests/ui/test_user_datasets.py::TestRollbackMechanism::test_rollback_creates_event_entry PASSED [ 90%]
tests/ui/test_user_datasets.py::TestActiveVersionResolution::test_get_active_version_returns_active_entry PASSED [ 90%]
tests/ui/test_user_datasets.py::TestActiveVersionResolution::test_get_active_version_after_overwrite PASSED [ 90%]
tests/ui/test_user_datasets.py::TestActiveVersionResolution::test_get_active_version_after_rollback PASSED [ 90%]
tests/ui/test_user_datasets.py::TestActiveVersionResolution::test_get_active_version_nonexistent_dataset PASSED [ 90%]
tests/ui/test_user_datasets.py::TestQueryVersionIntegration::test_get_cohort_works_after_rollback PASSED [ 91%]
tests/ui/test_user_datasets.py::TestSaveUploadIntegration::test_save_upload_creates_tables_directory PASSED [ 91%]
tests/ui/test_user_datasets.py::TestSaveUploadIntegration::test_save_upload_metadata_contains_inferred_schema PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_binary_yes_no PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_binary_1_0 PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_binary_true_false PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_categorical PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_continuous PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_datetime PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_datetime_parsed PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_id_column_by_uniqueness PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_with_nulls PASSED [ 91%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_all_nulls PASSED [ 92%]
tests/ui/test_variable_detector.py::TestVariableTypeDetector::test_detect_categorical_threshold PASSED [ 92%]
tests/ui/test_variable_detector.py::TestSuggestSchemaMapping::test_suggest_patient_id_by_uniqueness PASSED [ 92%]
tests/ui/test_variable_detector.py::TestSuggestSchemaMapping::test_suggest_outcome_by_binary_type PASSED [ 92%]
tests/ui/test_variable_detector.py::TestSuggestSchemaMapping::test_suggest_time_zero_by_datetime_type PASSED [ 92%]
tests/ui/test_variable_detector.py::TestSuggestSchemaMapping::test_suggest_no_id_when_none_qualifies PASSED [ 92%]
tests/ui/test_variable_detector.py::TestDetectAllVariables::test_detect_all_variables_returns_all_columns PASSED [ 92%]
tests/ui/test_variable_detector.py::TestDetectAllVariables::test_detect_all_variables_includes_missing_stats PASSED [ 92%]
tests/ui/test_zip_upload_progress.py::TestZipUploadProgress::test_save_zip_upload_calls_progress_callback PASSED [ 92%]
tests/ui/test_zip_upload_progress.py::TestZipUploadProgress::test_progress_callback_receives_table_loading_updates PASSED [ 92%]
tests/ui/test_zip_upload_progress.py::TestZipUploadProgress::test_progress_callback_receives_relationship_detection_update PASSED [ 92%]
tests/ui/test_zip_upload_progress.py::TestZipUploadProgress::test_progress_callback_without_callback_works PASSED [ 92%]
tests/ui/test_zip_upload_progress.py::TestZipUploadProgress::test_progress_callback_receives_correct_step_counts PASSED [ 92%]
tests/ui/test_zip_upload_progress.py::TestZipUploadProgress::test_progress_callback_receives_table_details PASSED [ 93%]
tests/unit/core/test_nl_query_engine_logging.py::TestStructuredLogging::test_parse_query_logs_start_with_standardized_fields PASSED [ 93%]
tests/unit/core/test_nl_query_engine_logging.py::TestStructuredLogging::test_parse_query_logs_success_with_standardized_fields PASSED [ 93%]
tests/unit/core/test_nl_query_engine_logging.py::TestStructuredLogging::test_parse_query_logs_error_with_standardized_fields PASSED [ 93%]
tests/unit/core/test_nl_query_engine_logging.py::TestStructuredLogging::test_parse_query_logs_warning_when_no_intent_found PASSED [ 93%]
tests/unit/core/test_nl_query_engine_logging.py::TestStructuredLogging::test_semantic_match_failed_logs_with_error_type PASSED [ 93%]
tests/unit/core/test_nl_query_engine_logging.py::TestStructuredLogging::test_get_matched_variables_extracts_all_variables PASSED [ 93%]
tests/unit/core/test_nl_query_engine_logging.py::TestStructuredLogging::test_get_matched_variables_handles_none_values PASSED [ 93%]
tests/unit/core/test_nl_query_engine_logging.py::TestStructuredLogging::test_parse_query_without_dataset_ids_still_logs PASSED [ 93%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_uses_associated_with_wording PASSED [ 93%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_ci_crosses_one_warning PASSED [ 93%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_small_sample_size_warning PASSED [ 93%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_moderate_sample_size_note PASSED [ 94%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_large_sample_no_warning PASSED [ 94%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_value_mapping_used PASSED [ 94%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_not_significant_with_ci_crossing PASSED [ 94%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_significant_increases PASSED [ 94%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretOddsRatio::test_interpret_odds_ratio_significant_decreases PASSED [ 94%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretMeanDifference::test_interpret_mean_difference_uses_display_names PASSED [ 94%]
tests/unit/ui/components/test_result_interpreter.py::TestInterpretMeanDifference::test_interpret_mean_difference_not_significant PASSED [ 94%]
tests/unit/ui/pages/test_ask_questions_code_label_mapping.py::TestCodeToLabelMapping::test_code_to_label_mapping_logic_is_generic PASSED [ 94%]
tests/unit/ui/pages/test_ask_questions_code_label_mapping.py::TestCodeToLabelMapping::test_mapping_works_for_any_coded_column_format PASSED [ 94%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_initialized_in_session_state PASSED [ 94%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_entry_structure_matches_adr001 PASSED [ 94%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_stores_lightweight_summaries PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_includes_filters_applied PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_limits_size_to_prevent_memory_bloat PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_entry_can_reference_full_result_via_run_key PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_handles_missing_headline_gracefully PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_preserved_across_reruns PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_conversation_history.py::TestConversationHistory::test_conversation_history_only_cleared_by_explicit_user_action PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_dataset_switching.py::TestDatasetSwitching::test_dataset_change_clears_conversation_history PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_dataset_switching.py::TestDatasetSwitching::test_dataset_change_clears_analysis_context PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_dataset_switching.py::TestDatasetSwitching::test_dataset_switching_is_generic_works_for_any_dataset PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_dataset_switching.py::TestDatasetSwitching::test_same_dataset_does_not_clear_history PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_idempotency.py::test_idempotency_same_query_uses_cached_result PASSED [ 95%]
tests/unit/ui/pages/test_ask_questions_idempotency.py::test_idempotency_different_query_computes_new_result PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_idempotency.py::test_idempotency_result_persists_across_reruns PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_idempotency.py::test_idempotency_result_stored_with_dataset_scoped_key PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_lifecycle.py::test_lifecycle_remember_run_evicts_oldest_when_maxlen_reached PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_lifecycle.py::test_lifecycle_remember_run_lru_behavior_moves_existing_to_end PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_lifecycle.py::test_lifecycle_clear_all_results_only_clears_dataset_scoped_keys PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_lifecycle.py::test_lifecycle_remember_run_stores_history_as_list_not_deque PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_lifecycle.py::test_lifecycle_remember_run_handles_empty_history PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_lifecycle.py::test_lifecycle_cleanup_old_results_removes_orphaned_results PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_lifecycle.py::test_lifecycle_execution_cache_eviction_prevents_unbounded_growth PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_lifecycle.py::test_lifecycle_remember_run_called_for_cached_results PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_low_confidence_shows_warning_message PASSED [ 96%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_low_confidence_shows_detected_variables PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_low_confidence_shows_collision_suggestions PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_low_confidence_allows_variable_editing PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_low_confidence_prefills_detected_variables PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_high_confidence_auto_executes PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_user_confirmation_overrides_low_confidence PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_collision_suggestions_rendered_from_context PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_low_confidence_handles_missing_semantic_layer PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_low_confidence_shows_all_detected_variables PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_low_confidence.py::TestLowConfidenceFeedback::test_low_confidence_context_updates_on_user_selection PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_run_key.py::test_normalize_query_handles_tabs_and_newlines PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_run_key.py::test_normalize_query_lowercases_and_strips PASSED [ 97%]
tests/unit/ui/pages/test_ask_questions_run_key.py::test_normalize_query_handles_none_returns_empty_string PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_run_key.py::test_canonicalize_scope_drops_none_values PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_run_key.py::test_canonicalize_scope_sorts_keys PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_run_key.py::test_canonicalize_scope_sorts_list_values PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_run_key.py::test_canonicalize_scope_handles_none_scope PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestConversationHistoryDisplay::test_conversation_history_display_shows_user_queries PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestConversationHistoryDisplay::test_conversation_history_display_shows_assistant_headlines PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestConversationHistoryDisplay::test_conversation_history_can_reconstruct_results_from_run_key PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestConversationHistoryDisplay::test_conversation_history_displays_expandable_details PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_chat_input_query_creates_analysis_context PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_chat_input_query_creates_queryplan_when_dataset_version_available PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_chat_input_query_handles_parsing_errors_gracefully PASSED [ 98%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_chat_input_query_integrates_with_existing_analysis_flow PASSED [ 99%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_chat_input_executes_immediately_when_context_complete PASSED [ 99%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_chat_input_renders_results_inline_in_chat_message_style PASSED [ 99%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_old_text_input_flow_removed_no_duplicate_inputs PASSED [ 99%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_followup_suggestions_have_unique_button_keys PASSED [ 99%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_conversation_history_skips_duplicate_rendering PASSED [ 99%]
tests/unit/ui/pages/test_ask_questions_ui_redesign.py::TestChatInputHandling::test_compact_interpretation_function_exists PASSED [ 99%]
tests/unit/ui/test_messages.py::TestMessageConstants::test_low_confidence_messages_defined PASSED [ 99%]
tests/unit/ui/test_messages.py::TestMessageConstants::test_analysis_execution_messages_defined PASSED [ 99%]
tests/unit/ui/test_messages.py::TestMessageConstants::test_dataset_messages_defined PASSED [ 99%]
tests/unit/ui/test_messages.py::TestMessageConstants::test_nl_query_messages_defined PASSED [ 99%]
tests/unit/ui/test_messages.py::TestMessageConstants::test_analysis_result_messages_defined PASSED [ 99%]
tests/unit/ui/test_messages.py::TestMessageConstants::test_messages_are_non_empty PASSED [100%]

=================================== FAILURES ===================================
_______________________ test_ollama_client_real_generate _______________________

ollama_client = <clinical_analytics.core.llm_client.OllamaClient object at 0x16b1a2b70>
skip_if_ollama_unavailable = None

    def test_ollama_client_real_generate(ollama_client, skip_if_ollama_unavailable):
        """Verify real OllamaClient can generate responses."""
        from clinical_analytics.core.nl_query_config import OLLAMA_DEFAULT_MODEL

        if not ollama_client.is_model_available(OLLAMA_DEFAULT_MODEL):
            pytest.skip(f"Model {OLLAMA_DEFAULT_MODEL} not available")

        prompt = "What is 2+2? Respond with just the number."
>       response = ollama_client.generate(prompt, model=OLLAMA_DEFAULT_MODEL)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: OllamaClient.generate() got an unexpected keyword argument 'model'

tests/core/test_llm_fallback_integration.py:75: TypeError
___________ TestColumnMapper.test_mapper_initialization_with_config ____________

self = <core.test_mapper.TestColumnMapper object at 0x129f4d450>
discovered_datasets = {'all_datasets': ['uploaded'], 'available': [], 'configs': {}}

    @pytest.mark.slow
    @pytest.mark.integration
    def test_mapper_initialization_with_config(self, discovered_datasets):
        """Test mapper can be initialized with dataset config."""
        # Arrange: Get config from first available dataset
>       config = get_first_available_dataset_config(discovered_datasets)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_mapper.py:63:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/core/test_mapper.py:38: in get_first_available_dataset_config
    logger.warning(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Logger core.test_mapper (WARNING)>
msg = 'test_mapper_no_datasets_available', args = ()
kwargs = {'all_datasets': ['uploaded'], 'reason': 'all datasets filtered out or none discovered'}

    def warning(self, msg, *args, **kwargs):
        """
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
        """
        if self.isEnabledFor(WARNING):
>           self._log(WARNING, msg, args, **kwargs)
E           TypeError: Logger._log() got an unexpected keyword argument 'all_datasets'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/logging/__init__.py:1532: TypeError
__________ TestColumnMapper.test_get_default_predictors_returns_list ___________

self = <core.test_mapper.TestColumnMapper object at 0x129f4d810>
discovered_datasets = {'all_datasets': ['uploaded'], 'available': [], 'configs': {}}

    @pytest.mark.slow
    @pytest.mark.integration
    def test_get_default_predictors_returns_list(self, discovered_datasets):
        """Test getting default predictors returns non-empty list."""
        # Arrange: Get config and create mapper
>       config = get_first_available_dataset_config(discovered_datasets)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_mapper.py:79:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/core/test_mapper.py:38: in get_first_available_dataset_config
    logger.warning(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Logger core.test_mapper (WARNING)>
msg = 'test_mapper_no_datasets_available', args = ()
kwargs = {'all_datasets': ['uploaded'], 'reason': 'all datasets filtered out or none discovered'}

    def warning(self, msg, *args, **kwargs):
        """
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
        """
        if self.isEnabledFor(WARNING):
>           self._log(WARNING, msg, args, **kwargs)
E           TypeError: Logger._log() got an unexpected keyword argument 'all_datasets'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/logging/__init__.py:1532: TypeError
_________ TestColumnMapper.test_get_categorical_variables_returns_list _________

self = <core.test_mapper.TestColumnMapper object at 0x129d57950>
discovered_datasets = {'all_datasets': ['uploaded'], 'available': [], 'configs': {}}

    @pytest.mark.slow
    @pytest.mark.integration
    def test_get_categorical_variables_returns_list(self, discovered_datasets):
        """Test getting categorical variables returns list."""
        # Arrange: Get config and create mapper
>       config = get_first_available_dataset_config(discovered_datasets)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_mapper.py:96:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/core/test_mapper.py:38: in get_first_available_dataset_config
    logger.warning(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Logger core.test_mapper (WARNING)>
msg = 'test_mapper_no_datasets_available', args = ()
kwargs = {'all_datasets': ['uploaded'], 'reason': 'all datasets filtered out or none discovered'}

    def warning(self, msg, *args, **kwargs):
        """
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
        """
        if self.isEnabledFor(WARNING):
>           self._log(WARNING, msg, args, **kwargs)
E           TypeError: Logger._log() got an unexpected keyword argument 'all_datasets'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/logging/__init__.py:1532: TypeError
______ TestColumnMapper.test_get_default_outcome_returns_non_empty_string ______

self = <core.test_mapper.TestColumnMapper object at 0x129d57a80>
discovered_datasets = {'all_datasets': ['uploaded'], 'available': [], 'configs': {}}

    @pytest.mark.slow
    @pytest.mark.integration
    def test_get_default_outcome_returns_non_empty_string(self, discovered_datasets):
        """Test getting default outcome returns non-empty string."""
        # Arrange: Get config and create mapper
>       config = get_first_available_dataset_config(discovered_datasets)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_mapper.py:112:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/core/test_mapper.py:38: in get_first_available_dataset_config
    logger.warning(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Logger core.test_mapper (WARNING)>
msg = 'test_mapper_no_datasets_available', args = ()
kwargs = {'all_datasets': ['uploaded'], 'reason': 'all datasets filtered out or none discovered'}

    def warning(self, msg, *args, **kwargs):
        """
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
        """
        if self.isEnabledFor(WARNING):
>           self._log(WARNING, msg, args, **kwargs)
E           TypeError: Logger._log() got an unexpected keyword argument 'all_datasets'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/logging/__init__.py:1532: TypeError
____________ TestColumnMapper.test_get_default_filters_returns_dict ____________

self = <core.test_mapper.TestColumnMapper object at 0x129f627b0>
discovered_datasets = {'all_datasets': ['uploaded'], 'available': [], 'configs': {}}

    @pytest.mark.slow
    @pytest.mark.integration
    def test_get_default_filters_returns_dict(self, discovered_datasets):
        """Test getting default filters returns dict."""
        # Arrange: Get config and create mapper
>       config = get_first_available_dataset_config(discovered_datasets)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_mapper.py:129:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/core/test_mapper.py:38: in get_first_available_dataset_config
    logger.warning(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Logger core.test_mapper (WARNING)>
msg = 'test_mapper_no_datasets_available', args = ()
kwargs = {'all_datasets': ['uploaded'], 'reason': 'all datasets filtered out or none discovered'}

    def warning(self, msg, *args, **kwargs):
        """
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
        """
        if self.isEnabledFor(WARNING):
>           self._log(WARNING, msg, args, **kwargs)
E           TypeError: Logger._log() got an unexpected keyword argument 'all_datasets'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/logging/__init__.py:1532: TypeError
_ TestFilterExtractionStrategy1ToStrategy2Handoff.test_strategy1_passes_coded_column_to_strategy2 _

self = <core.test_nl_query_engine_filter_extraction.TestFilterExtractionStrategy1ToStrategy2Handoff object at 0x12a03de50>
mock_semantic_layer = <function mock_semantic_layer.<locals>._make at 0x13801b240>
mock_llm_calls = <MagicMock name='call_llm' id='6158246848'>
nl_query_engine_with_cached_model = <function nl_query_engine_with_cached_model.<locals>._create_engine at 0x13801b1a0>

    def test_strategy1_passes_coded_column_to_strategy2(
        self, mock_semantic_layer, mock_llm_calls, nl_query_engine_with_cached_model
    ):
        """
        Test that when Strategy 1 finds a coded column via fuzzy matching,
        Strategy 2 uses it directly instead of searching again.

        This fixes the bug where "statins" (plural) matched to "Statin Used" (singular)
        but Strategy 2 couldn't find it because it searched for "statins" in aliases.
        """
        # Arrange: Create semantic layer where "statins" (plural) will fuzzy match to "statin_used" (singular)
        # The alias contains "statin" (singular), not "statins" (plural)
        # Note: mock_semantic_layer returns {canonical: alias}, but get_column_alias_index
        # should return {alias: canonical}. So we need to set it up correctly
        statin_alias = "Statin Used: 0: n/a 1: Atorvastatin 2: Rosuvastatin 3: Simvastatin"
        canonical_name = "statin_used"

        # Mock returns {alias: canonical} for get_column_alias_index (as per real semantic layer)
        from unittest.mock import MagicMock

        mock = MagicMock()
        mock.get_column_alias_index.return_value = {
            statin_alias: canonical_name,  # {alias: canonical}
            "statin used": canonical_name,  # normalized version
        }
        mock.get_collision_suggestions.return_value = None
        mock.get_collision_warnings.return_value = set()
        mock._normalize_alias = lambda x: x.lower().replace(" ", "_")
        # Mock _fuzzy_match_variable to return the canonical name when matching "statins"
        # This simulates Strategy 1 finding the column
        mock.get_column_metadata.return_value = {
            "type": "categorical",
            "metadata": {"numeric": True, "values": [0, 1, 2, 3]},
        }

        engine = nl_query_engine_with_cached_model(semantic_layer=mock)
        # Override _fuzzy_match_variable to return canonical_name for "statins"
        original_fuzzy = engine._fuzzy_match_variable

        def mock_fuzzy(term):
            if "statin" in term.lower():
                return canonical_name, 0.9, None
            return original_fuzzy(term)

        engine._fuzzy_match_variable = mock_fuzzy

        # Act: Extract filters - "statins" should match to "statin_used" via Strategy 1,
        # then Strategy 2 should use that column directly instead of searching
        query = "how many patients were on statins"
        intent = engine.parse_query(query)

        # Assert: Should extract filter with numeric codes (not string "statins")
        assert intent is not None, "Query should parse successfully"
>       assert len(intent.filters) > 0, "Should extract at least one filter for 'on statins'"
E       AssertionError: Should extract at least one filter for 'on statins'
E       assert 0 > 0
E        +  where 0 = len([])
E        +    where [] = QueryIntent(intent_type='COUNT', primary_variable=None, grouping_variable=None, predictor_variables=[], time_variable=None, event_variable=None, filters=[], confidence=0.8, parsing_tier='pattern_match', parsing_attempts=[{'tier': 'pattern_match', 'result': 'success', 'confidence': 0.9}], failure_reason=None, suggestions=[], follow_ups=[], follow_up_explanation='', interpretation='', confidence_explanation='').filters

tests/core/test_nl_query_engine_filter_extraction.py:478: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-01 20:44:54 [info     ] query_parse_start              dataset_id=None query='how many patients were on statins' upload_id=None
2026-01-01 20:44:54 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='how many patients were on statins' tier=pattern_match upload_id=None
2026-01-01 20:44:54 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'statin_used', 'operator': 'IN', 'value': [1, 2, 3]}] query='how many patients were on statins'
2026-01-01 20:44:54 [debug    ] regex_filter_validation_failed error="Column 'statin_used' not found in dataset" filter=FilterSpec(column='statin_used', operator='IN', value=[1, 2, 3], exclude_nulls=True)
2026-01-01 20:44:54 [debug    ] regex_filters_invalidated      confidence=0.8 invalid_count=1 query='how many patients were on statins' valid_count=0
2026-01-01 20:44:54 [debug    ] grouping_extraction_failed     intent_type=COUNT query='how many patients were on statins'
___ TestExclusionFilters.test_exclusion_filter_works_for_any_medication_type ___

self = <core.test_nl_query_engine_filter_extraction.TestExclusionFilters object at 0x12a0786b0>
mock_semantic_layer = <function mock_semantic_layer.<locals>._make at 0x16b1eb2e0>
mock_llm_calls = <MagicMock name='call_llm' id='6092941568'>
nl_query_engine_with_cached_model = <function nl_query_engine_with_cached_model.<locals>._create_engine at 0x13801a0c0>

    def test_exclusion_filter_works_for_any_medication_type(
        self, mock_semantic_layer, mock_llm_calls, nl_query_engine_with_cached_model
    ):
        """Test that exclusion filters are generic and work for any medication/treatment type."""
        # Arrange: Create semantic layer with diabetes medication column (different domain)
        diabetes_column_value = "Diabetes Medication: 0: n/a 1: Metformin 2: Insulin 3: Glipizide"
        mock = mock_semantic_layer(
            columns={
                diabetes_column_value: "diabetes_medication",  # alias -> canonical
                "diabetes medication": "diabetes_medication",  # normalized alias -> canonical
                "diabetes meds": "diabetes_medication",  # partial match -> canonical
            }
        )
        # Mock metadata to indicate coded column
        mock.get_column_metadata.return_value = {
            "type": "categorical",
            "metadata": {"numeric": True, "values": [0, 1, 2, 3]},
        }
        engine = nl_query_engine_with_cached_model(semantic_layer=mock)

        # Act: Extract filters from exclusion query (different domain)
        query = "excluding those not on diabetes medication"
        intent = engine.parse_query(query)

        # Assert: Should extract filter to exclude code 0 (generic, not hardcoded)
        assert intent is not None
        assert len(intent.filters) > 0
        exclusion_filter = intent.filters[0]
>       assert exclusion_filter.column == "diabetes_medication"
E       AssertionError: assert 'statin_used' == 'diabetes_medication'
E
E         - diabetes_medication
E         + statin_used

tests/core/test_nl_query_engine_filter_extraction.py:793: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-01 20:44:55 [info     ] query_parse_start              dataset_id=None query='excluding those not on diabetes medication' upload_id=None
2026-01-01 20:44:55 [debug    ] llm_raw_response_received      has_conversation_history=False query='excluding those not on diabetes medication' response_length=240 response_preview='{"intent": "COUNT", "metric": null, "group_by": "statin_used", "filters": [{"column": "statin_used", "operator": "!=", "value": 0, "exclude_nulls": true}], "confidence": 0.8, "explanation": "Refining '
2026-01-01 20:44:55 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='excluding those not on diabetes medication' valid_count=0
2026-01-01 20:44:55 [info     ] llm_parse_success              confidence=0.8 intent_type=COUNT query='excluding those not on diabetes medication'
2026-01-01 20:44:55 [info     ] query_parse_success            confidence=0.8 dataset_id=None intent=COUNT matched_vars=['statin_used'] query='excluding those not on diabetes medication' tier=llm_fallback upload_id=None
2026-01-01 20:44:55 [debug    ] filters_extracted              filter_count=2 filters=[{'column': 'diabetes_medication', 'operator': '!=', 'value': 0}, {'column': 'diabetes_medication', 'operator': 'IN', 'value': [1, 2, 3]}] query='excluding those not on diabetes medication'
2026-01-01 20:44:55 [debug    ] filters_extracted_in_parse     filter_count=3 intent_type=COUNT query='excluding those not on diabetes medication'
____ TestExclusionFilters.test_exclusion_filter_works_for_any_coded_column _____

self = <core.test_nl_query_engine_filter_extraction.TestExclusionFilters object at 0x12a0787c0>
mock_semantic_layer = <function mock_semantic_layer.<locals>._make at 0x1380198a0>
mock_llm_calls = <MagicMock name='call_llm' id='13258626048'>
nl_query_engine_with_cached_model = <function nl_query_engine_with_cached_model.<locals>._create_engine at 0x138019800>

    def test_exclusion_filter_works_for_any_coded_column(
        self, mock_semantic_layer, mock_llm_calls, nl_query_engine_with_cached_model
    ):
        """Test that exclusion filters work for any coded column, not just medications."""
        # Arrange: Create semantic layer with treatment column (different domain)
        treatment_column_value = "Treatment Type: 0: None 1: Surgery 2: Chemotherapy 3: Radiation"
        mock = mock_semantic_layer(
            columns={
                treatment_column_value: "treatment_type",  # alias -> canonical
                "treatment type": "treatment_type",  # normalized alias -> canonical
                "treatment": "treatment_type",  # partial match -> canonical
            }
        )
        # Mock metadata to indicate coded column
        mock.get_column_metadata.return_value = {
            "type": "categorical",
            "metadata": {"numeric": True, "values": [0, 1, 2, 3]},
        }
        engine = nl_query_engine_with_cached_model(semantic_layer=mock)

        # Act: Extract filters from exclusion query (different domain)
        query = "excluding patients not on treatment"
        intent = engine.parse_query(query)

        # Assert: Should extract filter to exclude code 0 (generic pattern)
        assert intent is not None
        assert len(intent.filters) > 0
        exclusion_filter = intent.filters[0]
>       assert exclusion_filter.column == "treatment_type"
E       AssertionError: assert 'statin_used' == 'treatment_type'
E
E         - treatment_type
E         + statin_used

tests/core/test_nl_query_engine_filter_extraction.py:826: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-01 20:44:55 [info     ] query_parse_start              dataset_id=None query='excluding patients not on treatment' upload_id=None
2026-01-01 20:44:55 [debug    ] llm_raw_response_received      has_conversation_history=False query='excluding patients not on treatment' response_length=240 response_preview='{"intent": "COUNT", "metric": null, "group_by": "statin_used", "filters": [{"column": "statin_used", "operator": "!=", "value": 0, "exclude_nulls": true}], "confidence": 0.8, "explanation": "Refining '
2026-01-01 20:44:55 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='excluding patients not on treatment' valid_count=0
2026-01-01 20:44:55 [info     ] llm_parse_success              confidence=0.8 intent_type=COUNT query='excluding patients not on treatment'
2026-01-01 20:44:55 [info     ] query_parse_success            confidence=0.8 dataset_id=None intent=COUNT matched_vars=['statin_used'] query='excluding patients not on treatment' tier=llm_fallback upload_id=None
2026-01-01 20:44:55 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'treatment_type', 'operator': '!=', 'value': 0}] query='excluding patients not on treatment'
2026-01-01 20:44:55 [debug    ] filters_extracted_in_parse     filter_count=2 intent_type=COUNT query='excluding patients not on treatment'
___________ test_parse_query_refinement_merges_with_existing_filters ___________

make_semantic_layer = <function make_semantic_layer.<locals>._make at 0x138013600>
mock_llm_calls = <MagicMock name='call_llm' id='6158239792'>
nl_query_engine_with_cached_model = <function nl_query_engine_with_cached_model.<locals>._create_engine at 0x138013420>

    def test_parse_query_refinement_merges_with_existing_filters(
        make_semantic_layer,
        mock_llm_calls,
        nl_query_engine_with_cached_model,
    ):
        """Test that LLM merges refinement filter with existing filters."""
        # Arrange
        semantic = make_semantic_layer(
            dataset_name="test",
            data={
                "patient_id": ["P1", "P2", "P3"],
                "age": [45, 52, 38],
                "status": [0, 1, 1],  # 0=unknown, 1=active
            },
        )
        engine = nl_query_engine_with_cached_model(semantic_layer=semantic)

        # Previous query already had an age filter
        conversation_history = [
            {
                "query": "count patients over 50",
                "intent": "COUNT",
                "group_by": None,
                "filters_applied": [
                    {
                        "column": "age",
                        "operator": ">",
                        "value": 50,
                        "exclude_nulls": True,
                    }
                ],
            }
        ]

        # Act: Add refinement to exclude unknown status
        result = engine.parse_query(
            query="exclude unknown status",
            conversation_history=conversation_history,
        )

        # Assert: Should have both filters
        assert result.intent_type == "COUNT"
        assert len(result.filters) >= 2, "Should have age + status filters"

        # Should preserve age filter
        age_filters = [f for f in result.filters if f.column == "age"]
>       assert len(age_filters) == 1
E       assert 0 == 1
E        +  where 0 = len([])

tests/core/test_nl_query_refinement.py:147: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-01 20:45:18 [info     ] query_parse_start              dataset_id=None query='exclude unknown status' upload_id=None
2026-01-01 20:45:18 [info     ] llm_refinement_parsing_started conversation_history_count=1 previous_filters=[{'column': 'age', 'operator': '>', 'value': 50, 'exclude_nulls': True}] previous_group_by=None previous_intent=COUNT previous_query='count patients over 50' query='exclude unknown status'
2026-01-01 20:45:18 [debug    ] llm_raw_response_received      has_conversation_history=True query='exclude unknown status' response_length=240 response_preview='{"intent": "COUNT", "metric": null, "group_by": "statin_used", "filters": [{"column": "statin_used", "operator": "!=", "value": 0, "exclude_nulls": true}], "confidence": 0.8, "explanation": "Refining '
2026-01-01 20:45:18 [info     ] llm_refinement_parsing_completed extracted_confidence=0.8 extracted_filters_count=1 extracted_group_by=statin_used extracted_intent=COUNT filters_extracted=[{'column': 'statin_used', 'operator': '!=', 'value': 0}] group_by_matches_previous=None intent_matches_previous=True previous_group_by=None previous_intent=COUNT query='exclude unknown status'
2026-01-01 20:45:18 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='exclude unknown status' valid_count=0
2026-01-01 20:45:18 [info     ] llm_parse_success              confidence=0.8 intent_type=COUNT query='exclude unknown status'
2026-01-01 20:45:18 [info     ] query_parse_success            confidence=0.8 dataset_id=None intent=COUNT matched_vars=['statin_used'] query='exclude unknown status' tier=llm_fallback upload_id=None
2026-01-01 20:45:18 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'status', 'operator': '!=', 'value': 'unknown status'}] query='exclude unknown status'
2026-01-01 20:45:18 [debug    ] filters_extracted_in_parse     filter_count=2 intent_type=COUNT query='exclude unknown status'
____________ test_parse_query_refinement_updates_same_column_filter ____________

make_semantic_layer = <function make_semantic_layer.<locals>._make at 0x138012b60>
mock_llm_calls = <MagicMock name='call_llm' id='6158240464'>
nl_query_engine_with_cached_model = <function nl_query_engine_with_cached_model.<locals>._create_engine at 0x138012980>

    def test_parse_query_refinement_updates_same_column_filter(
        make_semantic_layer,
        mock_llm_calls,
        nl_query_engine_with_cached_model,
    ):
        """Test that LLM replaces filter on same column when refined."""
        # Arrange
        semantic = make_semantic_layer(
            dataset_name="test",
            data={
                "patient_id": ["P1", "P2", "P3"],
                "age": [45, 52, 68],
            },
        )
        engine = nl_query_engine_with_cached_model(semantic_layer=semantic)

        conversation_history = [
            {
                "query": "patients over 50",
                "intent": "COUNT",
                "filters_applied": [
                    {
                        "column": "age",
                        "operator": ">",
                        "value": 50,
                        "exclude_nulls": True,
                    }
                ],
            }
        ]

        # Act: Refine the age filter
        result = engine.parse_query(
            query="actually make it over 65",
            conversation_history=conversation_history,
        )

        # Assert: LLM should update age filter, not duplicate
        age_filters = [f for f in result.filters if f.column == "age"]
>       assert len(age_filters) == 1, "Should only have one age filter (updated)"
E       AssertionError: Should only have one age filter (updated)
E       assert 0 == 1
E        +  where 0 = len([])

tests/core/test_nl_query_refinement.py:195: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-01 20:45:18 [info     ] query_parse_start              dataset_id=None query='actually make it over 65' upload_id=None
2026-01-01 20:45:18 [info     ] llm_refinement_parsing_started conversation_history_count=1 previous_filters=[{'column': 'age', 'operator': '>', 'value': 50, 'exclude_nulls': True}] previous_group_by=None previous_intent=COUNT previous_query='patients over 50' query='actually make it over 65'
2026-01-01 20:45:18 [debug    ] llm_raw_response_received      has_conversation_history=True query='actually make it over 65' response_length=240 response_preview='{"intent": "COUNT", "metric": null, "group_by": "statin_used", "filters": [{"column": "statin_used", "operator": "!=", "value": 0, "exclude_nulls": true}], "confidence": 0.8, "explanation": "Refining '
2026-01-01 20:45:18 [info     ] llm_refinement_parsing_completed extracted_confidence=0.8 extracted_filters_count=1 extracted_group_by=statin_used extracted_intent=COUNT filters_extracted=[{'column': 'statin_used', 'operator': '!=', 'value': 0}] group_by_matches_previous=None intent_matches_previous=True previous_group_by=None previous_intent=COUNT query='actually make it over 65'
2026-01-01 20:45:18 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='actually make it over 65' valid_count=0
2026-01-01 20:45:18 [info     ] llm_parse_success              confidence=0.8 intent_type=COUNT query='actually make it over 65'
2026-01-01 20:45:18 [info     ] query_parse_success            confidence=0.8 dataset_id=None intent=COUNT matched_vars=['statin_used'] query='actually make it over 65' tier=llm_fallback upload_id=None
2026-01-01 20:45:18 [debug    ] filters_extracted              filter_count=0 filters=[] query='actually make it over 65'
2026-01-01 20:45:18 [debug    ] filters_extracted_in_parse     filter_count=1 intent_type=COUNT query='actually make it over 65'
______________ test_llm_refinement_with_coded_categorical_column _______________

make_cohort_with_categorical = <function make_cohort_with_categorical.<locals>._make at 0x13801a020>
make_semantic_layer = <function make_semantic_layer.<locals>._make at 0x1380180e0>
mock_llm_calls = <MagicMock name='call_llm' id='13258625376'>
nl_query_engine_with_cached_model = <function nl_query_engine_with_cached_model.<locals>._create_engine at 0x1380122a0>

    def test_llm_refinement_with_coded_categorical_column(
        make_cohort_with_categorical,
        make_semantic_layer,
        mock_llm_calls,
        nl_query_engine_with_cached_model,
    ):
        """Test LLM handles refinement with coded categorical columns correctly."""
        # Arrange: Use factory fixture for categorical cohort
>       cohort = make_cohort_with_categorical(
            patient_ids=["P1", "P2", "P3", "P4"],
            ages=[45, 52, 38, 61],
            treatment=["1: Control", "2: Treatment A", "1: Control", "2: Treatment A"],
        )

tests/core/test_nl_query_refinement.py:313:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/conftest.py:1024: in _make
    return pl.DataFrame(
.venv/lib/python3.13/site-packages/polars/dataframe/frame.py:377: in __init__
    self._df = dict_to_pydf(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

data = {'age': [45, 52, 38, 61], 'patient_id': ['P1', 'P2', 'P3', 'P4'], 'status': ['1: Active', '2: Inactive', '1: Active', '1: Active', '2: Inactive'], 'treatment': ['1: Control', '2: Treatment A', '1: Control', '2: Treatment A']}
schema = None

    def dict_to_pydf(
        data: Mapping[str, Sequence[object] | Mapping[str, Sequence[object]] | Series],
        schema: SchemaDefinition | None = None,
        *,
        schema_overrides: SchemaDict | None = None,
        strict: bool = True,
        nan_to_null: bool = False,
        allow_multithreaded: bool = True,
    ) -> PyDataFrame:
        """Construct a PyDataFrame from a dictionary of sequences."""
        if isinstance(schema, Mapping) and data:
            if not all((col in schema) for col in data):
                msg = "the given column-schema names do not match the data dictionary"
                raise ValueError(msg)
            data = {col: data[col] for col in schema}

        column_names, schema_overrides = _unpack_schema(
            schema, lookup_names=data.keys(), schema_overrides=schema_overrides
        )
        if not column_names:
            column_names = list(data)

        if data and _NUMPY_AVAILABLE:
            # if there are 3 or more numpy arrays of sufficient size, we multi-thread:
            count_numpy = sum(
                int(
                    allow_multithreaded
                    and _check_for_numpy(val)
                    and isinstance(val, np.ndarray)
                    and len(val) > _MIN_NUMPY_SIZE_FOR_MULTITHREADING
                    # integers and non-nan floats are zero-copy
                    and nan_to_null
                    and val.dtype in (np.float32, np.float64)
                )
                for val in data.values()
            )
            if count_numpy >= 3:
                # yes, multi-threading was easier in python here; we cannot have multiple
                # threads running python and release the gil in pyo3 (it will deadlock).

                # (note: 'dummy' is threaded)
                # We catch FileNotFoundError: see 16675
                try:
                    import multiprocessing.dummy

                    pool_size = thread_pool_size()
                    with multiprocessing.dummy.Pool(pool_size) as pool:
                        data = dict(
                            zip(
                                column_names,
                                pool.map(
                                    lambda t: (
                                        pl.Series(t[0], t[1], nan_to_null=nan_to_null)
                                        if isinstance(t[1], np.ndarray)
                                        else t[1]
                                    ),
                                    list(data.items()),
                                ),
                            )
                        )
                except FileNotFoundError:
                    return dict_to_pydf(
                        data=data,
                        schema=schema,
                        schema_overrides=schema_overrides,
                        strict=strict,
                        nan_to_null=nan_to_null,
                        allow_multithreaded=False,
                    )

        if not data and schema_overrides:
            data_series = [
                pl.Series(
                    name,
                    [],
                    dtype=schema_overrides.get(name),
                    strict=strict,
                    nan_to_null=nan_to_null,
                )._s
                for name in column_names
            ]
        else:
            data_series = [
                s._s
                for s in _expand_dict_values(
                    data,
                    schema_overrides=schema_overrides,
                    strict=strict,
                    nan_to_null=nan_to_null,
                ).values()
            ]

        data_series = _handle_columns_arg(data_series, columns=column_names, from_dict=True)
>       pydf = PyDataFrame(data_series)
               ^^^^^^^^^^^^^^^^^^^^^^^^
E       polars.exceptions.ShapeError: could not create a new DataFrame: height of column 'status' (5) does not match height of column 'patient_id' (4)

.venv/lib/python3.13/site-packages/polars/_utils/construction/dataframe.py:170: ShapeError
_________________ test_llm_provides_explanation_for_refinement _________________

make_semantic_layer = <function make_semantic_layer.<locals>._make at 0x170962020>
mock_llm_calls = <MagicMock name='call_llm' id='4331045952'>
nl_query_engine_with_cached_model = <function nl_query_engine_with_cached_model.<locals>._create_engine at 0x170962200>

    def test_llm_provides_explanation_for_refinement(
        make_semantic_layer,
        mock_llm_calls,
        nl_query_engine_with_cached_model,
    ):
        """Test that LLM provides explanation when handling refinement."""
        # Arrange
        semantic = make_semantic_layer(
            dataset_name="test",
            data={"patient_id": ["P1", "P2"], "status": [0, 1]},
        )
        engine = nl_query_engine_with_cached_model(semantic_layer=semantic)

        conversation_history = [
            {
                "query": "count patients",
                "intent": "COUNT",
            }
        ]

        # Act
        result = engine.parse_query(
            query="exclude unknowns",
            conversation_history=conversation_history,
        )

        # Assert: LLM should provide explanation of refinement
        # QueryIntent uses 'interpretation' field, not 'explanation'
>       assert result.interpretation, "Should have interpretation"
E       AssertionError: Should have interpretation
E       assert ''
E        +  where '' = QueryIntent(intent_type='COUNT', primary_variable=None, grouping_variable='statin_used', predictor_variables=[], time_variable=None, event_variable=None, filters=[FilterSpec(column='statin_used', operator='!=', value=0, exclude_nulls=True)], confidence=0.8, parsing_tier='llm_fallback', parsing_attempts=[{'tier': 'pattern_match', 'result': 'failed', 'confidence': 0.0}, {'tier': 'semantic_match', 'result': 'failed', 'confidence': 0.0}, {'tier': 'llm_fallback', 'result': 'success', 'confidence': 0.8}], failure_reason=None, suggestions=[], follow_ups=[], follow_up_explanation='', interpretation='', confidence_explanation='').interpretation

tests/core/test_nl_query_refinement.py:374: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-01 20:45:19 [info     ] query_parse_start              dataset_id=None query='exclude unknowns' upload_id=None
2026-01-01 20:45:19 [info     ] llm_refinement_parsing_started conversation_history_count=1 previous_filters=[] previous_group_by=None previous_intent=COUNT previous_query='count patients' query='exclude unknowns'
2026-01-01 20:45:19 [debug    ] llm_raw_response_received      has_conversation_history=True query='exclude unknowns' response_length=240 response_preview='{"intent": "COUNT", "metric": null, "group_by": "statin_used", "filters": [{"column": "statin_used", "operator": "!=", "value": 0, "exclude_nulls": true}], "confidence": 0.8, "explanation": "Refining '
2026-01-01 20:45:19 [info     ] llm_refinement_parsing_completed extracted_confidence=0.8 extracted_filters_count=1 extracted_group_by=statin_used extracted_intent=COUNT filters_extracted=[{'column': 'statin_used', 'operator': '!=', 'value': 0}] group_by_matches_previous=None intent_matches_previous=True previous_group_by=None previous_intent=COUNT query='exclude unknowns'
2026-01-01 20:45:19 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='exclude unknowns' valid_count=0
2026-01-01 20:45:19 [info     ] llm_parse_success              confidence=0.8 intent_type=COUNT query='exclude unknowns'
2026-01-01 20:45:19 [info     ] query_parse_success            confidence=0.8 dataset_id=None intent=COUNT matched_vars=['statin_used'] query='exclude unknowns' tier=llm_fallback upload_id=None
2026-01-01 20:45:19 [debug    ] filters_extracted              filter_count=0 filters=[] query='exclude unknowns'
2026-01-01 20:45:19 [debug    ] filters_extracted_in_parse     filter_count=1 intent_type=COUNT query='exclude unknowns'
________ test_parse_query_refinement_handles_llm_failure_with_fallback _________

make_semantic_layer = <function make_semantic_layer.<locals>._make at 0x170962520>
mock_llm_calls = <MagicMock name='call_llm' id='13258629072'>
nl_query_engine_with_cached_model = <function nl_query_engine_with_cached_model.<locals>._create_engine at 0x170962c00>

    def test_parse_query_refinement_handles_llm_failure_with_fallback(
        make_semantic_layer,
        mock_llm_calls,
        nl_query_engine_with_cached_model,
    ):
        """
        Test that refinement queries work even when LLM returns invalid response.

        This tests the exact scenario from the terminal where LLM returns
        {"query": "remove the n/a"} instead of proper QueryPlan schema.
        The system should fall back to refinement handler that merges with previous context.
        """
        # Arrange: Create semantic layer with statin column matching terminal scenario
        statin_col = (
            "Statin Used:    0: n/a                       1: Atorvastatin  "
            "2: Rosuvastatin 3: Pravastatin   4: Pitavastatin  5: Simvastatin"
        )
        semantic = make_semantic_layer(
            dataset_name="test_statins",
            data={
                "patient_id": ["P1", "P2", "P3", "P4"],
                statin_col: [0, 1, 2, 1],
                "age": [45, 52, 38, 61],
            },
        )
        engine = nl_query_engine_with_cached_model(semantic_layer=semantic)

        # Previous query: count by statin (all values including n/a)
        conversation_history = [
            {
                "query": "what statins were those patients on, broken down by count of patients per statin?",
                "intent": "COUNT",
                "group_by": statin_col,
                "metric": None,
                "filters_applied": [],
                "run_key": "abc123",
                "timestamp": 100.0,
            }
        ]

        # Act: Parse refinement query "remove the n/a" with conversation context
        # This should work even if LLM fails and returns invalid response
        result = engine.parse_query(
            query="remove the n/a",
            conversation_history=conversation_history,
        )

        # Assert: Should maintain previous intent and grouping
        assert result.intent_type == "COUNT", "Should maintain previous COUNT intent"
>       assert result.grouping_variable == statin_col, "Should maintain previous grouping"
E       AssertionError: Should maintain previous grouping
E       assert 'statin_used' == 'Statin Used:...: Simvastatin'
E
E         - Statin Used:    0: n/a                       1: Atorvastatin  2: Rosuvastatin 3: Pravastatin   4: Pitavastatin  5: Simvastatin
E         + statin_used

tests/core/test_nl_query_refinement.py:432: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-01 20:45:19 [info     ] query_parse_start              dataset_id=None query='remove the n/a' upload_id=None
2026-01-01 20:45:19 [info     ] llm_refinement_parsing_started conversation_history_count=1 previous_filters=[] previous_group_by='Statin Used:    0: n/a                       1: Atorvastatin  2: Rosuvastatin 3: Pravastatin   4: Pitavastatin  5: Simvastatin' previous_intent=COUNT previous_query='what statins were those patients on, broken down by count of patients per statin?' query='remove the n/a'
2026-01-01 20:45:19 [debug    ] llm_raw_response_received      has_conversation_history=True query='remove the n/a' response_length=240 response_preview='{"intent": "COUNT", "metric": null, "group_by": "statin_used", "filters": [{"column": "statin_used", "operator": "!=", "value": 0, "exclude_nulls": true}], "confidence": 0.8, "explanation": "Refining '
2026-01-01 20:45:19 [info     ] llm_refinement_parsing_completed extracted_confidence=0.8 extracted_filters_count=1 extracted_group_by=statin_used extracted_intent=COUNT filters_extracted=[{'column': 'statin_used', 'operator': '!=', 'value': 0}] group_by_matches_previous=False intent_matches_previous=True previous_group_by='Statin Used:    0: n/a                       1: Atorvastatin  2: Rosuvastatin 3: Pravastatin   4: Pitavastatin  5: Simvastatin' previous_intent=COUNT query='remove the n/a'
2026-01-01 20:45:19 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='remove the n/a' valid_count=0
2026-01-01 20:45:19 [info     ] llm_parse_success              confidence=0.8 intent_type=COUNT query='remove the n/a'
2026-01-01 20:45:19 [info     ] query_parse_success            confidence=0.8 dataset_id=None intent=COUNT matched_vars=['statin_used'] query='remove the n/a' tier=llm_fallback upload_id=None
2026-01-01 20:45:19 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'statin_used', 'operator': '!=', 'value': 0}] query='remove the n/a'
2026-01-01 20:45:19 [debug    ] regex_filter_validation_failed error="Column 'statin_used' not found in dataset" filter=FilterSpec(column='statin_used', operator='!=', value=0, exclude_nulls=True)
2026-01-01 20:45:19 [debug    ] regex_filters_invalidated      confidence=0.7000000000000001 invalid_count=1 query='remove the n/a' valid_count=0
2026-01-01 20:45:19 [debug    ] filters_extracted_in_parse     filter_count=1 intent_type=COUNT query='remove the n/a'
_____ test_optimizer_analyze_failures_with_invalid_intent_detects_pattern ______

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})
sample_test_results_with_invalid_intent = [{'actual_intent': 'REMOVE_NA', 'expected_intent': 'COUNT', 'passed': False, 'query': 'remove the n/a'}, {'actual_inte...'exclude unknowns'}, {'actual_intent': 'COUNT', 'expected_intent': 'COUNT', 'passed': True, 'query': 'count patients'}]

    def test_optimizer_analyze_failures_with_invalid_intent_detects_pattern(
        sample_learning_config, sample_test_results_with_invalid_intent
    ):
        """Test that optimizer detects invalid intent pattern from failures."""
        # Arrange: Create optimizer with config
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:165:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x12a0db300>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
___ test_optimizer_analyze_failures_with_refinement_failures_detects_pattern ___

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})
sample_test_results_with_refinement_failures = [{'actual_intent': 'DESCRIBE', 'conversation_history': [{'group_by': 'statin', 'intent': 'COUNT'}], 'expected_intent':...tion_history': [{'intent': 'DESCRIBE', 'metric': 'cholesterol'}], 'expected_intent': 'DESCRIBE', 'passed': False, ...}]

    def test_optimizer_analyze_failures_with_refinement_failures_detects_pattern(
        sample_learning_config, sample_test_results_with_refinement_failures
    ):
        """Test that optimizer detects refinement ignored pattern from failures."""
        # Arrange: Create optimizer with config
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:183:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e198740>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
_____ test_optimizer_analyze_failures_with_all_passing_returns_empty_list ______

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})
sample_test_results_all_passing = [{'actual_intent': 'COUNT', 'expected_intent': 'COUNT', 'passed': True, 'query': 'count patients'}, {'actual_intent': 'DESCRIBE', 'expected_intent': 'DESCRIBE', 'passed': True, 'query': 'average age'}]

    def test_optimizer_analyze_failures_with_all_passing_returns_empty_list(
        sample_learning_config, sample_test_results_all_passing
    ):
        """Test that optimizer returns no patterns when all tests pass."""
        # Arrange: Create optimizer with config
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:201:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e199ee0>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
_______ test_optimizer_generate_fix_from_template_replaces_placeholders ________

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_generate_fix_from_template_replaces_placeholders(sample_learning_config):
        """Test that fix generation replaces template placeholders correctly."""
        # Arrange: Create optimizer and template
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:214:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x12a331850>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
_____ test_optimizer_generate_prompt_additions_with_patterns_returns_text ______

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})
sample_test_results_with_invalid_intent = [{'actual_intent': 'REMOVE_NA', 'expected_intent': 'COUNT', 'passed': False, 'query': 'remove the n/a'}, {'actual_inte...'exclude unknowns'}, {'actual_intent': 'COUNT', 'expected_intent': 'COUNT', 'passed': True, 'query': 'count patients'}]

    def test_optimizer_generate_prompt_additions_with_patterns_returns_text(
        sample_learning_config, sample_test_results_with_invalid_intent
    ):
        """Test that prompt additions are generated from failure patterns."""
        # Arrange: Create optimizer and analyze failures
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:232:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37d700>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
___ test_optimizer_generate_prompt_additions_with_no_patterns_returns_empty ____

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_generate_prompt_additions_with_no_patterns_returns_empty(
        sample_learning_config,
    ):
        """Test that no prompt additions generated when no patterns detected."""
        # Arrange: Create optimizer with no patterns
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:248:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37d230>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
____ test_optimizer_get_keyword_hints_with_matching_keyword_returns_intent _____

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_get_keyword_hints_with_matching_keyword_returns_intent(
        sample_learning_config,
    ):
        """Test that keyword hints return correct intent for matching query."""
        # Arrange: Create optimizer
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:264:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37d3f0>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
_________ test_optimizer_get_keyword_hints_with_no_match_returns_none __________

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_get_keyword_hints_with_no_match_returns_none(sample_learning_config):
        """Test that keyword hints return None when no keyword matches."""
        # Arrange: Create optimizer
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:277:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37e5e0>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
____ test_optimizer_is_refinement_query_with_refinement_phrase_returns_true ____

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_is_refinement_query_with_refinement_phrase_returns_true(
        sample_learning_config,
    ):
        """Test that refinement detection returns True for refinement queries."""
        # Arrange: Create optimizer
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:292:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37f1b0>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
_______ test_optimizer_is_refinement_query_with_no_phrase_returns_false ________

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_is_refinement_query_with_no_phrase_returns_false(
        sample_learning_config,
    ):
        """Test that refinement detection returns False for non-refinement queries."""
        # Arrange: Create optimizer
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:307:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37ece0>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
_____ test_optimizer_evaluate_condition_with_valid_condition_returns_true ______

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_evaluate_condition_with_valid_condition_returns_true(
        sample_learning_config,
    ):
        """Test that condition evaluation returns True for matching conditions."""
        # Arrange: Create optimizer and failure record
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:368:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37f4c0>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
____ test_optimizer_evaluate_condition_with_invalid_condition_returns_false ____

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_evaluate_condition_with_invalid_condition_returns_false(
        sample_learning_config,
    ):
        """Test that condition evaluation returns False for non-matching conditions."""
        # Arrange: Create optimizer and failure record
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:388:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37eea0>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
_____ test_optimizer_analyze_failures_with_none_intent_filters_none_values _____

sample_learning_config = LearningConfig(intent_keywords={'COUNT': ['how many', 'count'], 'DESCRIBE': ['average', 'mean'], 'FIND_PREDICTORS': ['...refinement_phrases}'}], prompt_template='Template: {dynamic_fixes}', logging_config={'enabled': True, 'log_dir': None})

    def test_optimizer_analyze_failures_with_none_intent_filters_none_values(sample_learning_config):
        """Test that optimizer filters None from invalid_intents set without crashing."""
        # Arrange: Create optimizer and test results with None actual_intent
>       optimizer = PromptOptimizer(config=sample_learning_config)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_prompt_optimizer.py:433:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/clinical_analytics/core/prompt_optimizer.py:72: in __init__
    self.log_dir = log_dir or Path(self.config.logging_config.get("log_dir", "/tmp/nl_query_learning"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:503: in __init__
    super().__init__(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <[AttributeError("'pathlib._local.PosixPath' object has no attribute '_raw_paths'") raised in repr()] PosixPath object at 0x31e37d2a0>
args = (None,), paths = [], arg = None, path = None

    def __init__(self, *args):
        paths = []
        for arg in args:
            if isinstance(arg, PurePath):
                if arg.parser is not self.parser:
                    # GH-103631: Convert separators for backwards compatibility.
                    paths.append(arg.as_posix())
                else:
                    paths.extend(arg._raw_paths)
            else:
                try:
                    path = os.fspath(arg)
                except TypeError:
                    path = arg
                if not isinstance(path, str):
>                   raise TypeError(
                        "argument should be a str or an os.PathLike "
                        "object where __fspath__ returns a str, "
                        f"not {type(path).__name__!r}")
E                   TypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py:132: TypeError
________ TestDatasetRegistry.test_get_dataset_factory_creates_instance _________

self = <core.test_registry.TestDatasetRegistry object at 0x12a39c180>
discovered_datasets = {'all_datasets': ['uploaded'], 'available': [], 'configs': {}}

    @pytest.mark.slow
    @pytest.mark.integration
    def test_get_dataset_factory_creates_instance(self, discovered_datasets):
        """Test factory method creates dataset instance."""
        # Arrange
>       dataset_name = get_first_available_dataset(discovered_datasets)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_registry.py:110:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/core/test_registry.py:39: in get_first_available_dataset
    logger.warning(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Logger core.test_registry (WARNING)>
msg = 'test_registry_no_datasets_available', args = ()
kwargs = {'all_datasets': ['uploaded'], 'reason': 'all datasets filtered out or none discovered'}

    def warning(self, msg, *args, **kwargs):
        """
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
        """
        if self.isEnabledFor(WARNING):
>           self._log(WARNING, msg, args, **kwargs)
E           TypeError: Logger._log() got an unexpected keyword argument 'all_datasets'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/logging/__init__.py:1532: TypeError
_ TestDatasetRegistry.test_get_dataset_with_override_params_applies_overrides __

self = <core.test_registry.TestDatasetRegistry object at 0x12a3634d0>
discovered_datasets = {'all_datasets': ['uploaded'], 'available': [], 'configs': {}}

    @pytest.mark.slow
    @pytest.mark.integration
    def test_get_dataset_with_override_params_applies_overrides(self, discovered_datasets):
        """Test getting dataset with override parameters applies overrides."""
        # Arrange
>       dataset_name = get_first_available_dataset(discovered_datasets)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_registry.py:236:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/core/test_registry.py:39: in get_first_available_dataset
    logger.warning(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Logger core.test_registry (WARNING)>
msg = 'test_registry_no_datasets_available', args = ()
kwargs = {'all_datasets': ['uploaded'], 'reason': 'all datasets filtered out or none discovered'}

    def warning(self, msg, *args, **kwargs):
        """
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
        """
        if self.isEnabledFor(WARNING):
>           self._log(WARNING, msg, args, **kwargs)
E           TypeError: Logger._log() got an unexpected keyword argument 'all_datasets'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/logging/__init__.py:1532: TypeError
__ TestDatasetRegistry.test_registry_filters_unsupported_params_without_error __

self = <core.test_registry.TestDatasetRegistry object at 0x12a37c600>
discovered_datasets = {'all_datasets': ['uploaded'], 'available': [], 'configs': {}}
caplog = <_pytest.logging.LogCaptureFixture object at 0x310f2b610>

    @pytest.mark.slow
    @pytest.mark.integration
    def test_registry_filters_unsupported_params_without_error(self, discovered_datasets, caplog):
        """Test that registry filters out unsupported init params without error."""
        # Arrange
>       dataset_name = get_first_available_dataset(discovered_datasets)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/core/test_registry.py:253:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/core/test_registry.py:39: in get_first_available_dataset
    logger.warning(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Logger core.test_registry (WARNING)>
msg = 'test_registry_no_datasets_available', args = ()
kwargs = {'all_datasets': ['uploaded'], 'reason': 'all datasets filtered out or none discovered'}

    def warning(self, msg, *args, **kwargs):
        """
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
        """
        if self.isEnabledFor(WARNING):
>           self._log(WARNING, msg, args, **kwargs)
E           TypeError: Logger._log() got an unexpected keyword argument 'all_datasets'

/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/logging/__init__.py:1532: TypeError
_______________________ test_golden_questions_evaluation _______________________

make_semantic_layer = <function make_semantic_layer.<locals>._make at 0x31e2f0680>

    @pytest.mark.integration
    @pytest.mark.slow
    def test_golden_questions_evaluation(make_semantic_layer):
        """
        Evaluate all golden questions and ensure accuracy is above threshold.

        This is a regression test - if parsing accuracy drops below 80%,
        the test will fail and alert us to degradation.

        Integration test: Uses real NLQueryEngine and SemanticLayer to test
        end-to-end query parsing pipeline.
        """
        # Arrange: Create semantic layer with test data
        semantic_layer = make_semantic_layer(
            data={
                "patient_id": list(range(1, 101)),
                "age": [25 + i % 40 for i in range(100)],
                "gender": ["M" if i % 2 == 0 else "F" for i in range(100)],
                "status": ["active" if i % 3 != 0 else "inactive" for i in range(100)],
                "treatment": ["A" if i % 2 == 0 else "B" for i in range(100)],
                "cholesterol": [150 + i % 100 for i in range(100)],
                "LDL": [100 + i % 80 for i in range(100)],
                "BMI": [20 + i % 15 for i in range(100)],
                "statin": [i % 6 for i in range(100)],  # 0=n/a, 1-5=different statins
            }
        )

        # Load golden questions
        yaml_path = "tests/eval/golden_questions.yaml"
        questions = load_golden_questions(yaml_path)

        # Act: Run evaluation
        harness = EvalHarness(semantic_layer)
        results = harness.evaluate_batch(questions)
        summary = harness.get_summary(results)

        # Print detailed results for failures
        failures = [r for r in results if not r.get("correct", False)]
        if failures:
            print("\n" + "=" * 80)
            print("FAILURES")
            print("=" * 80)
            for result in failures:
                print(f"\n✗ {result['id']}")
                print(f"  Query: {result['query']}")
                print(f"  Expected: {result.get('expected_intent', 'N/A')}")
                print(f"  Actual: {result.get('actual_intent', 'N/A')}")
                print(f"  Confidence: {result.get('confidence', 0.0):.2f}")
                if not result.get("intent_match"):
                    print(f"  ❌ Intent: expected {result.get('expected_intent')}, got {result.get('actual_intent')}")

        # Print summary
        print("\n" + "=" * 80)
        print("SUMMARY")
        print("=" * 80)
        print(f"Total Questions: {summary['total_questions']}")
        print(f"Correct: {summary['correct_count']}")
        print(f"Incorrect: {summary['incorrect_count']}")
        print(f"Accuracy: {summary['accuracy']:.1%}")
        print(f"Intent Accuracy: {summary['intent_accuracy']:.1%}")
        print(f"Average Confidence: {summary['average_confidence']:.2f}")

        # Assert: Accuracy must be above 80%
>       assert summary["accuracy"] >= 0.80, (
            f"Golden questions accuracy ({summary['accuracy']:.1%}) "
            f"is below 80% threshold. This indicates regression in query parsing."
        )
E       AssertionError: Golden questions accuracy (69.2%) is below 80% threshold. This indicates regression in query parsing.
E       assert 0.6923076923076923 >= 0.8

tests/eval/test_golden_questions.py:84: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='how many patients?' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='how many patients?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='how many patients?'
2026-01-01 20:45:22 [debug    ] grouping_extraction_failed     intent_type=COUNT query='how many patients?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='how many patients by status?' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='how many patients by status?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='how many patients by status?'
2026-01-01 20:45:22 [debug    ] grouping_extracted_broken_down column_name=status confidence=0.9 group_phrase=status query='how many patients by status?'
2026-01-01 20:45:22 [info     ] grouping_extracted_from_compound grouping_variable=status intent_type=COUNT query='how many patients by status?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='how many patients broken down by treatment?' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='how many patients broken down by treatment?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='how many patients broken down by treatment?'
2026-01-01 20:45:22 [debug    ] grouping_extracted_broken_down column_name=treatment confidence=0.9 group_phrase=treatment query='how many patients broken down by treatment?'
2026-01-01 20:45:22 [info     ] grouping_extracted_from_compound grouping_variable=treatment intent_type=COUNT query='how many patients broken down by treatment?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='what is the average age?' upload_id=None
2026-01-01 20:45:22 [debug    ] pattern_match_what_is_average  confidence=0.9 matched_var=age variable_term=age
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['age'] query='what is the average age?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='what is the average age?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='average age by gender' upload_id=None
2026-01-01 20:45:22 [debug    ] pattern_match_average_with_variable confidence=0.9 grouping=gender matched_var=age variable_term=age
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['age', 'gender'] query='average age by gender' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='average age by gender'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='describe cholesterol levels' upload_id=None
2026-01-01 20:45:22 [debug    ] pattern_match_describe_with_variable confidence=0.9 matched_var=cholesterol variable_term=cholesterol
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['cholesterol'] query='describe cholesterol levels' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='describe cholesterol levels'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='compare LDL between treatment and control' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.95 dataset_id=None intent=COMPARE_GROUPS matched_vars=['LDL', 'treatment'] query='compare LDL between treatment and control' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='compare LDL between treatment and control'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='compare age across different statuses' upload_id=None
2026-01-01 20:45:22 [debug    ] pattern_match_compare_across   group_term=statuses group_var=status primary_term=age primary_var=age
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.95 dataset_id=None intent=COMPARE_GROUPS matched_vars=['age', 'status'] query='compare age across different statuses' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='compare age across different statuses'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='how many active patients?' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='how many active patients?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='how many active patients?'
2026-01-01 20:45:22 [debug    ] grouping_extraction_failed     intent_type=COUNT query='how many active patients?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='average cholesterol for patients over 50' upload_id=None
2026-01-01 20:45:22 [debug    ] pattern_match_average_with_variable confidence=0.9 grouping=None matched_var=cholesterol variable_term=cholesterol
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['cholesterol'] query='average cholesterol for patients over 50' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'age', 'operator': '>', 'value': 50}] query='average cholesterol for patients over 50'
2026-01-01 20:45:22 [debug    ] filters_extracted_in_parse     filter_count=1 intent_type=DESCRIBE query='average cholesterol for patients over 50'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='how many patients excluding those with missing data?' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='how many patients excluding those with missing data?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='how many patients excluding those with missing data?'
2026-01-01 20:45:22 [debug    ] grouping_extraction_failed     intent_type=COUNT query='how many patients excluding those with missing data?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='how many active patients by treatment group?' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='how many active patients by treatment group?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='how many active patients by treatment group?'
2026-01-01 20:45:22 [debug    ] grouping_extracted_broken_down column_name=treatment confidence=0.7 group_phrase='treatment group' query='how many active patients by treatment group?'
2026-01-01 20:45:22 [info     ] grouping_extracted_from_compound grouping_variable=treatment intent_type=COUNT query='how many active patients by treatment group?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='what is the mean and median age?' upload_id=None
2026-01-01 20:45:22 [debug    ] pattern_match_what_is_average  confidence=0.9 matched_var=age variable_term=age
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['age'] query='what is the mean and median age?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='what is the mean and median age?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='total number of patients' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='total number of patients' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='total number of patients'
2026-01-01 20:45:22 [debug    ] grouping_extraction_failed     intent_type=COUNT query='total number of patients'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='summarize BMI statistics' upload_id=None
2026-01-01 20:45:22 [debug    ] pattern_match_describe_with_variable confidence=0.9 matched_var=BMI variable_term=bmi
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['BMI'] query='summarize BMI statistics' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='summarize BMI statistics'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='what statins were those patients on, broken down by count of patients per statin?' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='what statins were those patients on, broken down by count of patients per statin?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='what statins were those patients on, broken down by count of patients per statin?'
2026-01-01 20:45:22 [debug    ] grouping_extracted_broken_down column_name=statin confidence=0.9 group_phrase=statin query='what statins were those patients on, broken down by count of patients per statin?'
2026-01-01 20:45:22 [info     ] grouping_extracted_from_compound grouping_variable=statin intent_type=COUNT query='what statins were those patients on, broken down by count of patients per statin?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='remove the n/a (0) - what statins were patients on?' upload_id=None
2026-01-01 20:45:22 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=['statin'] query='remove the n/a (0) - what statins were patients on?' tier=pattern_match upload_id=None
2026-01-01 20:45:22 [debug    ] filters_extracted              filter_count=0 filters=[] query='remove the n/a (0) - what statins were patients on?'
2026-01-01 20:45:22 [info     ] query_parse_start              dataset_id=None query='show me the data' upload_id=None
2026-01-01 20:45:30 [debug    ] llm_raw_response_received      has_conversation_history=False query='show me the data' response_length=147 response_preview='{\n  "intent": "DESCRIBE",\n  "metric": null,\n  "group_by": null,\n  "filters": [],\n  "confidence": 0.95,\n  "explanation": "Show all available data"\n}'
2026-01-01 20:45:34 [debug    ] llm_json_parse_success         length=15
2026-01-01 20:45:34 [info     ] llm_call_success               feature=filter_extraction latency_ms=3248.212875012541 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:45:34 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='show me the data' valid_count=0
2026-01-01 20:45:34 [info     ] llm_parse_success              confidence=0.95 intent_type=DESCRIBE query='show me the data'
2026-01-01 20:45:34 [info     ] query_parse_success            confidence=0.95 dataset_id=None intent=DESCRIBE matched_vars=[] query='show me the data' tier=llm_fallback upload_id=None
2026-01-01 20:45:34 [debug    ] filters_extracted              filter_count=0 filters=[] query='show me the data'
2026-01-01 20:45:34 [info     ] query_parse_start              dataset_id=None query='compare the groups' upload_id=None
2026-01-01 20:45:41 [debug    ] llm_raw_response_received      has_conversation_history=False query='compare the groups' response_length=157 response_preview='{\n  "intent": "COMPARE_GROUPS",\n  "metric": null,\n  "group_by": null,\n  "filters": [],\n  "confidence": 0.9,\n  "explanation": "Compare the different groups"\n}'
2026-01-01 20:45:44 [debug    ] llm_json_parse_success         length=15
2026-01-01 20:45:44 [info     ] llm_call_success               feature=filter_extraction latency_ms=3218.1478750135284 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:45:44 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='compare the groups' valid_count=0
2026-01-01 20:45:44 [info     ] llm_parse_success              confidence=0.9 intent_type=COMPARE_GROUPS query='compare the groups'
2026-01-01 20:45:44 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COMPARE_GROUPS matched_vars=[] query='compare the groups' tier=llm_fallback upload_id=None
2026-01-01 20:45:44 [debug    ] filters_extracted              filter_count=0 filters=[] query='compare the groups'
2026-01-01 20:45:44 [info     ] query_parse_start              dataset_id=None query='remove the n/a' upload_id=None
2026-01-01 20:45:44 [info     ] llm_refinement_parsing_started conversation_history_count=1 previous_filters=[] previous_group_by=statin previous_intent=COUNT previous_query='count patients by statin' query='remove the n/a'
2026-01-01 20:45:55 [debug    ] llm_raw_response_received      has_conversation_history=True query='remove the n/a' response_length=226 response_preview='{\n  "intent": "COUNT",\n  "metric": null,\n  "group_by": null,\n  "filters": [{"column": "statin_prescribed", "operator": "!=", "value": 0}],\n  "confidence": 0.9,\n  "explanation": "Refining previous quer'
2026-01-01 20:45:55 [info     ] refinement_group_by_preserved  previous_group_by=statin query='remove the n/a'
2026-01-01 20:45:55 [info     ] llm_refinement_parsing_completed extracted_confidence=0.9 extracted_filters_count=1 extracted_group_by=statin extracted_intent=COUNT filters_extracted=[{'column': 'statin_prescribed', 'operator': '!=', 'value': 0}] group_by_matches_previous=True intent_matches_previous=True previous_group_by=statin previous_intent=COUNT query='remove the n/a'
2026-01-01 20:46:03 [debug    ] llm_json_parse_success         length=65
2026-01-01 20:46:03 [info     ] llm_call_success               feature=filter_extraction latency_ms=7216.4423749782145 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:46:03 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='remove the n/a' valid_count=1
2026-01-01 20:46:03 [info     ] llm_parse_success              confidence=0.9 intent_type=COUNT query='remove the n/a'
2026-01-01 20:46:03 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=['statin'] query='remove the n/a' tier=llm_fallback upload_id=None
2026-01-01 20:46:03 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'statin', 'operator': '!=', 'value': 0}] query='remove the n/a'
2026-01-01 20:46:03 [debug    ] filters_extracted_in_parse     filter_count=2 intent_type=COUNT query='remove the n/a'
2026-01-01 20:46:03 [info     ] query_parse_start              dataset_id=None query='exclude missing values' upload_id=None
2026-01-01 20:46:03 [info     ] llm_refinement_parsing_started conversation_history_count=1 previous_filters=[] previous_group_by=None previous_intent=DESCRIBE previous_query='describe cholesterol' query='exclude missing values'
2026-01-01 20:46:15 [debug    ] llm_raw_response_received      has_conversation_history=True query='exclude missing values' response_length=222 response_preview='{\n  "intent": "DESCRIBE",\n  "metric": null,\n  "group_by": null,\n  "filters": [{"column": "treatment", "operator": "!=", "value": 0}],\n  "confidence": 0.9,\n  "explanation": "Describing treatment, exclu'
2026-01-01 20:46:15 [info     ] refinement_metric_preserved    previous_metric=cholesterol query='exclude missing values'
2026-01-01 20:46:15 [info     ] llm_refinement_parsing_completed extracted_confidence=0.9 extracted_filters_count=1 extracted_group_by=None extracted_intent=DESCRIBE filters_extracted=[{'column': 'treatment', 'operator': '!=', 'value': 0}] group_by_matches_previous=None intent_matches_previous=True previous_group_by=None previous_intent=DESCRIBE query='exclude missing values'
2026-01-01 20:46:20 [debug    ] llm_json_parse_success         length=88
2026-01-01 20:46:20 [info     ] llm_call_success               feature=filter_extraction latency_ms=5472.935957979644 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:46:20 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='exclude missing values' valid_count=1
2026-01-01 20:46:20 [info     ] llm_parse_success              confidence=0.9 intent_type=DESCRIBE query='exclude missing values'
2026-01-01 20:46:20 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['cholesterol'] query='exclude missing values' tier=llm_fallback upload_id=None
2026-01-01 20:46:20 [debug    ] filters_extracted              filter_count=0 filters=[] query='exclude missing values'
2026-01-01 20:46:20 [debug    ] filters_extracted_in_parse     filter_count=2 intent_type=DESCRIBE query='exclude missing values'
2026-01-01 20:46:20 [info     ] query_parse_start              dataset_id=None query='actually over 65' upload_id=None
2026-01-01 20:46:21 [info     ] llm_refinement_parsing_started conversation_history_count=1 previous_filters=[{'column': 'age', 'operator': '>', 'value': 50, 'exclude_nulls': True}] previous_group_by=None previous_intent=COUNT previous_query='patients over 50' query='actually over 65'
2026-01-01 20:46:32 [debug    ] llm_raw_response_received      has_conversation_history=True query='actually over 65' response_length=195 response_preview='{\n  "intent": "COUNT",\n  "metric": null,\n  "group_by": null,\n  "filters": [{"column": "age", "operator": ">", "value": 65}],\n  "confidence": 0.9,\n  "explanation": "Count patients older than 65"\n}'
2026-01-01 20:46:32 [info     ] llm_refinement_parsing_completed extracted_confidence=0.9 extracted_filters_count=1 extracted_group_by=None extracted_intent=COUNT filters_extracted=[{'column': 'age', 'operator': '>', 'value': 65}] group_by_matches_previous=None intent_matches_previous=True previous_group_by=None previous_intent=COUNT query='actually over 65'
2026-01-01 20:46:37 [debug    ] llm_json_parse_success         length=86
2026-01-01 20:46:37 [info     ] llm_call_success               feature=filter_extraction latency_ms=5403.350792010315 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:46:37 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='actually over 65' valid_count=1
2026-01-01 20:46:37 [info     ] llm_parse_success              confidence=0.9 intent_type=COUNT query='actually over 65'
2026-01-01 20:46:37 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='actually over 65' tier=llm_fallback upload_id=None
2026-01-01 20:46:37 [debug    ] filters_extracted              filter_count=0 filters=[] query='actually over 65'
2026-01-01 20:46:37 [debug    ] filters_extracted_in_parse     filter_count=1 intent_type=COUNT query='actually over 65'
2026-01-01 20:46:37 [debug    ] grouping_extraction_failed     intent_type=COUNT query='actually over 65'
2026-01-01 20:46:37 [info     ] query_parse_start              dataset_id=None query='only active patients' upload_id=None
2026-01-01 20:46:37 [info     ] llm_refinement_parsing_started conversation_history_count=1 previous_filters=[] previous_group_by=treatment previous_intent=COUNT previous_query='count patients by treatment' query='only active patients'
2026-01-01 20:46:48 [debug    ] llm_raw_response_received      has_conversation_history=True query='only active patients' response_length=240 response_preview='{\n  "intent": "COMPARE_GROUPS",\n  "metric": null,\n  "group_by": "status",\n  "filters": [{"column": "status", "operator": "==", "value": 1}],\n  "confidence": 0.9,\n  "explanation": "Compare by active st'
2026-01-01 20:46:48 [info     ] refinement_intent_corrected    corrected_intent=COUNT llm_intent=COUNT query='only active patients'
2026-01-01 20:46:48 [info     ] llm_refinement_parsing_completed extracted_confidence=0.9 extracted_filters_count=1 extracted_group_by=status extracted_intent=COUNT filters_extracted=[{'column': 'status', 'operator': '==', 'value': 1}] group_by_matches_previous=False intent_matches_previous=True previous_group_by=treatment previous_intent=COUNT query='only active patients'
2026-01-01 20:46:53 [debug    ] llm_json_parse_success         length=72
2026-01-01 20:46:53 [info     ] llm_call_success               feature=filter_extraction latency_ms=4876.32812501397 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:46:53 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='only active patients' valid_count=1
2026-01-01 20:46:53 [info     ] llm_parse_success              confidence=0.9 intent_type=COUNT query='only active patients'
2026-01-01 20:46:53 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=['status'] query='only active patients' tier=llm_fallback upload_id=None
2026-01-01 20:46:53 [debug    ] filters_extracted              filter_count=0 filters=[] query='only active patients'
2026-01-01 20:46:53 [debug    ] filters_extracted_in_parse     filter_count=2 intent_type=COUNT query='only active patients'
2026-01-01 20:46:53 [info     ] query_parse_start              dataset_id=None query='remove the n/a' upload_id=None
2026-01-01 20:47:05 [debug    ] llm_raw_response_received      has_conversation_history=False query='remove the n/a' response_length=223 response_preview='{\n  "intent": "DESCRIBE",\n  "metric": null,\n  "group_by": null,\n  "filters": [{"column": "statin_used", "operator": "!=", "value": 0}],\n  "confidence": 0.9,\n  "explanation": "Remove n/a values from th'
2026-01-01 20:47:11 [debug    ] llm_json_parse_success         length=65
2026-01-01 20:47:11 [info     ] llm_call_success               feature=filter_extraction latency_ms=5369.920541997999 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:47:11 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='remove the n/a' valid_count=1
2026-01-01 20:47:11 [info     ] llm_parse_success              confidence=0.9 intent_type=DESCRIBE query='remove the n/a'
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=[] query='remove the n/a' tier=llm_fallback upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='remove the n/a'
2026-01-01 20:47:11 [debug    ] filters_extracted_in_parse     filter_count=2 intent_type=DESCRIBE query='remove the n/a'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='how many patients were on statins' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='how many patients were on statins' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'statin', 'operator': '==', 'value': 'statins'}] query='how many patients were on statins'
2026-01-01 20:47:11 [debug    ] filters_extracted_in_parse     filter_count=1 intent_type=COUNT query='how many patients were on statins'
2026-01-01 20:47:11 [debug    ] grouping_extraction_failed     intent_type=COUNT query='how many patients were on statins'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='excluding those not on statins, which was the most prescribed statin?' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='excluding those not on statins, which was the most prescribed statin?' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'statin', 'operator': '!=', 'value': 'statins'}] query='excluding those not on statins, which was the most prescribed statin?'
2026-01-01 20:47:11 [debug    ] filters_extracted_in_parse     filter_count=1 intent_type=COUNT query='excluding those not on statins, which was the most prescribed statin?'
2026-01-01 20:47:11 [debug    ] grouping_extracted             column_name=statin confidence=0.7 group_phrase=prescribed query='excluding those not on statins, which was the most prescribed statin?'
2026-01-01 20:47:11 [info     ] grouping_extracted_from_compound grouping_variable=statin intent_type=COUNT query='excluding those not on statins, which was the most prescribed statin?'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='what statins were those patients on, broken down by count of patients per statin?' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='what statins were those patients on, broken down by count of patients per statin?' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='what statins were those patients on, broken down by count of patients per statin?'
2026-01-01 20:47:11 [debug    ] grouping_extracted_broken_down column_name=statin confidence=0.9 group_phrase=statin query='what statins were those patients on, broken down by count of patients per statin?'
2026-01-01 20:47:11 [info     ] grouping_extracted_from_compound grouping_variable=statin intent_type=COUNT query='what statins were those patients on, broken down by count of patients per statin?'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='which statin was most prescribed?' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='which statin was most prescribed?' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='which statin was most prescribed?'
2026-01-01 20:47:11 [debug    ] grouping_extracted             column_name=statin confidence=0.7 group_phrase=statin query='which statin was most prescribed?'
2026-01-01 20:47:11 [info     ] grouping_extracted_from_compound grouping_variable=statin intent_type=COUNT query='which statin was most prescribed?'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='what was the most common HIV regiment?' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='what was the most common HIV regiment?' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='what was the most common HIV regiment?'
2026-01-01 20:47:11 [debug    ] grouping_extraction_failed     intent_type=COUNT query='what was the most common HIV regiment?'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='average BMI of patients' upload_id=None
2026-01-01 20:47:11 [debug    ] pattern_match_average_with_variable confidence=0.9 grouping=None matched_var=BMI variable_term=bmi
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['BMI'] query='average BMI of patients' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='average BMI of patients'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='average ldl of all patients' upload_id=None
2026-01-01 20:47:11 [debug    ] pattern_match_average_with_variable confidence=0.9 grouping=None matched_var=LDL variable_term=ldl
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=DESCRIBE matched_vars=['LDL'] query='average ldl of all patients' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='average ldl of all patients'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='what was the most common Current Regimen' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='what was the most common Current Regimen' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='what was the most common Current Regimen'
2026-01-01 20:47:11 [debug    ] grouping_extraction_failed     intent_type=COUNT query='what was the most common Current Regimen'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='what statins were those patients on, broken down by count of patients by their Current Regimen' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='what statins were those patients on, broken down by count of patients by their Current Regimen' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='what statins were those patients on, broken down by count of patients by their Current Regimen'
2026-01-01 20:47:11 [debug    ] grouping_extracted_broken_down column_name=patient_id confidence=0.6 group_phrase='count of patients by their current regimen' query='what statins were those patients on, broken down by count of patients by their Current Regimen'
2026-01-01 20:47:11 [info     ] grouping_extracted_from_compound grouping_variable=patient_id intent_type=COUNT query='what statins were those patients on, broken down by count of patients by their Current Regimen'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='how does bmi, statin use relate to the regiment that the person is on and their cd4 counts?' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=CORRELATIONS matched_vars=['BMI', 'statin', 'BMI', 'statin', 'treatment', 'time_zero', 'status'] query='how does bmi, statin use relate to the regiment that the person is on and their cd4 counts?' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='how does bmi, statin use relate to the regiment that the person is on and their cd4 counts?'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='what combination of age, baseline cd4 count, bmi, and statin use best predicts virologic failure within 12 months?' upload_id=None
2026-01-01 20:47:11 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='what combination of age, baseline cd4 count, bmi, and statin use best predicts virologic failure within 12 months?' tier=pattern_match upload_id=None
2026-01-01 20:47:11 [debug    ] filters_extracted              filter_count=0 filters=[] query='what combination of age, baseline cd4 count, bmi, and statin use best predicts virologic failure within 12 months?'
2026-01-01 20:47:11 [debug    ] grouping_extraction_failed     intent_type=COUNT query='what combination of age, baseline cd4 count, bmi, and statin use best predicts virologic failure within 12 months?'
2026-01-01 20:47:11 [info     ] query_parse_start              dataset_id=None query='time to first cardiovascular event or death, stratified by statin use and baseline ldl above 100' upload_id=None
2026-01-01 20:47:21 [debug    ] llm_raw_response_received      has_conversation_history=False query='time to first cardiovascular event or death, stratified by statin use and baseline ldl above 100' response_length=294 response_preview='{\n  "intent": "COMPARE_GROUPS",\n  "metric": null,\n  "group_by": "statin_used",\n  "filters": [\n    {\n      "column": "baseline_lld",\n      "operator": ">=",\n      "value": 100\n    }\n  ],\n  "confidence"'
2026-01-01 20:47:28 [debug    ] llm_json_parse_success         length=119
2026-01-01 20:47:28 [info     ] llm_call_success               feature=filter_extraction latency_ms=6630.158457992366 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:47:28 [debug    ] filter_extraction_completed    confidence_delta=0.0 invalid_count=0 query='time to first cardiovascular event or death, stratified by statin use and baseline ldl above 100' valid_count=2
2026-01-01 20:47:28 [info     ] llm_parse_success              confidence=0.9 intent_type=COMPARE_GROUPS query='time to first cardiovascular event or death, stratified by statin use and baseline ldl above 100'
2026-01-01 20:47:28 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COMPARE_GROUPS matched_vars=['statin_used'] query='time to first cardiovascular event or death, stratified by statin use and baseline ldl above 100' tier=llm_fallback upload_id=None
2026-01-01 20:47:28 [info     ] variables_extracted_post_parse grouping_variable=time_zero intent_type=COMPARE_GROUPS matched_vars=['time_zero', 'statin', 'LDL'] primary_variable=statin
2026-01-01 20:47:28 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'LDL', 'operator': '>', 'value': 100}] query='time to first cardiovascular event or death, stratified by statin use and baseline ldl above 100'
2026-01-01 20:47:28 [debug    ] filters_extracted_in_parse     filter_count=4 intent_type=COMPARE_GROUPS query='time to first cardiovascular event or death, stratified by statin use and baseline ldl above 100'
2026-01-01 20:47:28 [info     ] query_parse_start              dataset_id=None query='compare average cd4 change from baseline to 6 months between hiv regimens, only for those on statins with bmi > 25' upload_id=None
2026-01-01 20:47:28 [debug    ] pattern_match_average_no_variable_match reason=fuzzy_match_failed_but_pattern_matched variable_term='cd4 change from baseline to 6 months'
2026-01-01 20:47:28 [debug    ] filters_extracted              filter_count=3 filters=[{'column': 'BMI', 'operator': '==', 'value': 'bmi > 25'}, {'column': 'BMI', 'operator': '==', 'value': 'statins with bmi > 25'}, {'column': 'BMI', 'operator': '>', 'value': 25}] query='compare average cd4 change from baseline to 6 months between hiv regimens, only for those on statins with bmi > 25'
2026-01-01 20:47:28 [debug    ] filters_extracted_in_parse     filter_count=3 intent_type=DESCRIBE query='compare average cd4 change from baseline to 6 months between hiv regimens, only for those on statins with bmi > 25'
2026-01-01 20:47:28 [info     ] query_parse_start              dataset_id=None query='how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?' upload_id=None
2026-01-01 20:47:36 [debug    ] llm_raw_response_received      has_conversation_history=False query='how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?' response_length=251 response_preview='{\n  "intent": "COMPARE_GROUPS",\n  "metric": null,\n  "group_by": ["baseline_ldl_category", "regimen_type"],\n  "filters": [],\n  "confidence": 0.95,\n  "explanation": "Compare statin adherence and LDL red'
2026-01-01 20:47:43 [debug    ] llm_json_parse_success         length=139
2026-01-01 20:47:43 [info     ] llm_call_success               feature=filter_extraction latency_ms=6934.576416009804 model=llama3.1:8b payload_keys=['filters'] timeout_s=30.0
2026-01-01 20:47:43 [warning  ] filter_extraction_validation_failures failure_count=2 failures=["Invalid filter: Invalid operator '='. Must be one of {'==', '!=', '>', '<=', 'NOT_IN', 'IN', '>=', '<'}", "Invalid filter: Missing 'value' field"] query='how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?'
2026-01-01 20:47:43 [debug    ] filter_extraction_completed    confidence_delta=-0.35 invalid_count=2 query='how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?' valid_count=0
2026-01-01 20:47:43 [info     ] llm_parse_success              confidence=0.6 intent_type=COMPARE_GROUPS query='how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?'
2026-01-01 20:47:43 [info     ] query_parse_success            confidence=0.6 dataset_id=None intent=COMPARE_GROUPS matched_vars=[['baseline_ldl_category', 'regimen_type']] query='how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?' tier=llm_fallback upload_id=None
2026-01-01 20:47:43 [info     ] variables_extracted_post_parse grouping_variable=statin intent_type=COMPARE_GROUPS matched_vars=['statin', 'LDL', 'treatment'] primary_variable=LDL
2026-01-01 20:47:43 [debug    ] filters_extracted              filter_count=1 filters=[{'column': 'LDL', 'operator': '==', 'value': 'vary by baseline ldl category'}] query='how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?'
2026-01-01 20:47:43 [debug    ] filters_extracted_in_parse     filter_count=1 intent_type=COMPARE_GROUPS query='how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?'
2026-01-01 20:47:43 [info     ] query_parse_start              dataset_id=None query='among patients with virologic suppression within 6 months, how many had cardiovascular events by statin use and baseline ldl category?' upload_id=None
2026-01-01 20:47:43 [info     ] query_parse_success            confidence=0.9 dataset_id=None intent=COUNT matched_vars=[] query='among patients with virologic suppression within 6 months, how many had cardiovascular events by statin use and baseline ldl category?' tier=pattern_match upload_id=None
2026-01-01 20:47:43 [debug    ] filters_extracted              filter_count=0 filters=[] query='among patients with virologic suppression within 6 months, how many had cardiovascular events by statin use and baseline ldl category?'
2026-01-01 20:47:43 [debug    ] grouping_extracted_broken_down column_name=LDL confidence=0.6 group_phrase='statin use and baseline ldl category' query='among patients with virologic suppression within 6 months, how many had cardiovascular events by statin use and baseline ldl category?'
2026-01-01 20:47:43 [info     ] grouping_extracted_from_compound grouping_variable=LDL intent_type=COUNT query='among patients with virologic suppression within 6 months, how many had cardiovascular events by statin use and baseline ldl category?'

================================================================================
FAILURES
================================================================================

✗ exclude_na_statin_count
  Query: remove the n/a (0) - what statins were patients on?
  Expected: COUNT
  Actual: COUNT
  Confidence: 0.90

✗ refinement_remove_na_with_context
  Query: remove the n/a
  Expected: COUNT
  Actual: COUNT
  Confidence: 0.90

✗ refinement_exclude_with_context
  Query: exclude missing values
  Expected: DESCRIBE
  Actual: DESCRIBE
  Confidence: 0.90

✗ refinement_only_active_with_context
  Query: only active patients
  Expected: COUNT
  Actual: COUNT
  Confidence: 0.90

✗ prod_most_common_hiv_regimen
  Query: what was the most common HIV regiment?
  Expected: COUNT
  Actual: COUNT
  Confidence: 0.90

✗ prod_most_common_current_regimen
  Query: what was the most common Current Regimen
  Expected: COUNT
  Actual: COUNT
  Confidence: 0.90

✗ prod_statin_by_regimen
  Query: what statins were those patients on, broken down by count of patients by their Current Regimen
  Expected: COUNT
  Actual: COUNT
  Confidence: 0.90

✗ complex_predictive_modeling
  Query: what combination of age, baseline cd4 count, bmi, and statin use best predicts virologic failure within 12 months?
  Expected: FIND_PREDICTORS
  Actual: COUNT
  Confidence: 0.90
  ❌ Intent: expected FIND_PREDICTORS, got COUNT

✗ complex_survival_stratified
  Query: time to first cardiovascular event or death, stratified by statin use and baseline ldl above 100
  Expected: FIND_PREDICTORS
  Actual: COMPARE_GROUPS
  Confidence: 0.90
  ❌ Intent: expected FIND_PREDICTORS, got COMPARE_GROUPS

✗ complex_compare_with_filters
  Query: compare average cd4 change from baseline to 6 months between hiv regimens, only for those on statins with bmi > 25
  Expected: COMPARE_GROUPS
  Actual: DESCRIBE
  Confidence: 0.85
  ❌ Intent: expected COMPARE_GROUPS, got DESCRIBE

✗ complex_correlation_interactions
  Query: how does statin adherence and ldl reduction vary by baseline ldl category and regimen type?
  Expected: CORRELATIONS
  Actual: COMPARE_GROUPS
  Confidence: 0.60
  ❌ Intent: expected CORRELATIONS, got COMPARE_GROUPS

✗ complex_count_nested
  Query: among patients with virologic suppression within 6 months, how many had cardiovascular events by statin use and baseline ldl category?
  Expected: COUNT
  Actual: COUNT
  Confidence: 0.90

================================================================================
SUMMARY
================================================================================
Total Questions: 39
Correct: 27
Incorrect: 12
Accuracy: 69.2%
Intent Accuracy: 89.7%
Average Confidence: 0.89
____ TestUIDatasetIntegration.test_ui_workflow_end_to_end_with_all_datasets ____

self = <ui.test_integration.TestUIDatasetIntegration object at 0x12a5cb650>

    @pytest.mark.slow
    @pytest.mark.integration
    def test_ui_workflow_end_to_end_with_all_datasets(self):
        """Test complete UI workflow: select dataset -> get cohort -> verify schema."""
        # Arrange: Get all available datasets
        available_datasets = DatasetRegistry.list_datasets()

        tested_count = 0
        for dataset_name in available_datasets:
            # Skip uploaded class (requires upload_id)
            if dataset_name == "uploaded":
                continue

            # Act: Create dataset instance (UI pattern)
            dataset = DatasetRegistry.get_dataset(dataset_name)

            if not dataset.validate():
                continue

            # Get cohort (as UI would)
            cohort = dataset.get_cohort()

            # Assert: Verify results
            assert isinstance(cohort, pd.DataFrame)
            assert len(cohort) > 0

            # Check schema compliance
            for col in UnifiedCohort.REQUIRED_COLUMNS:
                assert col in cohort.columns, f"Dataset {dataset_name} missing required column: {col}"

            tested_count += 1

        # Assert: At least one dataset was tested
>       assert tested_count > 0, "No datasets available for testing"
E       AssertionError: No datasets available for testing
E       assert 0 > 0

tests/ui/test_integration.py:142: AssertionError
=============================== warnings summary ===============================
.venv/lib/python3.13/site-packages/_pytest/config/__init__.py:852
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/_pytest/config/__init__.py:852: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; performance.plugin
    self.import_plugin(import_spec)

tests/core/test_nl_query_engine_self_improvement.py:21
  /Users/jasontouleyrou/Projects/md_data_explorer/tests/core/test_nl_query_engine_self_improvement.py:21: PytestUnknownMarkWarning: Unknown pytest.mark.serial - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.serial  # Uses shared /tmp/ path - must run serially

tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_compute_comparison_analysis_chi_square_for_categorical
  /Users/jasontouleyrou/Projects/md_data_explorer/src/clinical_analytics/analysis/compute.py:557: DeprecationWarning: the argument `columns` for `DataFrame.pivot` is deprecated. It was renamed to `on` in version 1.0.0.
    .pivot(index=outcome_col, columns=group_col, values="count", aggregate_function="sum")

tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_comparison_analysis_with_european_comma_format
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/scipy/stats/_stats_py.py:6316: RuntimeWarning: invalid value encountered in scalar divide
    svar = ((n1 - 1) * v1 + (n2 - 1) * v2) / df

tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_comparison_analysis_with_european_comma_format
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:222: RuntimeWarning: Degrees of freedom <= 0 for slice
    ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,

tests/analysis/test_compute.py::TestComputeComparisonAnalysis::test_comparison_analysis_with_european_comma_format
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:214: RuntimeWarning: invalid value encountered in scalar divide
    ret = ret.dtype.type(ret / rcount)

tests/analysis/test_compute.py::TestComputePredictorAnalysis::test_compute_predictor_analysis_returns_serializable_dict
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_predictor
tests/analysis/test_stats.py::TestStats::test_run_logistic_regression_with_nulls
tests/analysis/test_stats_vectorization.py::TestVectorizedOperations::test_odds_ratio_calculation_uses_vectorized_operations
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
    warnings.warn("Maximum Likelihood optimization failed to "

tests/analysis/test_compute.py::TestComputePredictorAnalysis::test_compute_predictor_analysis_returns_serializable_dict
tests/analysis/test_compute.py::TestComputeAnalysisByType::test_compute_analysis_by_type_routes_to_predictor
tests/analysis/test_stats.py::TestStats::test_run_logistic_regression_with_nulls
tests/analysis/test_stats_vectorization.py::TestVectorizedOperations::test_odds_ratio_calculation_uses_vectorized_operations
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/pandas/core/internals/blocks.py:395: RuntimeWarning: overflow encountered in exp
    result = func(self.values, **kwargs)

tests/analysis/test_stats.py::TestStats::test_run_logistic_regression_with_nulls
tests/analysis/test_stats_vectorization.py::TestVectorizedOperations::test_odds_ratio_calculation_uses_vectorized_operations
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified
    warnings.warn(msg, category=PerfectSeparationWarning)

tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression_categorical
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression_with_nulls
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/lifelines/fitters/coxph_fitter.py:1217: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    self._time_fit_was_called = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S") + " UTC"

tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/lifelines/fitters/coxph_fitter.py:1589: ConvergenceWarning: The log-likelihood is getting suspiciously close to 0 and the delta is still large. There may be complete separation in the dataset. This may result in incorrect inference of coefficients. See https://stats.stackexchange.com/q/11109/11867 for more.

    warnings.warn(

tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression
tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression_with_nulls
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column age has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression

    warnings.warn(dedent(warning_text), ConvergenceWarning)

tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/lifelines/fitters/coxph_fitter.py:1614: ConvergenceWarning: Newton-Raphson failed to converge sufficiently. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model
    warnings.warn(

tests/analysis/test_survival.py::TestSurvivalAnalysis::test_run_cox_regression_with_nulls
  /Users/jasontouleyrou/Projects/md_data_explorer/.venv/lib/python3.13/site-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.707. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?

    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/core/test_llm_fallback_integration.py::test_ollama_client_real_generate
FAILED tests/core/test_mapper.py::TestColumnMapper::test_mapper_initialization_with_config
FAILED tests/core/test_mapper.py::TestColumnMapper::test_get_default_predictors_returns_list
FAILED tests/core/test_mapper.py::TestColumnMapper::test_get_categorical_variables_returns_list
FAILED tests/core/test_mapper.py::TestColumnMapper::test_get_default_outcome_returns_non_empty_string
FAILED tests/core/test_mapper.py::TestColumnMapper::test_get_default_filters_returns_dict
FAILED tests/core/test_nl_query_engine_filter_extraction.py::TestFilterExtractionStrategy1ToStrategy2Handoff::test_strategy1_passes_coded_column_to_strategy2
FAILED tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_exclusion_filter_works_for_any_medication_type
FAILED tests/core/test_nl_query_engine_filter_extraction.py::TestExclusionFilters::test_exclusion_filter_works_for_any_coded_column
FAILED tests/core/test_nl_query_refinement.py::test_parse_query_refinement_merges_with_existing_filters
FAILED tests/core/test_nl_query_refinement.py::test_parse_query_refinement_updates_same_column_filter
FAILED tests/core/test_nl_query_refinement.py::test_llm_refinement_with_coded_categorical_column
FAILED tests/core/test_nl_query_refinement.py::test_llm_provides_explanation_for_refinement
FAILED tests/core/test_nl_query_refinement.py::test_parse_query_refinement_handles_llm_failure_with_fallback
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_analyze_failures_with_invalid_intent_detects_pattern
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_analyze_failures_with_refinement_failures_detects_pattern
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_analyze_failures_with_all_passing_returns_empty_list
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_generate_fix_from_template_replaces_placeholders
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_generate_prompt_additions_with_patterns_returns_text
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_generate_prompt_additions_with_no_patterns_returns_empty
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_get_keyword_hints_with_matching_keyword_returns_intent
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_get_keyword_hints_with_no_match_returns_none
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_is_refinement_query_with_refinement_phrase_returns_true
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_is_refinement_query_with_no_phrase_returns_false
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_evaluate_condition_with_valid_condition_returns_true
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_evaluate_condition_with_invalid_condition_returns_false
FAILED tests/core/test_prompt_optimizer.py::test_optimizer_analyze_failures_with_none_intent_filters_none_values
FAILED tests/core/test_registry.py::TestDatasetRegistry::test_get_dataset_factory_creates_instance
FAILED tests/core/test_registry.py::TestDatasetRegistry::test_get_dataset_with_override_params_applies_overrides
FAILED tests/core/test_registry.py::TestDatasetRegistry::test_registry_filters_unsupported_params_without_error
FAILED tests/eval/test_golden_questions.py::test_golden_questions_evaluation
FAILED tests/ui/test_integration.py::TestUIDatasetIntegration::test_ui_workflow_end_to_end_with_all_datasets
===== 32 failed, 1153 passed, 29 skipped, 24 warnings in 338.09s (0:05:38) =====
make: *** [test] Error 1
